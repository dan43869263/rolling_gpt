self.enc_in = 7
self.data_x = (8640, 7)
train 56791
self.enc_in = 7
self.data_x = (3216, 7)
val 18823
self.enc_in = 7
self.data_x = (3216, 7)
test 18823
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)













221it [00:28,  7.77it/s]
14it [00:00, 17.49it/s]


73it [00:04, 17.21it/s]
Epoch: 1, Steps: 221 | Train Loss: 0.4234181 Vali Loss: 0.9508148
lr = 0.0000993845
Validation loss decreased (inf --> 0.950815).  Saving model ...













221it [00:27,  7.94it/s]
26it [00:01, 17.37it/s]

73it [00:04, 17.10it/s]
4it [00:00,  8.62it/s]
Epoch: 2, Steps: 221 | Train Loss: 0.3950043 Vali Loss: 0.9480848
lr = 0.0000975531













221it [00:27,  7.94it/s]
6it [00:00, 15.88it/s]


73it [00:04, 17.18it/s]
Epoch: 3, Steps: 221 | Train Loss: 0.3872611 Vali Loss: 0.9651084
lr = 0.0000945509
EarlyStopping counter: 1 out of 3













221it [00:27,  7.95it/s]
Epoch: 4 cost time: 28.11113929748535

73it [00:04, 17.21it/s]
11it [00:01,  8.04it/s]
Epoch: 4, Steps: 221 | Train Loss: 0.3808800 Vali Loss: 0.9699200
lr = 0.0000904518













221it [00:27,  7.95it/s]
22it [00:01, 17.71it/s]

73it [00:04, 17.18it/s]
10it [00:00, 17.93it/s]
Epoch: 5, Steps: 221 | Train Loss: 0.3759755 Vali Loss: 0.9710111
lr = 0.0000853568
EarlyStopping counter: 3 out of 3
Early stopping


73it [00:04, 18.01it/s]
test shape: (73, 256, 192, 1) (73, 256, 192, 1)
test shape: (18688, 192, 1) (18688, 192, 1)
mae:0.4243, mse:0.4238, rmse:0.6510, r2:0.6150
self.enc_in = 7
self.data_x = (8640, 7)
train 56791
self.enc_in = 7
self.data_x = (3216, 7)
val 18823
self.enc_in = 7
self.data_x = (3216, 7)
test 18823
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)













221it [00:27,  7.97it/s]
Epoch: 1 cost time: 28.021266222000122

73it [00:04, 17.19it/s]
6it [00:00,  8.36it/s]
Epoch: 1, Steps: 221 | Train Loss: 0.4239387 Vali Loss: 0.9460762
lr = 0.0000993845













221it [00:27,  7.97it/s]
12it [00:00, 17.34it/s]


73it [00:04, 17.24it/s]
Epoch: 2, Steps: 221 | Train Loss: 0.3951051 Vali Loss: 0.9419855
lr = 0.0000975531
Validation loss decreased (0.946076 --> 0.941986).  Saving model ...













220it [00:27,  7.99it/s]
221it [00:27,  7.97it/s]

62it [00:03, 17.46it/s]
Epoch: 3, Steps: 221 | Train Loss: 0.3867896 Vali Loss: 0.9473114
lr = 0.0000945509
73it [00:04, 17.17it/s]













217it [00:27,  7.95it/s]
221it [00:27,  7.97it/s]

54it [00:03, 17.38it/s]
Epoch: 4, Steps: 221 | Train Loss: 0.3810986 Vali Loss: 0.9592986
lr = 0.0000904518
73it [00:04, 17.21it/s]













212it [00:26,  7.94it/s]
221it [00:27,  7.96it/s]

44it [00:02, 17.48it/s]
Epoch: 5, Steps: 221 | Train Loss: 0.3747723 Vali Loss: 0.9731768
lr = 0.0000853568
EarlyStopping counter: 3 out of 3

73it [00:04, 17.27it/s]
------------------------------------

70it [00:03, 18.26it/s]
test shape: (73, 256, 192, 1) (73, 256, 192, 1)
test shape: (18688, 192, 1) (18688, 192, 1)
mae:0.4226, mse:0.4230, rmse:0.6504, r2:0.6157
self.enc_in = 7
self.data_x = (8640, 7)
train 56791
self.enc_in = 7
self.data_x = (3216, 7)
val 18823
self.enc_in = 7
self.data_x = (3216, 7)
test 18823
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
73it [00:04, 17.93it/s]













214it [00:26,  7.91it/s]
221it [00:27,  7.97it/s]

48it [00:02, 17.52it/s]
Epoch: 1, Steps: 221 | Train Loss: 0.4241005 Vali Loss: 0.9536784
lr = 0.0000993845

73it [00:04, 17.26it/s]













221it [00:27,  7.98it/s]
Epoch: 2 cost time: 28.014387845993042

66it [00:03, 17.53it/s]
Epoch: 2, Steps: 221 | Train Loss: 0.3945252 Vali Loss: 0.9415506
lr = 0.0000975531
73it [00:04, 17.20it/s]













213it [00:26,  8.00it/s]
221it [00:27,  7.97it/s]

46it [00:02, 17.53it/s]
Epoch: 3, Steps: 221 | Train Loss: 0.3865584 Vali Loss: 0.9621934
lr = 0.0000945509
73it [00:04, 17.25it/s]













209it [00:26,  7.95it/s]
221it [00:27,  7.97it/s]


73it [00:04, 17.25it/s]
Epoch: 4, Steps: 221 | Train Loss: 0.3808053 Vali Loss: 0.9726904
lr = 0.0000904518
EarlyStopping counter: 2 out of 3












221it [00:27,  7.98it/s]
Epoch: 5 cost time: 28.003525257110596

64it [00:03, 17.52it/s]
Epoch: 5, Steps: 221 | Train Loss: 0.3741152 Vali Loss: 0.9705904
lr = 0.0000853568
EarlyStopping counter: 3 out of 3
Early stopping
73it [00:04, 17.23it/s]

56it [00:03, 18.26it/s]
test shape: (73, 256, 192, 1) (73, 256, 192, 1)
test shape: (18688, 192, 1) (18688, 192, 1)
mae:0.4185, mse:0.4164, rmse:0.6453, r2:0.6218
mse_mean = 0.4211, mse_std = 0.0033

73it [00:04, 17.95it/s]