['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.12s/it]
1it [00:00, 10.94it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.4869012832641602
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([109])
missing_idx_len: 43
pred tensor([0.2475, 0.1490, 0.3043, 0.1228, 0.3836, 0.2199, 0.2150, 0.1977, 0.2359,
        0.2475, 0.2072, 0.1795, 0.2201, 0.1993, 0.2491, 0.2743, 0.2377, 0.1952,
        0.1925, 0.2062, 0.1940, 0.2168, 0.2683, 0.1768, 0.2479, 0.2184, 0.2591,
        0.1910, 0.2416, 0.2503, 0.2030, 0.2244, 0.2096, 0.2346, 0.1940, 0.2188,
        0.1971, 0.2496, 0.2313, 0.2843, 0.2549, 0.2433, 0.1717, 0.2811, 0.2015,
        0.2227, 0.1920, 0.2038, 0.2403, 0.2879, 0.2346, 0.2075, 0.2597, 0.2581,
        0.2280, 0.2920, 0.2175, 0.2546, 0.2447, 0.2127, 0.1987, 0.2916, 0.1848,
        0.2105, 0.2015, 0.1803, 0.2708, 0.2299, 0.2031, 0.1766, 0.2689, 0.2563,
        0.2427, 0.2116, 0.2273, 0.2495, 0.2403, 0.2553, 0.2736, 0.1977, 0.2570,
        0.2162, 0.2442, 0.2134, 0.2180, 0.2403, 0.1881, 0.3163, 0.2729, 0.1764,
        0.2584, 0.1937, 0.1494, 0.1920, 0.2216, 0.2706, 0.2021, 0.2251, 0.2178,
        0.2169, 0.2146, 0.2512, 0.2565, 0.1982, 0.2604, 0.2200, 0.2687, 0.2353,
        0.1894])
true tensor([1.2125, 0.8875, 1.1250, 0.9750, 1.0625, 1.1875, 0.8875, 1.1250, 0.9750,
        1.1875, 0.8875, 1.1250, 1.1875, 0.8875, 1.0375, 1.0500, 1.3000, 1.2125,
        1.2125, 1.1875, 0.8875, 0.9750, 1.0625, 1.0375, 1.0500, 1.0625, 1.0375,
        1.0500, 1.3000, 1.2125, 1.1250, 0.9750, 1.0625, 1.0375, 1.2125, 1.3000,
        1.1875, 0.8875, 1.1250, 0.9750, 1.2125, 1.0500, 1.3000, 0.9750, 1.0625,
        1.0375, 1.0500, 1.2125, 1.1625, 0.9750, 1.0625, 1.0375, 1.0500, 1.2125,
        1.3000, 0.8875, 1.1250, 0.9750, 1.0625, 1.2125, 1.1875, 0.8875, 1.0625,
        1.0375, 1.0500, 1.3000, 1.3000, 1.1250, 0.9750, 1.0625, 1.0375, 1.1875,
        0.8875, 1.1250, 1.2125, 1.1625, 1.0625, 1.0375, 1.0500, 1.3000, 1.0375,
        1.0500, 1.3000, 1.2125, 1.0375, 1.0500, 1.3000, 1.0500, 1.3000, 1.1625,
        1.2125, 1.1625, 1.0500, 1.3000, 1.1875, 0.8875, 1.1250, 0.9750, 0.8875,
        1.1250, 0.9750, 1.0625, 1.1875, 0.8875, 1.1250, 1.1250, 0.9750, 1.0625,
        1.0375])
Epoch: 1, Steps: 1 | Train Loss: 0.4420472 Vali Loss: 0.7645032
lr = 0.0000975531
Validation loss decreased (inf --> 0.764503).  Saving model ...
1it [00:00,  5.86it/s]
1it [00:00, 12.09it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.6124415397644043
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([109])
missing_idx_len: 43
pred tensor([0.2932, 0.0457, 0.2372, 0.2604, 0.2180, 0.2313, 0.2209, 0.3258, 0.2771,
        0.2544, 0.2188, 0.2494, 0.2385, 0.2527, 0.2396, 0.3019, 0.2103, 0.2549,
        0.2577, 0.2011, 0.2242, 0.2349, 0.2287, 0.1791, 0.2116, 0.3768, 0.2559,
        0.3584, 0.1575, 0.4135, 0.1066, 0.2820, 0.2316, 0.2512, 0.1727, 0.1996,
        0.2167, 0.2035, 0.2497, 0.2636, 0.1976, 0.2294, 0.2129, 0.2072, 0.2114,
        0.2079, 0.1677, 0.2310, 0.2362, 0.2154, 0.1780, 0.2735, 0.2092, 0.2541,
        0.2194, 0.2633, 0.2351, 0.2247, 0.2190, 0.2390, 0.1976, 0.2327, 0.2079,
        0.2457, 0.2907, 0.2719, 0.2196, 0.2098, 0.2633, 0.0575, 0.4022, 0.2365,
        0.2337, 0.2281, 0.2249, 0.1775, 0.3083, 0.2141, 0.2238, 0.2132, 0.2546,
        0.2334, 0.2284, 0.2450, 0.2110, 0.2510, 0.2114, 0.2408, 0.2539, 0.2631,
        0.2128, 0.2253, 0.1838, 0.2419, 0.2243, 0.2590, 0.1951, 0.2027, 0.2637,
        0.2150, 0.2203, 0.2583, 0.1419, 0.2672, 0.2660, 0.1903, 0.2222, 0.1724,
        0.2719])
true tensor([1.0500, 1.3000, 1.2125, 1.1875, 0.8875, 1.1250, 1.0375, 1.0500, 1.3000,
        1.1875, 0.8875, 1.1250, 0.9750, 1.2125, 1.1625, 1.3000, 1.2125, 1.0500,
        1.3000, 1.1250, 0.9750, 1.0625, 1.0375, 1.1875, 0.8875, 1.2125, 1.1625,
        0.8875, 1.1250, 0.9750, 1.0625, 0.8875, 1.1250, 0.9750, 1.0625, 1.1875,
        0.8875, 1.1250, 0.9750, 0.9750, 1.0625, 1.0375, 1.0500, 1.2125, 1.1875,
        0.8875, 1.1250, 1.2125, 1.1625, 1.1875, 0.8875, 1.2125, 1.0625, 1.0375,
        1.0500, 1.3000, 1.2125, 1.3000, 1.0625, 1.0375, 1.0500, 1.3000, 1.2125,
        1.1625, 1.2125, 1.0625, 1.0375, 1.0500, 1.3000, 1.0500, 1.3000, 0.9750,
        1.0625, 1.0375, 1.0500, 1.2125, 1.3000, 1.1875, 0.8875, 1.1250, 1.2125,
        1.1250, 0.9750, 1.0625, 1.0375, 0.8875, 1.1250, 0.9750, 1.0625, 1.0375,
        1.0500, 1.3000, 1.1875, 0.8875, 1.1875, 0.8875, 1.1250, 0.9750, 0.9750,
        1.0625, 1.0375, 1.0500, 1.0375, 1.0500, 1.3000, 1.1250, 0.9750, 1.0625,
        1.0375])
Epoch: 2, Steps: 1 | Train Loss: 0.4428246 Vali Loss: 0.7570456
lr = 0.0000904518
Validation loss decreased (0.764503 --> 0.757046).  Saving model ...
1it [00:00,  5.25it/s]
1it [00:00, 10.65it/s]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.635321855545044
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([109])
missing_idx_len: 43
pred tensor([0.2428, 0.2696, 0.2312, 0.2719, 0.2567, 0.2882, 0.2184, 0.2175, 0.2618,
        0.2343, 0.2906, 0.1572, 0.2215, 0.2057, 0.2536, 0.2095, 0.2235, 0.2566,
        0.2577, 0.2326, 0.1434, 0.2472, 0.2381, 0.2504, 0.1903, 0.2429, 0.2151,
        0.2119, 0.2567, 0.1942, 0.2680, 0.2679, 0.2080, 0.1932, 0.1770, 0.2977,
        0.2220, 0.2366, 0.2415, 0.1977, 0.2118, 0.1944, 0.2630, 0.2683, 0.2461,
        0.2172, 0.2584, 0.2152, 0.2182, 0.2106, 0.2321, 0.2337, 0.2153, 0.2485,
        0.2269, 0.1943, 0.2132, 0.1880, 0.2125, 0.2367, 0.1929, 0.2533, 0.2146,
        0.2577, 0.1218, 0.2646, 0.2571, 0.2468, 0.2157, 0.2662, 0.2081, 0.2072,
        0.2689, 0.2037, 0.2268, 0.2499, 0.2357, 0.2387, 0.2042, 0.2222, 0.1789,
        0.2170, 0.2642, 0.1941, 0.2224, 0.2599, 0.2734, 0.1929, 0.2335, 0.2106,
        0.2803, 0.1944, 0.2660, 0.2443, 0.2723, 0.1855, 0.1962, 0.2480, 0.1900,
        0.1730, 0.2549, 0.2321, 0.2472, 0.2381, 0.2783, 0.1909, 0.1452, 0.2189,
        0.2344])
true tensor([1.0375, 1.0500, 1.3000, 1.2125, 1.2125, 1.3000, 1.1875, 0.8875, 1.1250,
        0.9750, 1.3000, 1.1250, 0.9750, 1.0625, 1.0375, 1.1875, 0.8875, 1.1250,
        1.3000, 1.1875, 0.8875, 0.8875, 1.1250, 0.9750, 1.0625, 0.9750, 1.0625,
        1.0375, 1.0500, 1.1250, 0.9750, 1.0625, 1.0375, 1.0500, 1.3000, 1.2125,
        1.1875, 0.8875, 1.1250, 0.9750, 1.1625, 1.2125, 1.1625, 1.2125, 0.9750,
        1.0625, 1.0375, 1.0500, 1.2125, 1.0625, 1.0375, 1.0500, 1.3000, 1.2125,
        1.1875, 0.8875, 1.1250, 0.9750, 1.1250, 0.9750, 1.0625, 1.0375, 1.0625,
        1.0375, 1.0500, 1.3000, 1.2125, 1.2125, 1.0625, 1.0375, 1.0500, 1.3000,
        1.2125, 1.1625, 1.0500, 1.3000, 1.2125, 1.1625, 0.9750, 1.0625, 1.0375,
        1.0500, 1.1875, 0.8875, 1.1250, 0.8875, 1.1250, 0.9750, 1.0625, 1.0375,
        1.0500, 1.3000, 1.2125, 0.8875, 1.1250, 0.9750, 1.0625, 1.1875, 0.8875,
        1.1250, 1.1875, 0.8875, 1.0375, 1.0500, 1.3000, 1.0500, 1.3000, 1.1875,
        0.8875])
Epoch: 3, Steps: 1 | Train Loss: 0.4402179 Vali Loss: 0.7611097
lr = 0.0000793913
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
1it [00:00,  5.91it/s]
1it [00:00, 10.41it/s]
1it [00:00,  5.99it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([109])
missing_idx_len: 43
pred tensor([0.2516, 0.1913, 0.2651, 0.2325, 0.2249, 0.2733, 0.3006, 0.2472, 0.1938,
        0.2267, 0.2004, 0.2232, 0.2469, 0.2511, 0.2118, 0.2109, 0.2510, 0.2334,
        0.2450, 0.2472, 0.2193, 0.2183, 0.2562, 0.2388, 0.2247, 0.2315, 0.2468,
        0.2368, 0.2199, 0.2059, 0.2420, 0.2281, 0.2060, 0.2653, 0.2002, 0.2476,
        0.2515, 0.2403, 0.2250, 0.2681, 0.2066, 0.1575, 0.2331, 0.2273, 0.2179,
        0.2357, 0.1904, 0.2569, 0.2432, 0.1397, 0.2586, 0.2353, 0.2048, 0.2498,
        0.0961, 0.2631, 0.2342, 0.2546, 0.2243, 0.2328, 0.2642, 0.1921, 0.3150,
        0.2657, 0.2986, 0.2138, 0.2026, 0.1506, 0.2642, 0.2634, 0.2308, 0.2067,
        0.2286, 0.2646, 0.2115, 0.2083, 0.2340, 0.1847, 0.2514, 0.2178, 0.2935,
        0.2220, 0.2180, 0.2466, 0.2310, 0.2503, 0.2403, 0.2196, 0.2141, 0.2347,
        0.2168, 0.2158, 0.2135, 0.2019, 0.2536, 0.2675, 0.2987, 0.2263, 0.2067,
        0.2029, 0.2591, 0.2289, 0.2308, 0.2525, 0.2224, 0.2307, 0.1694, 0.2305,
        0.1914])
true tensor([1.2125, 1.1625, 1.0500, 1.3000, 1.0375, 1.0500, 1.3000, 0.9750, 1.0625,
        1.0375, 1.0500, 1.1625, 0.8875, 1.1250, 0.9750, 1.0625, 0.9750, 1.0625,
        1.0375, 1.0500, 1.1875, 0.8875, 1.3000, 1.2125, 1.1875, 0.8875, 1.1250,
        1.0500, 1.3000, 1.1250, 0.9750, 1.0625, 1.0375, 1.0625, 1.0375, 1.0500,
        1.3000, 1.2125, 1.0625, 1.0375, 1.0500, 1.3000, 1.0625, 1.0375, 1.0500,
        1.3000, 1.1875, 0.8875, 1.0500, 1.3000, 0.9750, 1.0625, 1.0375, 1.0500,
        1.0375, 1.0500, 1.3000, 1.3000, 1.2125, 1.1625, 1.2125, 1.2125, 0.8875,
        1.1250, 0.9750, 1.0625, 1.1875, 0.8875, 1.2125, 1.1875, 0.8875, 1.1250,
        0.9750, 1.0375, 1.0500, 1.3000, 1.1875, 0.8875, 1.1250, 0.9750, 1.1875,
        0.8875, 1.1250, 1.1875, 0.8875, 1.1250, 0.9750, 1.1250, 0.9750, 1.0625,
        1.0375, 0.8875, 1.1250, 0.9750, 1.0625, 1.2125, 1.2125, 1.1875, 0.8875,
        1.1250, 1.3000, 1.2125, 1.2125, 1.1625, 1.1250, 0.9750, 1.0625, 1.0375,
        1.2125])
Epoch: 4, Steps: 1 | Train Loss: 0.4382273 Vali Loss: 0.7587610
lr = 0.0000654543
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.6122746467590332
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([109])
missing_idx_len: 43
pred tensor([ 0.1810,  0.2514,  0.1956,  0.2553,  0.2481,  0.2791,  0.2558,  0.2397,
         0.2602,  0.2118,  0.2244,  0.2229,  0.2398,  0.2049,  0.2842,  0.2066,
         0.2370,  0.2359,  0.2074,  0.2769,  0.2235,  0.2347,  0.1975,  0.1680,
         0.2206,  0.2686,  0.1873,  0.2264,  0.2077,  0.2505,  0.2373,  0.2015,
         0.2135,  0.2495,  0.2077,  0.2917,  0.1754,  0.2173,  0.2156,  0.1999,
         0.2033,  0.2117,  0.2418,  0.2268,  0.1991,  0.2530,  0.2144,  0.2705,
         0.2267,  0.2048,  0.1994,  0.2297,  0.2302,  0.2846,  0.1861,  0.2036,
         0.2638,  0.2307,  0.2574,  0.1402,  0.1915,  0.2772,  0.2279,  0.3062,
         0.2169,  0.2486, -0.0632,  0.4918,  0.3100,  0.2036,  0.2017,  0.2250,
         0.2186,  0.2504,  0.1913,  0.2487,  0.2086,  0.2447,  0.2509,  0.2396,
         0.1878,  0.2500,  0.3554,  0.1833,  0.2213,  0.2137,  0.2639,  0.2361,
         0.2119,  0.2444,  0.1891,  0.1590,  0.1734,  0.2164,  0.2321,  0.1899,
         0.2480,  0.2127,  0.2294,  0.2010,  0.2187,  0.2018,  0.2387,  0.2366,
         0.2075,  0.2309,  0.1749,  0.2081,  0.2501])
true tensor([1.0625, 1.0375, 1.0500, 1.3000, 1.2125, 1.1625, 0.8875, 1.1250, 0.9750,
        1.0625, 1.2125, 1.1625, 1.1875, 0.8875, 1.1250, 0.9750, 1.2125, 1.0625,
        1.0375, 1.0500, 1.3000, 1.2125, 1.1875, 0.8875, 1.2125, 1.1875, 0.8875,
        1.1250, 1.1875, 0.8875, 1.1250, 0.9750, 1.0625, 1.0375, 1.0500, 1.3000,
        1.2125, 0.9750, 1.0625, 1.0375, 1.0500, 1.1250, 0.9750, 1.0625, 1.0375,
        1.3000, 1.0375, 1.0500, 1.3000, 0.9750, 1.0625, 1.0375, 1.0500, 0.9750,
        1.0625, 1.0375, 1.0500, 0.8875, 1.1250, 0.9750, 1.0625, 0.8875, 1.1250,
        0.9750, 1.0625, 1.2125, 1.0500, 1.3000, 1.2125, 1.0500, 1.3000, 1.1875,
        0.8875, 1.2125, 1.1625, 1.0375, 1.0500, 1.3000, 1.1250, 0.9750, 1.0625,
        1.0375, 1.2125, 1.1625, 1.3000, 1.1875, 0.8875, 1.1250, 1.2125, 1.1875,
        0.8875, 1.1250, 1.3000, 1.1250, 0.9750, 1.0625, 1.0375, 1.1875, 0.8875,
        1.1250, 0.9750, 1.0500, 1.3000, 1.2125, 1.0375, 1.0500, 1.3000, 1.1875,
        0.8875])
Epoch: 5, Steps: 1 | Train Loss: 0.4415935 Vali Loss: 0.7660369
lr = 0.0000500050
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
1it [00:00, 11.98it/s]
1it [00:00,  9.84it/s]
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 363) (1, 363)
test shape: (1, 1, 363) (1, 1, 363)
mae:0.7029, mse:0.5257, rmse:0.7251, r2:-15.6955
mse_mean = 0.5257, mse_std = 0.0000
r2_mean = -15.6955, mae_std = 0.0000