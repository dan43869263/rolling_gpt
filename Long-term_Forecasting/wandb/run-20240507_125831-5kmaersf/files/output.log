['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.11s/it]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.4644250869750977
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2328, 0.2290, 0.1856, 0.1425, 0.1891, 0.0679, 0.3027, 0.2209, 0.0936,
        0.1433, 0.2253, 0.2455, 0.1289, 0.1875, 0.2768, 0.2525, 0.2515, 0.2186,
        0.3056, 0.2575, 0.1922, 0.2798, 0.2416, 0.1087, 0.1810, 0.2113, 0.3121,
        0.1290, 0.2020, 0.1132, 0.1467, 0.1569, 0.1732, 0.1472, 0.2538, 0.1598,
        0.1826, 0.1893, 0.2419, 0.2792, 0.2183, 0.2398, 0.3977, 0.0964, 0.1346,
        0.1144, 0.2859, 0.2995, 0.2281, 0.1565, 0.2319, 0.1887, 0.2447, 0.1477,
        0.2842, 0.1883, 0.1999, 0.1686, 0.2190, 0.1932, 0.2172, 0.2564, 0.2729,
        0.2017, 0.2971, 0.0112, 0.3241, 0.1600, 0.2536, 0.1149, 0.2296, 0.2084,
        0.1143, 0.1823, 0.2738, 0.2663, 0.2072, 0.1353, 0.2591, 0.2667, 0.2546,
        0.0847, 0.1540, 0.1917, 0.1150, 0.1289, 0.2931, 0.2575, 0.2525, 0.1630,
        0.3635, 0.1514, 0.1661, 0.1050, 0.2492, 0.2734, 0.2301, 0.0753, 0.3362,
        0.0980, 0.2016, 0.2644, 0.2259, 0.1748, 0.1034, 0.2198, 0.2146, 0.2160,
        0.1180, 0.0917, 0.1574, 0.4536, 0.2438, 0.1787, 0.1889, 0.2155, 0.1423,
        0.3021, 0.2041, 0.2079, 0.2476, 0.1958, 0.2041, 0.2692, 0.2235, 0.2128,
        0.2154, 0.2876, 0.2240, 0.1171, 0.2010, 0.3441, 0.0574, 0.0482, 0.1602,
        0.3824, 0.2516, 0.1740, 0.2091, 0.1826, 0.3048, 0.2025, 0.3471, 0.2531,
        0.1463, 0.1233, 0.1745, 0.1386, 0.1632, 0.1087, 0.2176, 0.2811, 0.2311,
        0.2487, 0.2300, 0.1931, 0.2155, 0.0995, 0.2298, 0.1388, 0.2514, 0.2282,
        0.2263, 0.2298, 0.2361, 0.1370, 0.2851, 0.1893, 0.2112, 0.2488, 0.2117,
        0.2252])
true tensor([0.2550, 0.3250, 0.3250, 0.3300, 0.2100, 0.1650, 0.2350, 0.2250, 0.1700,
        0.2100, 0.1650, 0.2350, 0.1700, 0.1700, 0.2100, 0.1650, 0.1600, 0.1700,
        0.1700, 0.2100, 0.2500, 0.2300, 0.2600, 0.2550, 0.3250, 0.3300, 0.3400,
        0.3800, 0.3250, 0.3250, 0.3300, 0.3400, 0.1600, 0.1700, 0.1700, 0.2100,
        0.2350, 0.2250, 0.2500, 0.2300, 0.2250, 0.2500, 0.2300, 0.2600, 0.3250,
        0.3300, 0.3400, 0.3800, 0.1650, 0.2350, 0.2250, 0.2500, 0.2550, 0.3250,
        0.3250, 0.3300, 0.2600, 0.2550, 0.3250, 0.3250, 0.1700, 0.2100, 0.1650,
        0.2350, 0.3250, 0.3300, 0.3400, 0.3800, 0.2300, 0.2600, 0.2550, 0.3250,
        0.2350, 0.2250, 0.2500, 0.2300, 0.3300, 0.3400, 0.3800, 0.3650, 0.2350,
        0.2250, 0.2500, 0.2300, 0.3250, 0.3250, 0.3300, 0.3400, 0.2600, 0.2550,
        0.3250, 0.3250, 0.2100, 0.1650, 0.2350, 0.2250, 0.3250, 0.3250, 0.3300,
        0.3400, 0.1600, 0.1700, 0.1700, 0.2100, 0.2250, 0.2500, 0.2300, 0.2600,
        0.2600, 0.2550, 0.3250, 0.3250, 0.1650, 0.2350, 0.2250, 0.2500, 0.1700,
        0.1700, 0.2100, 0.1650, 0.3300, 0.3400, 0.3800, 0.3650, 0.2250, 0.2500,
        0.2300, 0.2600, 0.2500, 0.2300, 0.2600, 0.2550, 0.2550, 0.3250, 0.3250,
        0.3300, 0.2500, 0.2300, 0.2600, 0.2550, 0.2300, 0.2600, 0.2550, 0.3250,
        0.3400, 0.3800, 0.3650, 0.3700, 0.3300, 0.3400, 0.3800, 0.3650, 0.2300,
        0.2600, 0.2550, 0.3250, 0.1700, 0.2100, 0.1650, 0.2350, 0.2100, 0.1650,
        0.2350, 0.2250, 0.1700, 0.1700, 0.2100, 0.1650, 0.1650, 0.2350, 0.2250,
        0.2500])
Epoch: 1, Steps: 1 | Train Loss: 0.0542794 Vali Loss: 0.0120373
lr = 0.0000975531
Validation loss decreased (inf --> 0.012037).  Saving model ...
1it [00:00,  9.79it/s]
1it [00:00,  6.37it/s]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.6084249019622803
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2141,  0.1250,  0.1699,  0.1674,  0.0943,  0.0907,  0.2164,  0.2567,
         0.2879,  0.0641,  0.2943,  0.1805,  0.3149,  0.1197,  0.4942,  0.1182,
         0.2151,  0.2222,  0.2195,  0.2494,  0.1571,  0.1629,  0.2258,  0.0708,
         0.3771, -0.1539,  0.6848,  0.0778,  0.1521,  0.1587,  0.2463,  0.3282,
         0.2153,  0.2749,  0.1803,  0.1341,  0.2356,  0.1306,  0.2764,  0.2028,
         0.2251,  0.1644,  0.2423,  0.1233,  0.0898,  0.1876,  0.2231,  0.3321,
         0.2133,  0.1558,  0.2772,  0.1660,  0.1802,  0.2229,  0.2224,  0.2321,
         0.1892,  0.1359,  0.1849,  0.1480,  0.1072,  0.1916,  0.2239,  0.2479,
         0.1797,  0.2273,  0.2459,  0.0970,  0.1510,  0.1971,  0.2596,  0.1471,
         0.1096,  0.1770,  0.2533,  0.2570,  0.1778,  0.1046,  0.2461,  0.0988,
         0.1708,  0.1857,  0.2061,  0.2906,  0.2908,  0.0021,  0.3445,  0.1292,
         0.1893,  0.1670,  0.2743,  0.1963,  0.2189,  0.1872,  0.1916,  0.2355,
         0.0865,  0.1621,  0.2638,  0.1603,  0.1254,  0.1496,  0.1460,  0.3283,
         0.3418,  0.2065,  0.1892,  0.1231,  0.1402,  0.0031,  0.3196,  0.1531,
         0.2710,  0.0777,  0.2761,  0.1939,  0.2568,  0.2530,  0.2868,  0.2257,
         0.2262,  0.2411,  0.2511,  0.1853,  0.1375,  0.1689,  0.1336,  0.2646,
         0.0300,  0.3787,  0.1902,  0.4017,  0.1676,  0.1236,  0.2389,  0.1897,
         0.1987,  0.1768,  0.2740,  0.0832,  0.1568,  0.1859,  0.2082,  0.2993,
         0.2295,  0.1793,  0.2245,  0.1777,  0.1758,  0.3025,  0.2969,  0.1413,
         0.1810,  0.2115,  0.0960,  0.2642,  0.2043,  0.1637,  0.2202,  0.2141,
         0.1907,  0.1378,  0.2678,  0.1494,  0.1822,  0.1565,  0.1198,  0.3819,
         0.2078,  0.1529,  0.2762,  0.2557])
true tensor([0.2300, 0.2600, 0.2550, 0.3250, 0.2550, 0.3250, 0.3250, 0.3300, 0.1700,
        0.1700, 0.2100, 0.1650, 0.2500, 0.2300, 0.2600, 0.2550, 0.1700, 0.2100,
        0.1650, 0.2350, 0.3300, 0.3400, 0.3800, 0.3650, 0.2600, 0.2550, 0.3250,
        0.3250, 0.3250, 0.3250, 0.3300, 0.3400, 0.2300, 0.2600, 0.2550, 0.3250,
        0.1650, 0.2350, 0.2250, 0.2500, 0.1600, 0.1700, 0.1700, 0.2100, 0.3300,
        0.3400, 0.3800, 0.3650, 0.2100, 0.1650, 0.2350, 0.2250, 0.2100, 0.1650,
        0.2350, 0.2250, 0.1700, 0.2100, 0.1650, 0.2350, 0.2350, 0.2250, 0.2500,
        0.2300, 0.3250, 0.3250, 0.3300, 0.3400, 0.1700, 0.1700, 0.2100, 0.1650,
        0.3250, 0.3300, 0.3400, 0.3800, 0.3400, 0.3800, 0.3650, 0.3700, 0.1600,
        0.1700, 0.1700, 0.2100, 0.3250, 0.3300, 0.3400, 0.3800, 0.2250, 0.2500,
        0.2300, 0.2600, 0.3250, 0.3300, 0.3400, 0.3800, 0.2600, 0.2550, 0.3250,
        0.3250, 0.2250, 0.2500, 0.2300, 0.2600, 0.3300, 0.3400, 0.3800, 0.3650,
        0.3250, 0.3250, 0.3300, 0.3400, 0.2250, 0.2500, 0.2300, 0.2600, 0.2300,
        0.2600, 0.2550, 0.3250, 0.2350, 0.2250, 0.2500, 0.2300, 0.2550, 0.3250,
        0.3250, 0.3300, 0.2600, 0.2550, 0.3250, 0.3250, 0.1700, 0.1700, 0.2100,
        0.1650, 0.2550, 0.3250, 0.3250, 0.3300, 0.1650, 0.2350, 0.2250, 0.2500,
        0.2100, 0.1650, 0.2350, 0.2250, 0.2500, 0.2300, 0.2600, 0.2550, 0.1600,
        0.1700, 0.1700, 0.2100, 0.1700, 0.2100, 0.1650, 0.2350, 0.2350, 0.2250,
        0.2500, 0.2300, 0.2500, 0.2300, 0.2600, 0.2550, 0.1650, 0.2350, 0.2250,
        0.2500])
Epoch: 2, Steps: 1 | Train Loss: 0.0524506 Vali Loss: 0.0150652
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
1it [00:00, 10.54it/s]
1it [00:00,  5.56it/s]
1it [00:00, 10.00it/s]
1it [00:00,  5.64it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2179, 0.1589, 0.1829, 0.1252, 0.2379, 0.0483, 0.2223, 0.2272, 0.1208,
        0.2137, 0.2509, 0.0153, 0.2027, 0.0650, 0.1139, 0.1427, 0.2203, 0.1296,
        0.2567, 0.1595, 0.2782, 0.0462, 0.1959, 0.3335, 0.1602, 0.1175, 0.1639,
        0.3477, 0.1948, 0.0897, 0.2124, 0.2462, 0.2891, 0.0620, 0.3408, 0.1622,
        0.1289, 0.1607, 0.2675, 0.2018, 0.1656, 0.1347, 0.3101, 0.2646, 0.2062,
        0.2139, 0.1809, 0.2321, 0.2331, 0.1293, 0.3670, 0.1652, 0.1843, 0.2072,
        0.1985, 0.1855, 0.1704, 0.2058, 0.3017, 0.3113, 0.2167, 0.2720, 0.3157,
        0.0597, 0.2141, 0.2729, 0.0966, 0.1861, 0.1956, 0.1201, 0.0691, 0.1828,
        0.1471, 0.1105, 0.1321, 0.0955, 0.1953, 0.1518, 0.2230, 0.2012, 0.0752,
        0.2488, 0.1692, 0.3357, 0.2520, 0.3009, 0.2247, 0.1230, 0.2346, 0.0783,
        0.2239, 0.0777, 0.0678, 0.1239, 0.1424, 0.3311, 0.2022, 0.2073, 0.2216,
        0.1294, 0.2293, 0.0769, 0.2190, 0.1656, 0.1247, 0.3414, 0.2715, 0.2616,
        0.1447, 0.1262, 0.3057, 0.2729, 0.0896, 0.2157, 0.1499, 0.3133, 0.0816,
        0.2026, 0.2470, 0.2660, 0.1629, 0.2235, 0.2481, 0.2067, 0.2657, 0.1233,
        0.2699, 0.2087, 0.1668, 0.1218, 0.3047, 0.2005, 0.2526, 0.1286, 0.3503,
        0.1688, 0.2362, 0.1486, 0.2659, 0.1818, 0.2689, 0.1985, 0.2213, 0.2016,
        0.2156, 0.1066, 0.1698, 0.2432, 0.2160, 0.1059, 0.3014, 0.1673, 0.1404,
        0.1540, 0.2506, 0.2141, 0.1873, 0.1590, 0.1758, 0.2067, 0.0285, 0.2144,
        0.1518, 0.2590, 0.1822, 0.1628, 0.3069, 0.2892, 0.1631, 0.1919, 0.1818,
        0.1598])
true tensor([0.2500, 0.2300, 0.2600, 0.2550, 0.3250, 0.3250, 0.3300, 0.3400, 0.2550,
        0.3250, 0.3250, 0.3300, 0.2600, 0.2550, 0.3250, 0.3250, 0.1700, 0.2100,
        0.1650, 0.2350, 0.2600, 0.2550, 0.3250, 0.3250, 0.1650, 0.2350, 0.2250,
        0.2500, 0.1700, 0.1700, 0.2100, 0.1650, 0.2600, 0.2550, 0.3250, 0.3250,
        0.1600, 0.1700, 0.1700, 0.2100, 0.2100, 0.1650, 0.2350, 0.2250, 0.2350,
        0.2250, 0.2500, 0.2300, 0.1650, 0.2350, 0.2250, 0.2500, 0.2300, 0.2600,
        0.2550, 0.3250, 0.3250, 0.3300, 0.3400, 0.3800, 0.1700, 0.2100, 0.1650,
        0.2350, 0.3400, 0.3800, 0.3650, 0.3700, 0.3300, 0.3400, 0.3800, 0.3650,
        0.3250, 0.3300, 0.3400, 0.3800, 0.2350, 0.2250, 0.2500, 0.2300, 0.2550,
        0.3250, 0.3250, 0.3300, 0.2250, 0.2500, 0.2300, 0.2600, 0.3250, 0.3250,
        0.3300, 0.3400, 0.1700, 0.2100, 0.1650, 0.2350, 0.1650, 0.2350, 0.2250,
        0.2500, 0.2250, 0.2500, 0.2300, 0.2600, 0.3250, 0.3250, 0.3300, 0.3400,
        0.2550, 0.3250, 0.3250, 0.3300, 0.2250, 0.2500, 0.2300, 0.2600, 0.3300,
        0.3400, 0.3800, 0.3650, 0.2300, 0.2600, 0.2550, 0.3250, 0.3300, 0.3400,
        0.3800, 0.3650, 0.2350, 0.2250, 0.2500, 0.2300, 0.1700, 0.1700, 0.2100,
        0.1650, 0.2100, 0.1650, 0.2350, 0.2250, 0.2500, 0.2300, 0.2600, 0.2550,
        0.3250, 0.3300, 0.3400, 0.3800, 0.2100, 0.1650, 0.2350, 0.2250, 0.1700,
        0.1700, 0.2100, 0.1650, 0.1600, 0.1700, 0.1700, 0.2100, 0.2500, 0.2300,
        0.2600, 0.2550, 0.2300, 0.2600, 0.2550, 0.3250, 0.1600, 0.1700, 0.1700,
        0.2100])
Epoch: 3, Steps: 1 | Train Loss: 0.0527922 Vali Loss: 0.0131013
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.6279027462005615
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.1190,  0.1562,  0.1987,  0.2753,  0.2302,  0.2276,  0.2801,  0.2831,
         0.3584, -0.0210,  0.4484,  0.1241,  0.1994,  0.1858,  0.2531,  0.2536,
         0.1543,  0.2450,  0.2122,  0.2064,  0.2377,  0.1303,  0.2542,  0.1574,
         0.2305,  0.1992,  0.2752,  0.2373,  0.2159,  0.1911,  0.2647,  0.2049,
         0.1038,  0.1014,  0.2429,  0.3038,  0.1413, -0.0143,  0.3228,  0.1884,
         0.2089,  0.2055,  0.2176,  0.2490,  0.2091,  0.1918,  0.1679,  0.2295,
         0.2719,  0.1748,  0.2276,  0.1454,  0.2651,  0.1545,  0.2304,  0.1822,
         0.2248, -0.0131,  0.3036,  0.1269,  0.1789,  0.1990,  0.2214,  0.1584,
         0.2120,  0.1744,  0.1585,  0.2015,  0.2134,  0.1764,  0.1603,  0.2373,
         0.1733,  0.2566,  0.2028,  0.2525,  0.1587,  0.2584,  0.1935,  0.2117,
         0.0624,  0.1766,  0.1161,  0.2148,  0.2107,  0.1535,  0.1426,  0.2360,
         0.2987,  0.0102,  0.1681,  0.0692,  0.1786,  0.2727,  0.1954,  0.1955,
         0.0261,  0.1934,  0.1726,  0.1798,  0.1673,  0.1881,  0.2030,  0.2834,
         0.2158,  0.2109,  0.2439,  0.2819,  0.0894,  0.2315,  0.2709,  0.0509,
         0.1979,  0.1764,  0.1904,  0.2164,  0.2278,  0.2285,  0.3155,  0.1358,
         0.2561,  0.2464,  0.1674,  0.1478,  0.2482,  0.1430,  0.3133,  0.1909,
         0.1863,  0.1316,  0.1965,  0.1878,  0.0912,  0.2171,  0.3353,  0.2899,
         0.3035,  0.1218,  0.2584,  0.1289,  0.0726,  0.1846,  0.2864,  0.3173,
         0.0873,  0.3395,  0.2146,  0.2903,  0.1609,  0.1522,  0.1613,  0.2604,
         0.1837,  0.1017,  0.3973,  0.1135,  0.2540,  0.0672,  0.2047,  0.1333,
         0.1070,  0.1459,  0.2482,  0.1151,  0.2492,  0.2416,  0.1839,  0.2320,
         0.1765,  0.0881,  0.2747,  0.2911])
true tensor([0.3300, 0.3400, 0.3800, 0.3650, 0.2300, 0.2600, 0.2550, 0.3250, 0.2500,
        0.2300, 0.2600, 0.2550, 0.2350, 0.2250, 0.2500, 0.2300, 0.3400, 0.3800,
        0.3650, 0.3700, 0.2100, 0.1650, 0.2350, 0.2250, 0.2350, 0.2250, 0.2500,
        0.2300, 0.1600, 0.1700, 0.1700, 0.2100, 0.2600, 0.2550, 0.3250, 0.3250,
        0.2550, 0.3250, 0.3250, 0.3300, 0.1700, 0.1700, 0.2100, 0.1650, 0.2300,
        0.2600, 0.2550, 0.3250, 0.1650, 0.2350, 0.2250, 0.2500, 0.2250, 0.2500,
        0.2300, 0.2600, 0.3250, 0.3250, 0.3300, 0.3400, 0.2250, 0.2500, 0.2300,
        0.2600, 0.2250, 0.2500, 0.2300, 0.2600, 0.1600, 0.1700, 0.1700, 0.2100,
        0.2300, 0.2600, 0.2550, 0.3250, 0.2350, 0.2250, 0.2500, 0.2300, 0.2500,
        0.2300, 0.2600, 0.2550, 0.2600, 0.2550, 0.3250, 0.3250, 0.3300, 0.3400,
        0.3800, 0.3650, 0.2550, 0.3250, 0.3250, 0.3300, 0.2550, 0.3250, 0.3250,
        0.3300, 0.2100, 0.1650, 0.2350, 0.2250, 0.1600, 0.1700, 0.1700, 0.2100,
        0.3250, 0.3250, 0.3300, 0.3400, 0.1700, 0.2100, 0.1650, 0.2350, 0.2500,
        0.2300, 0.2600, 0.2550, 0.1700, 0.2100, 0.1650, 0.2350, 0.1700, 0.1700,
        0.2100, 0.1650, 0.1700, 0.2100, 0.1650, 0.2350, 0.1650, 0.2350, 0.2250,
        0.2500, 0.2100, 0.1650, 0.2350, 0.2250, 0.3250, 0.3300, 0.3400, 0.3800,
        0.3250, 0.3300, 0.3400, 0.3800, 0.1700, 0.1700, 0.2100, 0.1650, 0.2600,
        0.2550, 0.3250, 0.3250, 0.3250, 0.3300, 0.3400, 0.3800, 0.3300, 0.3400,
        0.3800, 0.3650, 0.1650, 0.2350, 0.2250, 0.2500, 0.3250, 0.3250, 0.3300,
        0.3400])
Epoch: 4, Steps: 1 | Train Loss: 0.0519900 Vali Loss: 0.0136640
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
1it [00:00, 10.17it/s]
1it [00:00,  8.85it/s]
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 372) (1, 372)
test shape: (1, 1, 372) (1, 1, 372)
mae:0.4738, mse:0.2675, rmse:0.5172, r2:-7.4657
mse_mean = 0.2675, mse_std = 0.0000
r2_mean = -7.4657, mae_std = 0.0000