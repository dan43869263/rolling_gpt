['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.10s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3611936569213867
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2369, 0.2070, 0.2370, 0.1679, 0.1989, 0.0757, 0.2073, 0.1756, 0.1120,
        0.2148, 0.2623, 0.2640, 0.0876, 0.2037, 0.2054, 0.2960, 0.1334, 0.1810,
        0.2407, 0.3079, 0.1335, 0.2634, 0.2683, 0.1127, 0.2355, 0.1815, 0.2641,
        0.1756, 0.2242, 0.1248, 0.1694, 0.1893, 0.2467, 0.2145, 0.1671, 0.1373,
        0.2257, 0.1438, 0.3517, 0.1810, 0.1562, 0.1759, 0.3581, 0.1760, 0.1411,
        0.0944, 0.2894, 0.3262, 0.2299, 0.1186, 0.1509, 0.1224, 0.2337, 0.1001,
        0.3477, 0.1514, 0.2185, 0.2401, 0.2569, 0.1948, 0.1895, 0.2683, 0.2908,
        0.0923, 0.3354, 0.0861, 0.2909, 0.1395, 0.2345, 0.2107, 0.1463, 0.1369,
        0.1807, 0.1772, 0.2500, 0.3216, 0.1629, 0.1357, 0.2503, 0.2191, 0.2065,
        0.2243, 0.2121, 0.2325, 0.1964, 0.2140, 0.2710, 0.2643, 0.1887, 0.1249,
        0.3055, 0.0901, 0.1205, 0.2399, 0.2903, 0.2717, 0.2416, 0.0901, 0.2594,
        0.1340, 0.2268, 0.3066, 0.2139, 0.1495, 0.1624, 0.1172, 0.1587, 0.3275,
        0.1009, 0.1963, 0.1454, 0.3717, 0.1712, 0.1306, 0.2141, 0.0572, 0.2097,
        0.2232, 0.2331, 0.2170, 0.2049, 0.2067, 0.1999, 0.2074, 0.1066, 0.0991,
        0.1836, 0.1285, 0.1078, 0.1442, 0.1947, 0.3313, 0.1224, 0.1277, 0.2000,
        0.3729, 0.2531, 0.1029, 0.3256, 0.1222, 0.2158, 0.1106, 0.2731, 0.3453,
        0.1626, 0.1806, 0.2339, 0.1435, 0.2073, 0.1474, 0.2523, 0.2197, 0.2074,
        0.1128, 0.2338, 0.1813, 0.2068, 0.1197, 0.2102, 0.1866, 0.2018, 0.1478,
        0.3008, 0.1925, 0.2300, 0.0768, 0.2726, 0.0916, 0.1044, 0.1623, 0.2196,
        0.2567])
true tensor([0.3867, 0.4000, 0.3533, 0.5267, 0.3333, 0.2333, 0.2867, 0.3667, 0.3467,
        0.3333, 0.2333, 0.2867, 0.4933, 0.3467, 0.3333, 0.2333, 0.3200, 0.4933,
        0.3467, 0.3333, 0.2800, 0.4000, 0.4067, 0.3867, 0.3533, 0.5267, 0.4600,
        0.4533, 0.4000, 0.3533, 0.5267, 0.4600, 0.3200, 0.4933, 0.3467, 0.3333,
        0.2867, 0.3667, 0.2800, 0.4000, 0.3667, 0.2800, 0.4000, 0.4067, 0.3533,
        0.5267, 0.4600, 0.4533, 0.2333, 0.2867, 0.3667, 0.2800, 0.3867, 0.4000,
        0.3533, 0.5267, 0.4067, 0.3867, 0.4000, 0.3533, 0.3467, 0.3333, 0.2333,
        0.2867, 0.3533, 0.5267, 0.4600, 0.4533, 0.4000, 0.4067, 0.3867, 0.4000,
        0.2867, 0.3667, 0.2800, 0.4000, 0.5267, 0.4600, 0.4533, 0.4267, 0.2867,
        0.3667, 0.2800, 0.4000, 0.4000, 0.3533, 0.5267, 0.4600, 0.4067, 0.3867,
        0.4000, 0.3533, 0.3333, 0.2333, 0.2867, 0.3667, 0.4000, 0.3533, 0.5267,
        0.4600, 0.3200, 0.4933, 0.3467, 0.3333, 0.3667, 0.2800, 0.4000, 0.4067,
        0.4067, 0.3867, 0.4000, 0.3533, 0.2333, 0.2867, 0.3667, 0.2800, 0.4933,
        0.3467, 0.3333, 0.2333, 0.5267, 0.4600, 0.4533, 0.4267, 0.3667, 0.2800,
        0.4000, 0.4067, 0.2800, 0.4000, 0.4067, 0.3867, 0.3867, 0.4000, 0.3533,
        0.5267, 0.2800, 0.4000, 0.4067, 0.3867, 0.4000, 0.4067, 0.3867, 0.4000,
        0.4600, 0.4533, 0.4267, 0.5000, 0.5267, 0.4600, 0.4533, 0.4267, 0.4000,
        0.4067, 0.3867, 0.4000, 0.3467, 0.3333, 0.2333, 0.2867, 0.3333, 0.2333,
        0.2867, 0.3667, 0.4933, 0.3467, 0.3333, 0.2333, 0.2333, 0.2867, 0.3667,
        0.2800])
Epoch: 1, Steps: 1 | Train Loss: 0.0398535 Vali Loss: 0.0413449
lr = 0.0000975531
1it [00:00, 11.87it/s]
1it [00:00,  6.41it/s]
1it [00:00, 11.85it/s]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.4917020797729492
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2634,  0.1219,  0.3172,  0.1811,  0.1868,  0.1116,  0.2947,  0.1949,
         0.2945,  0.0660,  0.2874,  0.1392,  0.1985,  0.1378,  0.2055,  0.1274,
         0.1715,  0.1799,  0.2735,  0.0551,  0.1362,  0.2064,  0.2533,  0.1122,
         0.1898,  0.2408,  0.2424,  0.2443,  0.1795,  0.2017,  0.2559,  0.2873,
         0.1863,  0.1675,  0.2328,  0.1116,  0.1726,  0.1956,  0.2793,  0.1301,
         0.2527,  0.1626,  0.2796,  0.1481,  0.1540,  0.1511,  0.2028,  0.3065,
         0.2882,  0.1013,  0.3029,  0.1307,  0.1379,  0.2563,  0.2665,  0.2185,
         0.2250,  0.0933,  0.3653,  0.1880,  0.1998,  0.1960,  0.2628,  0.2370,
         0.2196,  0.1551,  0.2443,  0.1164, -0.0423,  0.0615,  0.2065,  0.3075,
         0.1684,  0.2004,  0.2360,  0.2981,  0.1828,  0.1671,  0.2017,  0.1957,
         0.0895,  0.1759,  0.2217,  0.2370,  0.2608,  0.0621,  0.2538,  0.1385,
         0.1711,  0.1248,  0.1886,  0.1612,  0.2581,  0.1565,  0.2222,  0.2248,
         0.1501,  0.2203,  0.2393,  0.1450,  0.1271,  0.1917,  0.2735,  0.2337,
         0.3311,  0.1874,  0.2221,  0.1881,  0.1944,  0.0492,  0.3087,  0.1118,
         0.1325,  0.1717,  0.2308,  0.0900,  0.0153,  0.2061,  0.0958,  0.5837,
         0.3209,  0.1064,  0.3682,  0.1300,  0.0961,  0.1956,  0.1836,  0.2198,
         0.0562,  0.2430,  0.1985,  0.3719,  0.1484,  0.1345,  0.2546,  0.1097,
         0.2291,  0.2048,  0.2616,  0.1293,  0.1280,  0.1519,  0.2522,  0.2722,
         0.1753,  0.1205,  0.3148,  0.1334,  0.1551,  0.2413,  0.2266,  0.1493,
         0.1687,  0.1999,  0.1896,  0.1932,  0.1190,  0.2151,  0.2904,  0.2751,
         0.2181,  0.1898,  0.2059,  0.0983, -0.0177,  0.0937,  0.1745,  0.3351,
         0.2309,  0.1148,  0.3364,  0.2406])
true tensor([0.4000, 0.4067, 0.3867, 0.4000, 0.3867, 0.4000, 0.3533, 0.5267, 0.4933,
        0.3467, 0.3333, 0.2333, 0.2800, 0.4000, 0.4067, 0.3867, 0.3467, 0.3333,
        0.2333, 0.2867, 0.5267, 0.4600, 0.4533, 0.4267, 0.4067, 0.3867, 0.4000,
        0.3533, 0.4000, 0.3533, 0.5267, 0.4600, 0.4000, 0.4067, 0.3867, 0.4000,
        0.2333, 0.2867, 0.3667, 0.2800, 0.3200, 0.4933, 0.3467, 0.3333, 0.5267,
        0.4600, 0.4533, 0.4267, 0.3333, 0.2333, 0.2867, 0.3667, 0.3333, 0.2333,
        0.2867, 0.3667, 0.3467, 0.3333, 0.2333, 0.2867, 0.2867, 0.3667, 0.2800,
        0.4000, 0.4000, 0.3533, 0.5267, 0.4600, 0.4933, 0.3467, 0.3333, 0.2333,
        0.3533, 0.5267, 0.4600, 0.4533, 0.4600, 0.4533, 0.4267, 0.5000, 0.3200,
        0.4933, 0.3467, 0.3333, 0.3533, 0.5267, 0.4600, 0.4533, 0.3667, 0.2800,
        0.4000, 0.4067, 0.3533, 0.5267, 0.4600, 0.4533, 0.4067, 0.3867, 0.4000,
        0.3533, 0.3667, 0.2800, 0.4000, 0.4067, 0.5267, 0.4600, 0.4533, 0.4267,
        0.4000, 0.3533, 0.5267, 0.4600, 0.3667, 0.2800, 0.4000, 0.4067, 0.4000,
        0.4067, 0.3867, 0.4000, 0.2867, 0.3667, 0.2800, 0.4000, 0.3867, 0.4000,
        0.3533, 0.5267, 0.4067, 0.3867, 0.4000, 0.3533, 0.4933, 0.3467, 0.3333,
        0.2333, 0.3867, 0.4000, 0.3533, 0.5267, 0.2333, 0.2867, 0.3667, 0.2800,
        0.3333, 0.2333, 0.2867, 0.3667, 0.2800, 0.4000, 0.4067, 0.3867, 0.3200,
        0.4933, 0.3467, 0.3333, 0.3467, 0.3333, 0.2333, 0.2867, 0.2867, 0.3667,
        0.2800, 0.4000, 0.2800, 0.4000, 0.4067, 0.3867, 0.2333, 0.2867, 0.3667,
        0.2800])
Epoch: 2, Steps: 1 | Train Loss: 0.0392862 Vali Loss: 0.0453310
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.4849674701690674
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.1538, 0.2553, 0.2009, 0.0758, 0.2019, 0.1369, 0.2075, 0.1828, 0.1431,
        0.2075, 0.2605, 0.0579, 0.1794, 0.0906, 0.1466, 0.1459, 0.2070, 0.1607,
        0.2223, 0.1999, 0.1596, 0.1402, 0.2282, 0.3285, 0.0556, 0.1078, 0.2056,
        0.3267, 0.2269, 0.2090, 0.2525, 0.2103, 0.2823, 0.1742, 0.3039, 0.2319,
        0.1251, 0.1732, 0.2549, 0.2349, 0.0727, 0.3264, 0.2703, 0.1650, 0.2708,
        0.1836, 0.1686, 0.1320, 0.2010, 0.1674, 0.2230, 0.1765, 0.1913, 0.2089,
        0.2711, 0.0601, 0.2252, 0.1833, 0.2817, 0.3316, 0.1525, 0.2447, 0.1856,
        0.1742, 0.1830, 0.2555, 0.1605, 0.1594, 0.1605, 0.1566, 0.1128, 0.1868,
        0.2366, 0.0969, 0.1767, 0.1051, 0.1477, 0.1186, 0.2466, 0.3293, 0.0771,
        0.2290, 0.1905, 0.2290, 0.1768, 0.1273, 0.2420, 0.1598, 0.2125, 0.1521,
        0.2494, 0.1554, 0.1467, 0.2381, 0.2274, 0.2820, 0.1444, 0.2092, 0.3052,
        0.0743, 0.2087, 0.1577, 0.2671, 0.2197, 0.1389, 0.2854, 0.2655, 0.3153,
        0.2172, 0.1077, 0.2359, 0.1961, 0.1301, 0.0983, 0.2129, 0.3327, 0.1275,
        0.1746, 0.2087, 0.2638, 0.1900, 0.1400, 0.2148, 0.3553, 0.2650, 0.0856,
        0.3181, 0.1852, 0.1827, 0.0841, 0.3090, 0.1467, 0.2145, 0.1358, 0.3174,
        0.1089, 0.1656, 0.1678, 0.1693, 0.1958, 0.2992, 0.1690, 0.3129, 0.1509,
        0.2301, 0.1140, 0.1369, 0.1791, 0.2288, 0.0967, 0.2153, 0.1672, 0.1669,
        0.1708, 0.1714, 0.2194, 0.2321, 0.0880, 0.2966, 0.1849, 0.0810, 0.0472,
        0.2409, 0.4580, 0.1979, 0.1330, 0.2124, 0.2438, 0.1784, 0.0373, 0.2847,
        0.0574])
true tensor([0.2800, 0.4000, 0.4067, 0.3867, 0.4000, 0.3533, 0.5267, 0.4600, 0.3867,
        0.4000, 0.3533, 0.5267, 0.4067, 0.3867, 0.4000, 0.3533, 0.3467, 0.3333,
        0.2333, 0.2867, 0.4067, 0.3867, 0.4000, 0.3533, 0.2333, 0.2867, 0.3667,
        0.2800, 0.4933, 0.3467, 0.3333, 0.2333, 0.4067, 0.3867, 0.4000, 0.3533,
        0.3200, 0.4933, 0.3467, 0.3333, 0.3333, 0.2333, 0.2867, 0.3667, 0.2867,
        0.3667, 0.2800, 0.4000, 0.2333, 0.2867, 0.3667, 0.2800, 0.4000, 0.4067,
        0.3867, 0.4000, 0.3533, 0.5267, 0.4600, 0.4533, 0.3467, 0.3333, 0.2333,
        0.2867, 0.4600, 0.4533, 0.4267, 0.5000, 0.5267, 0.4600, 0.4533, 0.4267,
        0.3533, 0.5267, 0.4600, 0.4533, 0.2867, 0.3667, 0.2800, 0.4000, 0.3867,
        0.4000, 0.3533, 0.5267, 0.3667, 0.2800, 0.4000, 0.4067, 0.4000, 0.3533,
        0.5267, 0.4600, 0.3467, 0.3333, 0.2333, 0.2867, 0.2333, 0.2867, 0.3667,
        0.2800, 0.3667, 0.2800, 0.4000, 0.4067, 0.4000, 0.3533, 0.5267, 0.4600,
        0.3867, 0.4000, 0.3533, 0.5267, 0.3667, 0.2800, 0.4000, 0.4067, 0.5267,
        0.4600, 0.4533, 0.4267, 0.4000, 0.4067, 0.3867, 0.4000, 0.5267, 0.4600,
        0.4533, 0.4267, 0.2867, 0.3667, 0.2800, 0.4000, 0.4933, 0.3467, 0.3333,
        0.2333, 0.3333, 0.2333, 0.2867, 0.3667, 0.2800, 0.4000, 0.4067, 0.3867,
        0.3533, 0.5267, 0.4600, 0.4533, 0.3333, 0.2333, 0.2867, 0.3667, 0.4933,
        0.3467, 0.3333, 0.2333, 0.3200, 0.4933, 0.3467, 0.3333, 0.2800, 0.4000,
        0.4067, 0.3867, 0.4000, 0.4067, 0.3867, 0.4000, 0.3200, 0.4933, 0.3467,
        0.3333])
Epoch: 3, Steps: 1 | Train Loss: 0.0379799 Vali Loss: 0.0445356
lr = 0.0000793913
1it [00:00,  6.18it/s]
1it [00:00, 11.80it/s]
1it [00:00,  6.05it/s]
1it [00:00, 11.80it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.5022451877593994
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.1448,  0.1702,  0.1855,  0.2280,  0.1631,  0.1668,  0.1880,  0.2890,
         0.1580,  0.0570,  0.3552,  0.0774,  0.1735,  0.1565,  0.1929,  0.3148,
         0.0973,  0.2582,  0.2493,  0.1563,  0.1969,  0.1126,  0.3289,  0.1628,
         0.2512,  0.1106,  0.2390,  0.1431,  0.1146,  0.0310,  0.2740,  0.0613,
         0.1252,  0.1960,  0.1977,  0.2430,  0.2179,  0.0465,  0.3206,  0.1240,
         0.1792,  0.2155,  0.1857,  0.1212,  0.2194,  0.1494,  0.1717,  0.2294,
         0.1545,  0.2111,  0.2431,  0.1257,  0.1238,  0.1408,  0.2350,  0.1491,
         0.1957,  0.0541,  0.2859,  0.2272,  0.0774,  0.1716,  0.1751,  0.3076,
         0.2736,  0.1914,  0.2365,  0.2595,  0.0668,  0.1785,  0.1791,  0.1792,
         0.2421,  0.0930,  0.2512,  0.1080,  0.2144,  0.1589,  0.2335,  0.1588,
         0.0788,  0.1529,  0.1546,  0.2469,  0.2010,  0.1729,  0.1586,  0.1861,
         0.2417,  0.1073,  0.1795,  0.1572,  0.1437,  0.2368,  0.1988,  0.1134,
        -0.0131,  0.1774,  0.2779,  0.1576,  0.1270,  0.1634,  0.2613,  0.2824,
         0.0918,  0.2314,  0.2408,  0.2154,  0.1442,  0.1978,  0.2379,  0.0877,
         0.0951,  0.2025,  0.2462,  0.2761,  0.1877,  0.2144,  0.1851,  0.2271,
         0.2325,  0.1599,  0.2324,  0.0885,  0.1963,  0.1792,  0.2098,  0.2152,
         0.2071,  0.1747,  0.3284,  0.1883,  0.0800,  0.0673,  0.2867,  0.3091,
         0.1591,  0.2293,  0.2620,  0.1482,  0.1112,  0.1323,  0.2334,  0.3157,
         0.0822,  0.2257,  0.2635,  0.2662,  0.1277,  0.0770,  0.1406,  0.3233,
         0.2256,  0.2032,  0.2155,  0.2127,  0.2497,  0.0960,  0.1743,  0.1778,
         0.1001,  0.1973,  0.2023,  0.1575,  0.2489,  0.1192,  0.3019,  0.1894,
         0.1479,  0.0925,  0.2257,  0.2912])
true tensor([0.5267, 0.4600, 0.4533, 0.4267, 0.4000, 0.4067, 0.3867, 0.4000, 0.2800,
        0.4000, 0.4067, 0.3867, 0.2867, 0.3667, 0.2800, 0.4000, 0.4600, 0.4533,
        0.4267, 0.5000, 0.3333, 0.2333, 0.2867, 0.3667, 0.2867, 0.3667, 0.2800,
        0.4000, 0.3200, 0.4933, 0.3467, 0.3333, 0.4067, 0.3867, 0.4000, 0.3533,
        0.3867, 0.4000, 0.3533, 0.5267, 0.4933, 0.3467, 0.3333, 0.2333, 0.4000,
        0.4067, 0.3867, 0.4000, 0.2333, 0.2867, 0.3667, 0.2800, 0.3667, 0.2800,
        0.4000, 0.4067, 0.4000, 0.3533, 0.5267, 0.4600, 0.3667, 0.2800, 0.4000,
        0.4067, 0.3667, 0.2800, 0.4000, 0.4067, 0.3200, 0.4933, 0.3467, 0.3333,
        0.4000, 0.4067, 0.3867, 0.4000, 0.2867, 0.3667, 0.2800, 0.4000, 0.2800,
        0.4000, 0.4067, 0.3867, 0.4067, 0.3867, 0.4000, 0.3533, 0.5267, 0.4600,
        0.4533, 0.4267, 0.3867, 0.4000, 0.3533, 0.5267, 0.3867, 0.4000, 0.3533,
        0.5267, 0.3333, 0.2333, 0.2867, 0.3667, 0.3200, 0.4933, 0.3467, 0.3333,
        0.4000, 0.3533, 0.5267, 0.4600, 0.3467, 0.3333, 0.2333, 0.2867, 0.2800,
        0.4000, 0.4067, 0.3867, 0.3467, 0.3333, 0.2333, 0.2867, 0.4933, 0.3467,
        0.3333, 0.2333, 0.3467, 0.3333, 0.2333, 0.2867, 0.2333, 0.2867, 0.3667,
        0.2800, 0.3333, 0.2333, 0.2867, 0.3667, 0.3533, 0.5267, 0.4600, 0.4533,
        0.3533, 0.5267, 0.4600, 0.4533, 0.4933, 0.3467, 0.3333, 0.2333, 0.4067,
        0.3867, 0.4000, 0.3533, 0.3533, 0.5267, 0.4600, 0.4533, 0.5267, 0.4600,
        0.4533, 0.4267, 0.2333, 0.2867, 0.3667, 0.2800, 0.4000, 0.3533, 0.5267,
        0.4600])
Epoch: 4, Steps: 1 | Train Loss: 0.0349439 Vali Loss: 0.0473114
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 372) (1, 372)
test shape: (1, 1, 372) (1, 1, 372)
mae:0.7995, mse:0.8651, rmse:0.9301, r2:-2.8561
mse_mean = 0.8651, mse_std = 0.0000
r2_mean = -2.8561, mae_std = 0.0000
1it [00:00, 10.23it/s]