['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.10s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.372173547744751
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2186, 0.2194, 0.2258, 0.2267, 0.2118, 0.1930, 0.2082, 0.2305, 0.2118,
        0.2364, 0.2455, 0.2347, 0.2219, 0.2255, 0.2186, 0.2202, 0.2526, 0.2036,
        0.2248, 0.2521, 0.1890, 0.2330, 0.2031, 0.2230, 0.2140, 0.2558, 0.3831,
        0.2576, 0.2292, 0.2081, 0.2040, 0.2090, 0.1940, 0.2374, 0.2603, 0.2153,
        0.2291, 0.1889, 0.2335, 0.1923, 0.2045, 0.2405, 0.1813, 0.1643, 0.2368,
        0.2238, 0.1987, 0.2497, 0.1823, 0.2203, 0.2328, 0.2203, 0.2078, 0.2546,
        0.1993, 0.2142, 0.2547, 0.2059, 0.2391, 0.2184, 0.2157, 0.2273, 0.2472,
        0.2277, 0.2050, 0.2700, 0.2355, 0.1899, 0.2315, 0.2401, 0.2195, 0.2205,
        0.2124, 0.1948, 0.2085, 0.2423, 0.2436, 0.2523, 0.2313, 0.2254, 0.2427,
        0.1755, 0.2872, 0.1863, 0.2397, 0.2299, 0.2384, 0.2276, 0.2891, 0.2184,
        0.2423, 0.2644, 0.2526, 0.2391, 0.2498, 0.2371, 0.2065, 0.2081, 0.2144,
        0.2476, 0.2339, 0.1985, 0.2401, 0.2331, 0.2509, 0.2434, 0.2497, 0.1752,
        0.2228, 0.2334, 0.2398, 0.1999, 0.2156, 0.2389, 0.2509, 0.2192, 0.2507,
        0.2180, 0.2715, 0.1965, 0.3170, 0.2136, 0.1235, 0.3390, 0.2427, 0.2176,
        0.2193, 0.2379, 0.2773, 0.1949, 0.2285, 0.2102, 0.2620, 0.2268, 0.2215,
        0.1989, 0.1963, 0.2406, 0.1867, 0.2341, 0.2143, 0.2024, 0.1919, 0.2239,
        0.1258, 0.2088, 0.2906, 0.2209, 0.2063, 0.2570, 0.1665, 0.2263, 0.2465,
        0.2280, 0.2349, 0.2412, 0.2295, 0.2033, 0.2466, 0.2006, 0.2362, 0.1759,
        0.2635, 0.1713, 0.2509, 0.2445, 0.2547, 0.2179, 0.2406, 0.2029, 0.2438,
        0.2581])
true tensor([0.2700, 0.3300, 0.3800, 0.3600, 0.4400, 0.3700, 0.2700, 0.1300, 0.4400,
        0.3700, 0.2700, 0.1300, 0.3800, 0.4400, 0.3700, 0.2700, 0.3700, 0.3800,
        0.4400, 0.3700, 0.1500, 0.2900, 0.2400, 0.2700, 0.3800, 0.3600, 0.3000,
        0.3100, 0.3300, 0.3800, 0.3600, 0.3000, 0.4700, 0.3700, 0.3800, 0.4400,
        0.2700, 0.1300, 0.1500, 0.2900, 0.1300, 0.1500, 0.2900, 0.2400, 0.3600,
        0.3000, 0.3100, 0.3900, 0.3700, 0.2700, 0.1300, 0.1500, 0.2700, 0.3300,
        0.3800, 0.3600, 0.2400, 0.2700, 0.3300, 0.3800, 0.3800, 0.4400, 0.3700,
        0.2700, 0.3800, 0.3600, 0.3000, 0.3100, 0.2900, 0.2400, 0.2700, 0.3300,
        0.1300, 0.1500, 0.2900, 0.2400, 0.3600, 0.3000, 0.3100, 0.3900, 0.2700,
        0.1300, 0.1500, 0.2900, 0.3800, 0.3600, 0.3000, 0.3100, 0.2400, 0.2700,
        0.3300, 0.3800, 0.3700, 0.2700, 0.1300, 0.1500, 0.3300, 0.3800, 0.3600,
        0.3000, 0.4700, 0.3700, 0.3800, 0.4400, 0.1500, 0.2900, 0.2400, 0.2700,
        0.2700, 0.3300, 0.3800, 0.3600, 0.3700, 0.2700, 0.1300, 0.1500, 0.3700,
        0.3800, 0.4400, 0.3700, 0.3600, 0.3000, 0.3100, 0.3900, 0.1300, 0.1500,
        0.2900, 0.2400, 0.2900, 0.2400, 0.2700, 0.3300, 0.3300, 0.3800, 0.3600,
        0.3000, 0.1500, 0.2900, 0.2400, 0.2700, 0.2400, 0.2700, 0.3300, 0.3800,
        0.3000, 0.3100, 0.3900, 0.3100, 0.3000, 0.3100, 0.3900, 0.3100, 0.2900,
        0.2400, 0.2700, 0.3300, 0.3800, 0.4400, 0.3700, 0.2700, 0.4400, 0.3700,
        0.2700, 0.1300, 0.3700, 0.3800, 0.4400, 0.3700, 0.2700, 0.1300, 0.1500,
        0.2900])
Epoch: 1, Steps: 1 | Train Loss: 0.0191199 Vali Loss: 0.0140718
lr = 0.0000975531
1it [00:00, 11.83it/s]
1it [00:00,  6.22it/s]
1it [00:00, 11.71it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.4985032081604004
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2297, 0.1950, 0.2550, 0.2597, 0.2131, 0.2156, 0.2040, 0.1992, 0.2458,
        0.2255, 0.2515, 0.2100, 0.2046, 0.2122, 0.1375, 0.2101, 0.2444, 0.2061,
        0.2499, 0.2213, 0.2349, 0.4047, 0.1304, 0.2732, 0.3786, 0.2174, 0.2256,
        0.2881, 0.2468, 0.2564, 0.1635, 0.2124, 0.2406, 0.2403, 0.2446, 0.1966,
        0.2235, 0.2372, 0.2469, 0.2397, 0.2052, 0.2025, 0.2359, 0.2672, 0.2515,
        0.1692, 0.2193, 0.1705, 0.2023, 0.2063, 0.2012, 0.2127, 0.2582, 0.2245,
        0.2589, 0.2447, 0.1969, 0.2171, 0.2277, 0.2110, 0.2158, 0.2096, 0.2228,
        0.2341, 0.2264, 0.2185, 0.2115, 0.1909, 0.1960, 0.2074, 0.1878, 0.2285,
        0.2185, 0.2243, 0.1819, 0.2517, 0.2056, 0.1466, 0.2867, 0.2193, 0.2506,
        0.2178, 0.2164, 0.2441, 0.0685, 0.2731, 0.1938, 0.4179, 0.2136, 0.2150,
        0.2105, 0.2005, 0.2435, 0.2651, 0.1828, 0.2854, 0.2347, 0.2356, 0.2309,
        0.2362, 0.2192, 0.2729, 0.2370, 0.1881, 0.1530, 0.2309, 0.2036, 0.2760,
        0.2420, 0.2005, 0.2359, 0.2572, 0.2152, 0.2183, 0.2395, 0.2718, 0.2018,
        0.2054, 0.2383, 0.2202, 0.2676, 0.1960, 0.2608, 0.2355, 0.2488, 0.2370,
        0.2044, 0.2221, 0.2313, 0.2461, 0.2311, 0.2020, 0.2321, 0.2013, 0.2430,
        0.1884, 0.2085, 0.2218, 0.2064, 0.2435, 0.2500, 0.1887, 0.2223, 0.2650,
        0.2177, 0.2055, 0.2460, 0.1968, 0.2198, 0.2244, 0.1852, 0.2243, 0.2097,
        0.2189, 0.2197, 0.2309, 0.2205, 0.2385, 0.2352, 0.2472, 0.2175, 0.2007,
        0.2653, 0.2193, 0.2498, 0.2250, 0.2302, 0.2116, 0.1721, 0.2165, 0.2089,
        0.2241])
true tensor([0.2900, 0.2400, 0.2700, 0.3300, 0.2700, 0.3300, 0.3800, 0.3600, 0.3700,
        0.3800, 0.4400, 0.3700, 0.1500, 0.2900, 0.2400, 0.2700, 0.3800, 0.4400,
        0.3700, 0.2700, 0.3600, 0.3000, 0.3100, 0.3900, 0.2400, 0.2700, 0.3300,
        0.3800, 0.3800, 0.3600, 0.3000, 0.3100, 0.2900, 0.2400, 0.2700, 0.3300,
        0.3700, 0.2700, 0.1300, 0.1500, 0.4700, 0.3700, 0.3800, 0.4400, 0.3000,
        0.3100, 0.3900, 0.3100, 0.4400, 0.3700, 0.2700, 0.1300, 0.3700, 0.2700,
        0.1300, 0.1500, 0.3800, 0.4400, 0.3700, 0.2700, 0.1300, 0.1500, 0.2900,
        0.2400, 0.3300, 0.3800, 0.3600, 0.3000, 0.3800, 0.4400, 0.3700, 0.2700,
        0.3600, 0.3000, 0.3100, 0.3900, 0.3000, 0.3100, 0.3900, 0.3100, 0.3700,
        0.3800, 0.4400, 0.3700, 0.3800, 0.3600, 0.3000, 0.3100, 0.1300, 0.1500,
        0.2900, 0.2400, 0.3800, 0.3600, 0.3000, 0.3100, 0.2400, 0.2700, 0.3300,
        0.3800, 0.1500, 0.2900, 0.2400, 0.2700, 0.3600, 0.3000, 0.3100, 0.3900,
        0.3300, 0.3800, 0.3600, 0.3000, 0.1300, 0.1500, 0.2900, 0.2400, 0.2400,
        0.2700, 0.3300, 0.3800, 0.2700, 0.1300, 0.1500, 0.2900, 0.3300, 0.3800,
        0.3600, 0.3000, 0.2700, 0.3300, 0.3800, 0.3600, 0.3700, 0.3800, 0.4400,
        0.3700, 0.2700, 0.3300, 0.3800, 0.3600, 0.2700, 0.1300, 0.1500, 0.2900,
        0.4400, 0.3700, 0.2700, 0.1300, 0.1500, 0.2900, 0.2400, 0.2700, 0.4700,
        0.3700, 0.3800, 0.4400, 0.4400, 0.3700, 0.2700, 0.1300, 0.2700, 0.1300,
        0.1500, 0.2900, 0.2900, 0.2400, 0.2700, 0.3300, 0.3700, 0.2700, 0.1300,
        0.1500])
Epoch: 2, Steps: 1 | Train Loss: 0.0184583 Vali Loss: 0.0151158
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.49550676345825195
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2240, 0.2120, 0.2099, 0.2091, 0.2195, 0.2231, 0.2145, 0.2144, 0.2348,
        0.2030, 0.2286, 0.2255, 0.2323, 0.2151, 0.2137, 0.2451, 0.2113, 0.2087,
        0.2116, 0.1929, 0.2056, 0.2556, 0.1891, 0.2240, 0.0759, 0.1881, 0.2545,
        0.1597, 0.2480, 0.2025, 0.2819, 0.2181, 0.2788, 0.2006, 0.2532, 0.2457,
        0.2413, 0.2133, 0.2209, 0.2380, 0.2396, 0.2166, 0.2256, 0.2285, 0.2289,
        0.1963, 0.2917, 0.1786, 0.1889, 0.1991, 0.2275, 0.2499, 0.2405, 0.2192,
        0.2415, 0.1886, 0.2261, 0.1877, 0.2028, 0.2544, 0.2316, 0.2354, 0.2479,
        0.2006, 0.2288, 0.1617, 0.2825, 0.2350, 0.1988, 0.2233, 0.1746, 0.2291,
        0.2142, 0.2324, 0.2314, 0.2295, 0.2065, 0.2269, 0.2366, 0.2366, 0.2461,
        0.2345, 0.2582, 0.1771, 0.2064, 0.2169, 0.2326, 0.2469, 0.2131, 0.2236,
        0.2350, 0.2459, 0.1988, 0.2379, 0.2775, 0.2098, 0.2047, 0.2183, 0.2281,
        0.2273, 0.2228, 0.2101, 0.1945, 0.2159, 0.2480, 0.2154, 0.2254, 0.2097,
        0.1841, 0.2604, 0.1511, 0.2134, 0.2137, 0.2607, 0.2289, 0.2041, 0.2231,
        0.2341, 0.2144, 0.2152, 0.2416, 0.2182, 0.1849, 0.2487, 0.2625, 0.2421,
        0.2565, 0.2242, 0.2421, 0.2175, 0.2441, 0.1967, 0.2361, 0.2143, 0.2398,
        0.2448, 0.2209, 0.2100, 0.2258, 0.2134, 0.1862, 0.2211, 0.1903, 0.2234,
        0.2177, 0.3265, 0.0603, 0.3334, 0.2124, 0.1761, 0.1937, 0.2020, 0.1916,
        0.2299, 0.2155, 0.2264, 0.1770, 0.2333, 0.1793, 0.2290, 0.2789, 0.2182,
        0.1826, 0.2131, 0.3018, 0.1730, 0.2568, 0.2584, 0.2075, 0.2318, 0.2632,
        0.2443])
true tensor([0.1500, 0.2900, 0.2400, 0.2700, 0.3300, 0.3800, 0.3600, 0.3000, 0.2700,
        0.3300, 0.3800, 0.3600, 0.2400, 0.2700, 0.3300, 0.3800, 0.3800, 0.4400,
        0.3700, 0.2700, 0.2700, 0.3300, 0.3800, 0.3600, 0.2700, 0.1300, 0.1500,
        0.2900, 0.3700, 0.3800, 0.4400, 0.3700, 0.2400, 0.2700, 0.3300, 0.3800,
        0.3700, 0.3800, 0.4400, 0.3700, 0.3700, 0.2700, 0.1300, 0.1500, 0.2700,
        0.1300, 0.1500, 0.2900, 0.3700, 0.2700, 0.1300, 0.1500, 0.2900, 0.2400,
        0.2700, 0.3300, 0.3600, 0.3000, 0.3100, 0.3900, 0.3800, 0.4400, 0.3700,
        0.2700, 0.3000, 0.3100, 0.3900, 0.3100, 0.3600, 0.3000, 0.3100, 0.3900,
        0.3800, 0.3600, 0.3000, 0.3100, 0.1300, 0.1500, 0.2900, 0.2400, 0.3300,
        0.3800, 0.3600, 0.3000, 0.1300, 0.1500, 0.2900, 0.2400, 0.3300, 0.3800,
        0.3600, 0.3000, 0.4400, 0.3700, 0.2700, 0.1300, 0.3700, 0.2700, 0.1300,
        0.1500, 0.1300, 0.1500, 0.2900, 0.2400, 0.3800, 0.3600, 0.3000, 0.3100,
        0.2700, 0.3300, 0.3800, 0.3600, 0.1500, 0.2900, 0.2400, 0.2700, 0.3000,
        0.3100, 0.3900, 0.3100, 0.2400, 0.2700, 0.3300, 0.3800, 0.3600, 0.3000,
        0.3100, 0.3900, 0.2700, 0.1300, 0.1500, 0.2900, 0.3700, 0.3800, 0.4400,
        0.3700, 0.4400, 0.3700, 0.2700, 0.1300, 0.1500, 0.2900, 0.2400, 0.2700,
        0.3800, 0.3600, 0.3000, 0.3100, 0.4400, 0.3700, 0.2700, 0.1300, 0.3800,
        0.4400, 0.3700, 0.2700, 0.4700, 0.3700, 0.3800, 0.4400, 0.2900, 0.2400,
        0.2700, 0.3300, 0.2900, 0.2400, 0.2700, 0.3300, 0.4700, 0.3700, 0.3800,
        0.4400])
Epoch: 3, Steps: 1 | Train Loss: 0.0178927 Vali Loss: 0.0149763
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
1it [00:00,  6.09it/s]
1it [00:00, 11.74it/s]
1it [00:00,  6.14it/s]
1it [00:00, 12.47it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.4903113842010498
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2136, 0.2090, 0.2289, 0.2318, 0.2775, 0.2068, 0.2107, 0.2567, 0.0851,
        0.1372, 0.1131, 0.3506, 0.2106, 0.2170, 0.2228, 0.2214, 0.1880, 0.1440,
        0.3397, 0.1715, 0.1987, 0.1867, 0.1875, 0.2410, 0.2433, 0.1925, 0.2484,
        0.2269, 0.2008, 0.2165, 0.2058, 0.2232, 0.1988, 0.2419, 0.2254, 0.2344,
        0.1991, 0.2190, 0.2424, 0.2018, 0.2422, 0.2341, 0.2604, 0.2260, 0.2304,
        0.2406, 0.2270, 0.2082, 0.2119, 0.2166, 0.2429, 0.2370, 0.2100, 0.2245,
        0.2353, 0.2533, 0.2382, 0.1981, 0.2356, 0.2667, 0.2316, 0.2645, 0.2408,
        0.1963, 0.2220, 0.2334, 0.1971, 0.2160, 0.2255, 0.2078, 0.2259, 0.2271,
        0.2407, 0.1932, 0.2495, 0.2288, 0.2253, 0.1574, 0.3037, 0.2062, 0.2815,
        0.2034, 0.2523, 0.1999, 0.2168, 0.2260, 0.2234, 0.2361, 0.2374, 0.3345,
        0.2304, 0.1787, 0.2039, 0.2785, 0.2495, 0.2579, 0.2412, 0.2765, 0.2288,
        0.1765, 0.2079, 0.1909, 0.2224, 0.2270, 0.2350, 0.2163, 0.2344, 0.2411,
        0.2219, 0.2163, 0.1992, 0.1981, 0.1844, 0.2447, 0.2310, 0.2237, 0.2303,
        0.2014, 0.2105, 0.2270, 0.2176, 0.2188, 0.2875, 0.1949, 0.2763, 0.2130,
        0.2542, 0.2085, 0.2391, 0.2179, 0.2219, 0.1894, 0.2412, 0.1997, 0.2127,
        0.2582, 0.2268, 0.1922, 0.2384, 0.2065, 0.1983, 0.2447, 0.1401, 0.2986,
        0.2140, 0.2623, 0.2367, 0.2422, 0.2040, 0.1970, 0.2212, 0.2389, 0.2516,
        0.2286, 0.2571, 0.2545, 0.1453, 0.2020, 0.3685, 0.2725, 0.1946, 0.2379,
        0.2257, 0.2439, 0.1642, 0.1896, 0.1983, 0.2249, 0.2471, 0.2157, 0.2432,
        0.2189])
true tensor([0.3000, 0.3100, 0.3900, 0.3100, 0.2400, 0.2700, 0.3300, 0.3800, 0.1500,
        0.2900, 0.2400, 0.2700, 0.1300, 0.1500, 0.2900, 0.2400, 0.3000, 0.3100,
        0.3900, 0.3100, 0.4400, 0.3700, 0.2700, 0.1300, 0.2700, 0.1300, 0.1500,
        0.2900, 0.4700, 0.3700, 0.3800, 0.4400, 0.2700, 0.3300, 0.3800, 0.3600,
        0.2700, 0.3300, 0.3800, 0.3600, 0.3700, 0.3800, 0.4400, 0.3700, 0.2900,
        0.2400, 0.2700, 0.3300, 0.3700, 0.2700, 0.1300, 0.1500, 0.1300, 0.1500,
        0.2900, 0.2400, 0.3300, 0.3800, 0.3600, 0.3000, 0.1500, 0.2900, 0.2400,
        0.2700, 0.1300, 0.1500, 0.2900, 0.2400, 0.4700, 0.3700, 0.3800, 0.4400,
        0.2900, 0.2400, 0.2700, 0.3300, 0.2700, 0.1300, 0.1500, 0.2900, 0.2900,
        0.2400, 0.2700, 0.3300, 0.2400, 0.2700, 0.3300, 0.3800, 0.3600, 0.3000,
        0.3100, 0.3900, 0.2700, 0.3300, 0.3800, 0.3600, 0.3300, 0.3800, 0.3600,
        0.3000, 0.3700, 0.2700, 0.1300, 0.1500, 0.3700, 0.3800, 0.4400, 0.3700,
        0.3300, 0.3800, 0.3600, 0.3000, 0.4400, 0.3700, 0.2700, 0.1300, 0.1500,
        0.2900, 0.2400, 0.2700, 0.3800, 0.4400, 0.3700, 0.2700, 0.3700, 0.3800,
        0.4400, 0.3700, 0.3800, 0.4400, 0.3700, 0.2700, 0.2700, 0.1300, 0.1500,
        0.2900, 0.4400, 0.3700, 0.2700, 0.1300, 0.3600, 0.3000, 0.3100, 0.3900,
        0.3800, 0.3600, 0.3000, 0.3100, 0.3800, 0.4400, 0.3700, 0.2700, 0.2400,
        0.2700, 0.3300, 0.3800, 0.3800, 0.3600, 0.3000, 0.3100, 0.3600, 0.3000,
        0.3100, 0.3900, 0.3700, 0.2700, 0.1300, 0.1500, 0.3800, 0.3600, 0.3000,
        0.3100])
Epoch: 4, Steps: 1 | Train Loss: 0.0189161 Vali Loss: 0.0146664
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 364) (1, 364)
test shape: (1, 1, 364) (1, 1, 364)
mae:0.1092, mse:0.0162, rmse:0.1273, r2:-1.9273
mse_mean = 0.0162, mse_std = 0.0000
r2_mean = -1.9273, mae_std = 0.0000
1it [00:00,  9.48it/s]