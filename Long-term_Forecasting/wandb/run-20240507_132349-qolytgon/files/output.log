['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.11s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3786900043487549
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2308, 0.2084, 0.2443, 0.2265, 0.2008, 0.2467, 0.2198, 0.2422, 0.2448,
        0.2346, 0.2302, 0.2008, 0.2322, 0.2488, 0.2547, 0.1825, 0.2062, 0.2257,
        0.2555, 0.2129, 0.1963, 0.2192, 0.2399, 0.1855, 0.2186, 0.2063, 0.2345,
        0.2147, 0.2352, 0.1773, 0.2273, 0.2097, 0.0078, 0.4076, 0.0701, 0.3503,
        0.2468, 0.2463, 0.2716, 0.1868, 0.1907, 0.2518, 0.1908, 0.1762, 0.2322,
        0.1957, 0.2338, 0.2314, 0.2628, 0.2271, 0.2900, 0.2348, 0.2028, 0.2741,
        0.2075, 0.1915, 0.2511, 0.2101, 0.2446, 0.2162, 0.2233, 0.2643, 0.1777,
        0.2702, 0.1626, 0.2025, 0.2454, 0.2271, 0.2099, 0.2247, 0.2123, 0.2314,
        0.2243, 0.2145, 0.2369, 0.2320, 0.2191, 0.2398, 0.2528, 0.2338, 0.2486,
        0.1833, 0.2400, 0.2266, 0.2390, 0.2365, 0.2444, 0.2061, 0.2946, 0.2008,
        0.2711, 0.2750, 0.2719, 0.1872, 0.2167, 0.2101, 0.1968, 0.2043, 0.2087,
        0.2307, 0.2502, 0.1753, 0.2638, 0.1954, 0.2311, 0.2346, 0.2639, 0.1521,
        0.2009, 0.1996, 0.2060, 0.2338, 0.2194, 0.2337, 0.2713, 0.2182, 0.2220,
        0.2007, 0.2642, 0.2341, 0.2408, 0.1905, 0.2323, 0.1925, 0.2288, 0.2179,
        0.2347, 0.2313, 0.2683, 0.2063, 0.2132, 0.2136, 0.2263, 0.2528, 0.2224,
        0.2303, 0.1855, 0.2233, 0.2076, 0.2521, 0.2520, 0.2087, 0.1893, 0.2426,
        0.2026, 0.2630, 0.2568, 0.1804, 0.1912, 0.2382, 0.1807, 0.2295, 0.2403,
        0.2257, 0.2310, 0.2598, 0.1899, 0.1907, 0.1907, 0.2260, 0.2018, 0.2296,
        0.2162, 0.2212, 0.2441, 0.2386, 0.2269, 0.2221, 0.1986, 0.2277, 0.2330,
        0.2283])
true tensor([ 0.2200,  0.2700,  0.3800,  0.4000,  0.0400,  0.1200,  0.0400, -0.0300,
         0.0400,  0.1200,  0.0400, -0.0300,  0.1100,  0.0400,  0.1200,  0.0400,
         0.1300,  0.1100,  0.0400,  0.1200,  0.1300,  0.1400,  0.2600,  0.2200,
         0.3800,  0.4000,  0.3300,  0.4200,  0.2700,  0.3800,  0.4000,  0.3300,
         0.1700,  0.1300,  0.1100,  0.0400,  0.0400, -0.0300,  0.1300,  0.1400,
        -0.0300,  0.1300,  0.1400,  0.2600,  0.4000,  0.3300,  0.4200,  0.4800,
         0.1200,  0.0400, -0.0300,  0.1300,  0.2200,  0.2700,  0.3800,  0.4000,
         0.2600,  0.2200,  0.2700,  0.3800,  0.1100,  0.0400,  0.1200,  0.0400,
         0.3800,  0.4000,  0.3300,  0.4200,  0.1400,  0.2600,  0.2200,  0.2700,
        -0.0300,  0.1300,  0.1400,  0.2600,  0.4000,  0.3300,  0.4200,  0.4800,
         0.0400, -0.0300,  0.1300,  0.1400,  0.3800,  0.4000,  0.3300,  0.4200,
         0.2600,  0.2200,  0.2700,  0.3800,  0.1200,  0.0400, -0.0300,  0.1300,
         0.2700,  0.3800,  0.4000,  0.3300,  0.1700,  0.1300,  0.1100,  0.0400,
         0.1300,  0.1400,  0.2600,  0.2200,  0.2200,  0.2700,  0.3800,  0.4000,
         0.1200,  0.0400, -0.0300,  0.1300,  0.1300,  0.1100,  0.0400,  0.1200,
         0.4000,  0.3300,  0.4200,  0.4800, -0.0300,  0.1300,  0.1400,  0.2600,
         0.1400,  0.2600,  0.2200,  0.2700,  0.2700,  0.3800,  0.4000,  0.3300,
         0.1300,  0.1400,  0.2600,  0.2200,  0.2600,  0.2200,  0.2700,  0.3800,
         0.3300,  0.4200,  0.4800,  0.3700,  0.3300,  0.4200,  0.4800,  0.3700,
         0.1400,  0.2600,  0.2200,  0.2700,  0.1100,  0.0400,  0.1200,  0.0400,
         0.0400,  0.1200,  0.0400, -0.0300,  0.1300,  0.1100,  0.0400,  0.1200,
         0.0400, -0.0300,  0.1300,  0.1400])
Epoch: 1, Steps: 1 | Train Loss: 0.0515282 Vali Loss: 0.0224824
lr = 0.0000975531
1it [00:00, 11.83it/s]
1it [00:00,  6.15it/s]
1it [00:00, 10.66it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5078067779541016
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2436, 0.2163, 0.2688, 0.2603, 0.1923, 0.2512, 0.2264, 0.1833, 0.2114,
        0.2361, 0.2197, 0.2222, 0.1688, 0.1671, 0.1392, 0.2344, 0.2278, 0.2342,
        0.2121, 0.2366, 0.2473, 0.2139, 0.2356, 0.2192, 0.2587, 0.2913, 0.3016,
        0.2292, 0.2484, 0.2253, 0.2260, 0.2103, 0.2291, 0.2327, 0.2090, 0.2128,
        0.2460, 0.2323, 0.2691, 0.2293, 0.0985, 0.1525, 0.1741, 0.2538, 0.2330,
        0.2083, 0.2361, 0.2274, 0.1909, 0.2326, 0.2128, 0.2612, 0.2599, 0.1776,
        0.2211, 0.2462, 0.1970, 0.2397, 0.2206, 0.2196, 0.2282, 0.2425, 0.2407,
        0.1979, 0.2505, 0.1914, 0.2578, 0.1835, 0.2100, 0.2351, 0.2241, 0.1899,
        0.2451, 0.2313, 0.2106, 0.2409, 0.2242, 0.2176, 0.2311, 0.1913, 0.2503,
        0.2182, 0.2353, 0.2135, 0.2167, 0.1969, 0.2327, 0.2372, 0.2185, 0.2142,
        0.2043, 0.1812, 0.2368, 0.1794, 0.2477, 0.2048, 0.2383, 0.2142, 0.2505,
        0.1955, 0.2208, 0.2515, 0.2407, 0.1864, 0.2286, 0.2423, 0.2388, 0.2384,
        0.2203, 0.1930, 0.2347, 0.2270, 0.2478, 0.1992, 0.2179, 0.2260, 0.1275,
        0.2724, 0.2968, 0.1759, 0.2509, 0.2218, 0.2644, 0.2395, 0.1991, 0.2699,
        0.2059, 0.2155, 0.1920, 0.2533, 0.1900, 0.2260, 0.2355, 0.1941, 0.2482,
        0.2146, 0.2169, 0.1983, 0.2135, 0.2275, 0.1867, 0.2155, 0.1909, 0.2613,
        0.2116, 0.2276, 0.1998, 0.2301, 0.2178, 0.2212, 0.1951, 0.1926, 0.2457,
        0.1920, 0.2451, 0.1866, 0.2166, 0.2419, 0.2423, 0.2171, 0.2045, 0.1996,
        0.2162, 0.2585, 0.2240, 0.2238, 0.2104, 0.2074, 0.2459, 0.2535, 0.2749,
        0.2450])
true tensor([ 0.1400,  0.2600,  0.2200,  0.2700,  0.2200,  0.2700,  0.3800,  0.4000,
         0.1300,  0.1100,  0.0400,  0.1200,  0.1300,  0.1400,  0.2600,  0.2200,
         0.1100,  0.0400,  0.1200,  0.0400,  0.4000,  0.3300,  0.4200,  0.4800,
         0.2600,  0.2200,  0.2700,  0.3800,  0.3800,  0.4000,  0.3300,  0.4200,
         0.1400,  0.2600,  0.2200,  0.2700,  0.1200,  0.0400, -0.0300,  0.1300,
         0.1700,  0.1300,  0.1100,  0.0400,  0.3300,  0.4200,  0.4800,  0.3700,
         0.0400,  0.1200,  0.0400, -0.0300,  0.1200,  0.0400, -0.0300,  0.1300,
         0.1100,  0.0400,  0.1200,  0.0400, -0.0300,  0.1300,  0.1400,  0.2600,
         0.2700,  0.3800,  0.4000,  0.3300,  0.1100,  0.0400,  0.1200,  0.0400,
         0.4000,  0.3300,  0.4200,  0.4800,  0.3300,  0.4200,  0.4800,  0.3700,
         0.1300,  0.1100,  0.0400,  0.1200,  0.3800,  0.4000,  0.3300,  0.4200,
        -0.0300,  0.1300,  0.1400,  0.2600,  0.3800,  0.4000,  0.3300,  0.4200,
         0.2600,  0.2200,  0.2700,  0.3800,  0.1300,  0.1400,  0.2600,  0.2200,
         0.4000,  0.3300,  0.4200,  0.4800,  0.2700,  0.3800,  0.4000,  0.3300,
        -0.0300,  0.1300,  0.1400,  0.2600,  0.2600,  0.2200,  0.2700,  0.3800,
         0.0400, -0.0300,  0.1300,  0.1400,  0.2700,  0.3800,  0.4000,  0.3300,
         0.2200,  0.2700,  0.3800,  0.4000,  0.1300,  0.1100,  0.0400,  0.1200,
         0.2200,  0.2700,  0.3800,  0.4000,  0.0400, -0.0300,  0.1300,  0.1400,
         0.0400,  0.1200,  0.0400, -0.0300,  0.1300,  0.1400,  0.2600,  0.2200,
         0.1700,  0.1300,  0.1100,  0.0400,  0.0400,  0.1200,  0.0400, -0.0300,
         0.0400, -0.0300,  0.1300,  0.1400,  0.1400,  0.2600,  0.2200,  0.2700,
         0.1200,  0.0400, -0.0300,  0.1300])
Epoch: 2, Steps: 1 | Train Loss: 0.0515472 Vali Loss: 0.0215962
lr = 0.0000904518
Validation loss decreased (0.022482 --> 0.021596).  Saving model ...
1it [00:00,  5.88it/s]
1it [00:00, 11.53it/s]
1it [00:00,  6.24it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5060856342315674
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2210, 0.2095, 0.2454, 0.2002, 0.2538, 0.2034, 0.2841, 0.2202, 0.2539,
        0.2034, 0.2270, 0.2172, 0.2299, 0.2286, 0.2318, 0.2188, 0.1972, 0.2098,
        0.1896, 0.2207, 0.2043, 0.2367, 0.1611, 0.2412, 0.2021, 0.2199, 0.2153,
        0.2324, 0.2537, 0.1897, 0.2776, 0.2106, 0.2356, 0.2254, 0.2588, 0.2382,
        0.2279, 0.2286, 0.2467, 0.2182, 0.2812, 0.2237, 0.1974, 0.2367, 0.2426,
        0.2025, 0.2501, 0.2255, 0.2669, 0.2206, 0.2771, 0.2563, 0.2285, 0.2073,
        0.2333, 0.2211, 0.2309, 0.2098, 0.2243, 0.2523, 0.2169, 0.3038, 0.1167,
        0.2683, 0.2206, 0.1923, 0.2680, 0.2066, 0.2459, 0.1883, 0.2235, 0.1963,
        0.2061, 0.2142, 0.2538, 0.1910, 0.2161, 0.2434, 0.2314, 0.2096, 0.2130,
        0.2439, 0.2337, 0.2122, 0.2319, 0.2034, 0.2240, 0.2101, 0.1895, 0.2101,
        0.2383, 0.2175, 0.2408, 0.2285, 0.2321, 0.2039, 0.2351, 0.2278, 0.2279,
        0.2555, 0.2177, 0.1852, 0.1784, 0.1803, 0.2534, 0.2179, 0.2219, 0.1851,
        0.2153, 0.2671, 0.2294, 0.2230, 0.2394, 0.2347, 0.2460, 0.1875, 0.2298,
        0.1997, 0.2317, 0.2186, 0.1874, 0.2041, 0.1306, 0.2625, 0.2448, 0.2251,
        0.2753, 0.2293, 0.2675, 0.2280, 0.2754, 0.2188, 0.2045, 0.2059, 0.2127,
        0.2445, 0.2217, 0.2385, 0.2273, 0.2328, 0.1517, 0.2130, 0.1898, 0.2588,
        0.1933, 0.1987, 0.2503, 0.2366, 0.2072, 0.2216, 0.2391, 0.2378, 0.2121,
        0.2442, 0.2397, 0.2128, 0.2326, 0.2209, 0.2260, 0.2203, 0.2491, 0.1973,
        0.1667, 0.2124, 0.3072, 0.1970, 0.2904, 0.2712, 0.2365, 0.1935, 0.2929,
        0.2030])
true tensor([ 0.1300,  0.1400,  0.2600,  0.2200,  0.2700,  0.3800,  0.4000,  0.3300,
         0.2200,  0.2700,  0.3800,  0.4000,  0.2600,  0.2200,  0.2700,  0.3800,
         0.1100,  0.0400,  0.1200,  0.0400,  0.2200,  0.2700,  0.3800,  0.4000,
         0.0400, -0.0300,  0.1300,  0.1400,  0.1300,  0.1100,  0.0400,  0.1200,
         0.2600,  0.2200,  0.2700,  0.3800,  0.1300,  0.1100,  0.0400,  0.1200,
         0.1200,  0.0400, -0.0300,  0.1300,  0.0400, -0.0300,  0.1300,  0.1400,
         0.1200,  0.0400, -0.0300,  0.1300,  0.1400,  0.2600,  0.2200,  0.2700,
         0.4000,  0.3300,  0.4200,  0.4800,  0.1100,  0.0400,  0.1200,  0.0400,
         0.3300,  0.4200,  0.4800,  0.3700,  0.4000,  0.3300,  0.4200,  0.4800,
         0.3800,  0.4000,  0.3300,  0.4200, -0.0300,  0.1300,  0.1400,  0.2600,
         0.2700,  0.3800,  0.4000,  0.3300, -0.0300,  0.1300,  0.1400,  0.2600,
         0.2700,  0.3800,  0.4000,  0.3300,  0.0400,  0.1200,  0.0400, -0.0300,
         0.1200,  0.0400, -0.0300,  0.1300, -0.0300,  0.1300,  0.1400,  0.2600,
         0.3800,  0.4000,  0.3300,  0.4200,  0.2200,  0.2700,  0.3800,  0.4000,
         0.1300,  0.1400,  0.2600,  0.2200,  0.3300,  0.4200,  0.4800,  0.3700,
         0.2600,  0.2200,  0.2700,  0.3800,  0.4000,  0.3300,  0.4200,  0.4800,
         0.0400, -0.0300,  0.1300,  0.1400,  0.1300,  0.1100,  0.0400,  0.1200,
         0.0400,  0.1200,  0.0400, -0.0300,  0.1300,  0.1400,  0.2600,  0.2200,
         0.3800,  0.4000,  0.3300,  0.4200,  0.0400,  0.1200,  0.0400, -0.0300,
         0.1100,  0.0400,  0.1200,  0.0400,  0.1700,  0.1300,  0.1100,  0.0400,
         0.1400,  0.2600,  0.2200,  0.2700,  0.1400,  0.2600,  0.2200,  0.2700,
         0.1700,  0.1300,  0.1100,  0.0400])
Epoch: 3, Steps: 1 | Train Loss: 0.0507540 Vali Loss: 0.0218827
lr = 0.0000793913
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.49092984199523926
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2329,  0.1837,  0.3104,  0.1868,  0.2873,  0.2147,  0.2203,  0.2605,
         0.1600,  0.1768,  0.1825,  0.2611,  0.2177,  0.2285,  0.2257,  0.1860,
         0.2170,  0.1890,  0.2683,  0.2144,  0.1988,  0.2534,  0.0086,  0.4385,
         0.2384,  0.2169,  0.2458,  0.2366,  0.2298,  0.2069,  0.2289,  0.2116,
         0.1853,  0.2367,  0.1934,  0.2215,  0.2200,  0.2460,  0.2366,  0.2052,
         0.2512,  0.2285,  0.2429,  0.2264,  0.2196,  0.1949,  0.2170,  0.2198,
         0.2383,  0.2345,  0.2473,  0.2474,  0.2242,  0.2196,  0.2342,  0.2320,
         0.2150,  0.2143,  0.2254,  0.2490,  0.2257,  0.2578,  0.2450,  0.1702,
         0.1944,  0.2606,  0.2066,  0.2033,  0.2337,  0.1731,  0.2548,  0.1780,
         0.1196,  0.2162,  0.3654,  0.2373,  0.2319,  0.1946,  0.2193,  0.2430,
         0.2613,  0.2636,  0.2353,  0.2225,  0.2111,  0.2363,  0.2374,  0.2288,
        -0.0354,  0.0907,  0.2506,  0.1112,  0.2178,  0.2517,  0.2004,  0.3047,
         0.2015,  0.2647,  0.2101,  0.2125,  0.2214,  0.1585,  0.1837,  0.2443,
         0.2438,  0.2272,  0.2566,  0.2387,  0.2232,  0.2168,  0.2461,  0.2042,
         0.2307,  0.2438,  0.2282,  0.1844,  0.2340,  0.2088,  0.2322,  0.2030,
         0.2329,  0.2437,  0.2315,  0.2348,  0.2159,  0.2124,  0.2184,  0.2161,
         0.2070,  0.2228,  0.1915,  0.2213,  0.1862,  0.2373,  0.2081,  0.2428,
         0.2436,  0.2146,  0.2324,  0.2526,  0.2404,  0.2023,  0.2522,  0.2525,
         0.2140,  0.2153,  0.2351,  0.2371,  0.2154,  0.2392,  0.2583,  0.2112,
         0.2445,  0.2520,  0.2691,  0.2572,  0.1921,  0.2060,  0.2288,  0.2184,
         0.2206,  0.2054,  0.2507,  0.2034,  0.2778,  0.2369,  0.2824,  0.2120,
         0.2358,  0.2300,  0.2399,  0.1963])
true tensor([ 0.3300,  0.4200,  0.4800,  0.3700,  0.2600,  0.2200,  0.2700,  0.3800,
         0.1300,  0.1400,  0.2600,  0.2200, -0.0300,  0.1300,  0.1400,  0.2600,
         0.3300,  0.4200,  0.4800,  0.3700,  0.0400,  0.1200,  0.0400, -0.0300,
         0.0400, -0.0300,  0.1300,  0.1400,  0.1700,  0.1300,  0.1100,  0.0400,
         0.2200,  0.2700,  0.3800,  0.4000,  0.2200,  0.2700,  0.3800,  0.4000,
         0.1300,  0.1100,  0.0400,  0.1200,  0.1400,  0.2600,  0.2200,  0.2700,
         0.1200,  0.0400, -0.0300,  0.1300, -0.0300,  0.1300,  0.1400,  0.2600,
         0.2700,  0.3800,  0.4000,  0.3300,  0.1300,  0.1400,  0.2600,  0.2200,
        -0.0300,  0.1300,  0.1400,  0.2600,  0.1700,  0.1300,  0.1100,  0.0400,
         0.1400,  0.2600,  0.2200,  0.2700,  0.0400, -0.0300,  0.1300,  0.1400,
         0.1400,  0.2600,  0.2200,  0.2700,  0.2600,  0.2200,  0.2700,  0.3800,
         0.4000,  0.3300,  0.4200,  0.4800,  0.2200,  0.2700,  0.3800,  0.4000,
         0.2700,  0.3800,  0.4000,  0.3300,  0.1200,  0.0400, -0.0300,  0.1300,
         0.1300,  0.1100,  0.0400,  0.1200,  0.2700,  0.3800,  0.4000,  0.3300,
         0.0400,  0.1200,  0.0400, -0.0300,  0.1300,  0.1400,  0.2600,  0.2200,
         0.1100,  0.0400,  0.1200,  0.0400,  0.1300,  0.1100,  0.0400,  0.1200,
         0.1100,  0.0400,  0.1200,  0.0400,  0.0400, -0.0300,  0.1300,  0.1400,
         0.0400,  0.1200,  0.0400, -0.0300,  0.4000,  0.3300,  0.4200,  0.4800,
         0.3800,  0.4000,  0.3300,  0.4200,  0.1100,  0.0400,  0.1200,  0.0400,
         0.2600,  0.2200,  0.2700,  0.3800,  0.3800,  0.4000,  0.3300,  0.4200,
         0.4000,  0.3300,  0.4200,  0.4800,  0.1200,  0.0400, -0.0300,  0.1300,
         0.3800,  0.4000,  0.3300,  0.4200])
Epoch: 4, Steps: 1 | Train Loss: 0.0511644 Vali Loss: 0.0231204
lr = 0.0000654543
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
1it [00:00, 11.52it/s]
1it [00:00,  6.01it/s]
1it [00:00, 11.25it/s]
1it [00:00, 10.52it/s]
Epoch: 5 cost time: 0.5003607273101807
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2196,  0.2279,  0.2183,  0.2027,  0.2391,  0.2181,  0.2306,  0.1996,
         0.2174,  0.2147,  0.1871,  0.2650,  0.2426,  0.2234,  0.2598,  0.2414,
         0.2339,  0.1927,  0.2364,  0.1896,  0.2221,  0.2735,  0.1497,  0.2407,
         0.2338,  0.2275,  0.2309,  0.2360,  0.2248,  0.1925,  0.2370,  0.2011,
         0.2071,  0.2246,  0.2249,  0.2483,  0.2182,  0.2381,  0.2446,  0.2074,
         0.2423,  0.2581,  0.2451,  0.2303,  0.2192,  0.2366,  0.2112,  0.2170,
         0.2657,  0.2326,  0.2231,  0.2048,  0.2040,  0.2420,  0.1931,  0.1536,
         0.2328,  0.1794,  0.2358,  0.1928,  0.2535,  0.2230,  0.2449,  0.2201,
         0.1950,  0.2436,  0.2104,  0.2304,  0.1872,  0.2327,  0.1918,  0.2365,
         0.2076,  0.1736,  0.2251,  0.1983,  0.2569,  0.1695,  0.2278,  0.1922,
         0.2051,  0.2274,  0.2514,  0.2000,  0.1911,  0.2277,  0.2073,  0.2523,
         0.2470,  0.2120,  0.2115,  0.2277,  0.2044,  0.2262,  0.2000,  0.2370,
         0.2619,  0.2245,  0.2287,  0.2400,  0.2097,  0.1940,  0.2018,  0.2165,
         0.2217,  0.2289,  0.2248,  0.2797,  0.0668,  0.2434,  0.1549,  0.2369,
        -0.0156,  0.1309,  0.2758,  0.1712,  0.2288,  0.2131,  0.2247,  0.1825,
         0.2594,  0.2419,  0.2912,  0.2471,  0.2164,  0.2154,  0.1920,  0.1454,
         0.2640,  0.2582,  0.2655,  0.2301,  0.2288,  0.2064,  0.2458,  0.2225,
         0.2115,  0.1836,  0.2397,  0.2248,  0.2315,  0.2365,  0.2375,  0.1828,
         0.2523,  0.2204,  0.2170,  0.2031,  0.2578,  0.2163,  0.2792,  0.2148,
         0.1780,  0.2179,  0.1970,  0.2319,  0.2239,  0.2364,  0.2001,  0.2306,
         0.2321,  0.2132,  0.2360,  0.1857,  0.1882,  0.1621,  0.2306,  0.2389,
         0.2316,  0.2195,  0.2472,  0.2019])
true tensor([ 0.1300,  0.1400,  0.2600,  0.2200,  0.4000,  0.3300,  0.4200,  0.4800,
         0.1200,  0.0400, -0.0300,  0.1300,  0.2200,  0.2700,  0.3800,  0.4000,
         0.3300,  0.4200,  0.4800,  0.3700,  0.1100,  0.0400,  0.1200,  0.0400,
         0.3800,  0.4000,  0.3300,  0.4200, -0.0300,  0.1300,  0.1400,  0.2600,
         0.4000,  0.3300,  0.4200,  0.4800,  0.1300,  0.1100,  0.0400,  0.1200,
         0.2200,  0.2700,  0.3800,  0.4000,  0.1300,  0.1100,  0.0400,  0.1200,
         0.0400,  0.1200,  0.0400, -0.0300, -0.0300,  0.1300,  0.1400,  0.2600,
         0.2700,  0.3800,  0.4000,  0.3300,  0.0400, -0.0300,  0.1300,  0.1400,
         0.0400, -0.0300,  0.1300,  0.1400,  0.2200,  0.2700,  0.3800,  0.4000,
         0.1400,  0.2600,  0.2200,  0.2700,  0.0400, -0.0300,  0.1300,  0.1400,
        -0.0300,  0.1300,  0.1400,  0.2600,  0.0400,  0.1200,  0.0400, -0.0300,
         0.0400,  0.1200,  0.0400, -0.0300,  0.2700,  0.3800,  0.4000,  0.3300,
         0.2600,  0.2200,  0.2700,  0.3800,  0.2700,  0.3800,  0.4000,  0.3300,
         0.1400,  0.2600,  0.2200,  0.2700,  0.1700,  0.1300,  0.1100,  0.0400,
         0.4000,  0.3300,  0.4200,  0.4800,  0.1300,  0.1400,  0.2600,  0.2200,
         0.1200,  0.0400, -0.0300,  0.1300,  0.3300,  0.4200,  0.4800,  0.3700,
         0.2600,  0.2200,  0.2700,  0.3800,  0.1300,  0.1100,  0.0400,  0.1200,
         0.3800,  0.4000,  0.3300,  0.4200,  0.1100,  0.0400,  0.1200,  0.0400,
         0.2600,  0.2200,  0.2700,  0.3800,  0.1200,  0.0400, -0.0300,  0.1300,
         0.1100,  0.0400,  0.1200,  0.0400,  0.1400,  0.2600,  0.2200,  0.2700,
         0.3800,  0.4000,  0.3300,  0.4200,  0.1300,  0.1400,  0.2600,  0.2200,
         0.1700,  0.1300,  0.1100,  0.0400])
Epoch: 5, Steps: 1 | Train Loss: 0.0503596 Vali Loss: 0.0228467
lr = 0.0000500050
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 371) (1, 371)
test shape: (1, 1, 371) (1, 1, 371)
mae:1.0852, mse:2.2412, rmse:1.4971, r2:-0.9836
mse_mean = 2.2412, mse_std = 0.0000
r2_mean = -0.9836, mae_std = 0.0000