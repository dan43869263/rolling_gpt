['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.08s/it]
1it [00:00, 11.44it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.372812271118164
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2484, 0.2200, 0.2277, 0.1963, 0.2315, 0.1514, 0.2694, 0.1931, 0.2094,
        0.2433, 0.2370, 0.2095, 0.2224, 0.2502, 0.2370, 0.2113, 0.2100, 0.1941,
        0.2189, 0.2391, 0.1749, 0.2597, 0.2822, 0.1067, 0.2215, 0.2101, 0.2853,
        0.1605, 0.2466, 0.1306, 0.1741, 0.2381, 0.2030, 0.2366, 0.2556, 0.2032,
        0.2786, 0.1792, 0.3745, 0.2133, 0.2407, 0.1828, 0.3729, 0.1926, 0.1083,
        0.1042, 0.2984, 0.3089, 0.2163, 0.2033, 0.2129, 0.2028, 0.1729, 0.1841,
        0.3976, 0.1624, 0.2306, 0.2803, 0.2722, 0.2118, 0.1965, 0.2240, 0.2169,
        0.2447, 0.3397, 0.0813, 0.3542, 0.1080, 0.2581, 0.2242, 0.1459, 0.1662,
        0.1583, 0.2775, 0.2436, 0.2829, 0.2051, 0.1520, 0.2951, 0.2267, 0.1885,
        0.2277, 0.1932, 0.2641, 0.2167, 0.2175, 0.2543, 0.2396, 0.2192, 0.2071,
        0.2656, 0.1044, 0.2564, 0.2710, 0.2721, 0.2026, 0.2469, 0.0962, 0.2488,
        0.1608, 0.2210, 0.2149, 0.2300, 0.2052, 0.1999, 0.1410, 0.1695, 0.3130,
        0.1400, 0.2263, 0.1794, 0.3451, 0.2494, 0.1991, 0.1891, 0.2199, 0.2702,
        0.2307, 0.3115, 0.2589, 0.2345, 0.2301, 0.2306, 0.2238, 0.1144, 0.1297,
        0.1988, 0.1328, 0.1559, 0.1241, 0.2312, 0.3645, 0.1299, 0.1236, 0.2405,
        0.3914, 0.2603, 0.1210, 0.3330, 0.1351, 0.2513, 0.1779, 0.2688, 0.3521,
        0.1562, 0.1810, 0.2750, 0.1750, 0.2513, 0.1518, 0.2795, 0.2230, 0.2378,
        0.1128, 0.2498, 0.2077, 0.2288, 0.2150, 0.2299, 0.2454, 0.2312, 0.2438,
        0.2186, 0.2328, 0.2383, 0.2277, 0.2425, 0.2318, 0.2374, 0.2042, 0.2652,
        0.2253])
true tensor([ 0.3300,  0.6600,  0.4500,  0.4300,  0.3200,  0.0800,  0.4800,  0.5200,
         0.6400,  0.3200,  0.0800,  0.4800,  0.4000,  0.6400,  0.3200,  0.0800,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.4000,  0.2800,  0.5500,  0.3300,
         0.4500,  0.4300, -0.1200,  0.1700,  0.6600,  0.4500,  0.4300, -0.1200,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.4800,  0.5200,  0.4000,  0.2800,
         0.5200,  0.4000,  0.2800,  0.5500,  0.4500,  0.4300, -0.1200,  0.1700,
         0.0800,  0.4800,  0.5200,  0.4000,  0.3300,  0.6600,  0.4500,  0.4300,
         0.5500,  0.3300,  0.6600,  0.4500,  0.6400,  0.3200,  0.0800,  0.4800,
         0.4500,  0.4300, -0.1200,  0.1700,  0.2800,  0.5500,  0.3300,  0.6600,
         0.4800,  0.5200,  0.4000,  0.2800,  0.4300, -0.1200,  0.1700,  0.3600,
         0.4800,  0.5200,  0.4000,  0.2800,  0.6600,  0.4500,  0.4300, -0.1200,
         0.5500,  0.3300,  0.6600,  0.4500,  0.3200,  0.0800,  0.4800,  0.5200,
         0.6600,  0.4500,  0.4300, -0.1200, -0.0400,  0.4000,  0.6400,  0.3200,
         0.5200,  0.4000,  0.2800,  0.5500,  0.5500,  0.3300,  0.6600,  0.4500,
         0.0800,  0.4800,  0.5200,  0.4000,  0.4000,  0.6400,  0.3200,  0.0800,
         0.4300, -0.1200,  0.1700,  0.3600,  0.5200,  0.4000,  0.2800,  0.5500,
         0.4000,  0.2800,  0.5500,  0.3300,  0.3300,  0.6600,  0.4500,  0.4300,
         0.4000,  0.2800,  0.5500,  0.3300,  0.2800,  0.5500,  0.3300,  0.6600,
        -0.1200,  0.1700,  0.3600,  1.0300,  0.4300, -0.1200,  0.1700,  0.3600,
         0.2800,  0.5500,  0.3300,  0.6600,  0.6400,  0.3200,  0.0800,  0.4800,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4000,  0.6400,  0.3200,  0.0800,
         0.0800,  0.4800,  0.5200,  0.4000])
Epoch: 1, Steps: 1 | Train Loss: 0.6126729 Vali Loss: 0.0712535
lr = 0.0000975531
Validation loss decreased (inf --> 0.071253).  Saving model ...
1it [00:00,  6.10it/s]
1it [00:00, 11.58it/s]
1it [00:00,  6.16it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5121455192565918
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 3.0004e-01,  1.2302e-01,  3.6072e-01,  2.1410e-01,  1.7631e-01,
         1.2290e-01,  3.2744e-01,  2.4311e-01,  2.4861e-01,  2.0065e-01,
         2.5689e-01,  2.1250e-01,  2.5256e-01,  1.3218e-01,  2.3861e-01,
         1.4305e-01,  2.1523e-01,  2.1468e-01,  2.2225e-01,  2.4527e-01,
         1.7963e-01,  2.2131e-01,  2.8706e-01,  1.1942e-01,  1.9901e-01,
         4.9973e-01, -9.8377e-05,  2.9566e-01,  2.0933e-01,  2.1879e-01,
         2.7605e-01,  2.9050e-01,  1.9387e-01,  1.6739e-01,  2.4072e-01,
         1.4249e-01,  2.3757e-01,  1.8945e-01,  2.3783e-01,  2.5507e-01,
         2.2175e-01,  2.2830e-01,  2.1699e-01,  2.1017e-01,  1.9171e-01,
         1.6833e-01,  2.6410e-01,  3.1975e-01,  3.0043e-01,  8.4875e-02,
         3.7343e-01,  1.1266e-01,  2.4761e-01,  3.0294e-01,  1.3205e-01,
         2.3865e-01,  2.0821e-01,  2.4723e-01,  2.0370e-01,  2.5604e-01,
         2.3068e-01,  2.4925e-01,  2.8369e-01,  2.5188e-01,  2.4487e-01,
         1.6522e-01,  2.3852e-01,  1.6928e-01,  2.5346e-01,  2.3187e-01,
         2.4776e-01,  2.4209e-01,  1.7773e-01,  2.3813e-01,  2.4089e-01,
         2.9866e-01,  1.9324e-01,  1.8588e-01,  2.1525e-01,  2.3794e-01,
        -1.0441e-01,  1.1889e-01,  4.5917e-02,  3.2708e-01,  2.7880e-01,
         1.0376e-01,  2.8979e-01,  1.7028e-01,  2.1373e-01,  1.3035e-01,
         2.2194e-01,  1.6669e-01,  2.6164e-01,  2.0392e-01,  2.4757e-01,
         2.4188e-01,  1.6287e-01,  2.7298e-01,  2.7101e-01,  1.8712e-01,
         1.5378e-01,  2.3440e-01,  2.8143e-01,  2.1790e-01,  3.5628e-01,
         1.9923e-01,  2.7247e-01,  2.1187e-01,  2.1759e-01,  8.1984e-02,
         3.0287e-01,  1.7299e-01,  1.4256e-01,  2.3588e-01,  2.6447e-01,
         9.2515e-02,  1.7498e-01,  2.1745e-01,  2.7607e-01,  3.2049e-01,
         3.6588e-01,  1.4254e-01,  4.0727e-01,  1.7657e-01,  1.6418e-01,
         2.1388e-01,  2.2192e-01,  2.6042e-01,  1.2835e-01,  2.4907e-01,
         2.2608e-01,  3.7829e-01,  2.4205e-01,  2.3126e-01,  2.3016e-01,
         2.1672e-01,  2.4683e-01,  2.1524e-01,  2.6772e-01,  1.7198e-01,
         2.3984e-01,  2.2672e-01,  2.7586e-01,  2.2445e-01,  1.5985e-01,
         9.5328e-02,  4.0559e-01,  1.7704e-01,  1.7511e-01,  2.6837e-01,
         2.4975e-01,  1.8055e-01,  2.3244e-01,  2.4105e-01,  2.0190e-01,
         2.3037e-01,  2.4081e-01,  2.2141e-01,  2.4309e-01,  2.0955e-01,
         2.2530e-01,  2.1946e-01,  2.1208e-01,  1.5924e-01,  5.7107e-02,
         1.9585e-01,  1.2353e-01,  2.7640e-01,  2.3233e-01,  1.9477e-01,
         2.4501e-01,  2.1560e-01])
true tensor([ 0.2800,  0.5500,  0.3300,  0.6600,  0.3300,  0.6600,  0.4500,  0.4300,
         0.4000,  0.6400,  0.3200,  0.0800,  0.4000,  0.2800,  0.5500,  0.3300,
         0.6400,  0.3200,  0.0800,  0.4800,  0.4300, -0.1200,  0.1700,  0.3600,
         0.5500,  0.3300,  0.6600,  0.4500,  0.6600,  0.4500,  0.4300, -0.1200,
         0.2800,  0.5500,  0.3300,  0.6600,  0.0800,  0.4800,  0.5200,  0.4000,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.4300, -0.1200,  0.1700,  0.3600,
         0.3200,  0.0800,  0.4800,  0.5200,  0.3200,  0.0800,  0.4800,  0.5200,
         0.6400,  0.3200,  0.0800,  0.4800,  0.4800,  0.5200,  0.4000,  0.2800,
         0.6600,  0.4500,  0.4300, -0.1200,  0.4000,  0.6400,  0.3200,  0.0800,
         0.4500,  0.4300, -0.1200,  0.1700, -0.1200,  0.1700,  0.3600,  1.0300,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.4500,  0.4300, -0.1200,  0.1700,
         0.5200,  0.4000,  0.2800,  0.5500,  0.4500,  0.4300, -0.1200,  0.1700,
         0.5500,  0.3300,  0.6600,  0.4500,  0.5200,  0.4000,  0.2800,  0.5500,
         0.4300, -0.1200,  0.1700,  0.3600,  0.6600,  0.4500,  0.4300, -0.1200,
         0.5200,  0.4000,  0.2800,  0.5500,  0.2800,  0.5500,  0.3300,  0.6600,
         0.4800,  0.5200,  0.4000,  0.2800,  0.3300,  0.6600,  0.4500,  0.4300,
         0.5500,  0.3300,  0.6600,  0.4500,  0.4000,  0.6400,  0.3200,  0.0800,
         0.3300,  0.6600,  0.4500,  0.4300,  0.0800,  0.4800,  0.5200,  0.4000,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4000,  0.2800,  0.5500,  0.3300,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.6400,  0.3200,  0.0800,  0.4800,
         0.4800,  0.5200,  0.4000,  0.2800,  0.4000,  0.2800,  0.5500,  0.3300,
         0.0800,  0.4800,  0.5200,  0.4000])
Epoch: 2, Steps: 1 | Train Loss: 0.6027512 Vali Loss: 0.0728859
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5018703937530518
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2259, 0.2797, 0.2620, 0.1008, 0.2420, 0.1558, 0.2183, 0.2562, 0.1622,
        0.2479, 0.2784, 0.1122, 0.2207, 0.1368, 0.1825, 0.1676, 0.2181, 0.2403,
        0.2355, 0.2563, 0.2048, 0.1921, 0.2583, 0.3308, 0.2196, 0.2108, 0.2548,
        0.2581, 0.2673, 0.2282, 0.2648, 0.2303, 0.2349, 0.1583, 0.3197, 0.1639,
        0.2057, 0.2473, 0.2291, 0.2335, 0.1839, 0.2187, 0.2392, 0.1903, 0.2534,
        0.2431, 0.1997, 0.2137, 0.1940, 0.2120, 0.2384, 0.2138, 0.2136, 0.2523,
        0.3000, 0.0933, 0.2309, 0.2361, 0.3193, 0.3609, 0.2341, 0.2177, 0.2645,
        0.2036, 0.2265, 0.2984, 0.2121, 0.2129, 0.2164, 0.2084, 0.1465, 0.2228,
        0.2244, 0.1326, 0.1788, 0.1348, 0.1891, 0.1787, 0.2661, 0.3696, 0.1367,
        0.2626, 0.2599, 0.2767, 0.1917, 0.1916, 0.2559, 0.1860, 0.2606, 0.1690,
        0.2842, 0.2055, 0.1204, 0.2429, 0.2172, 0.2664, 0.2576, 0.1980, 0.2486,
        0.2193, 0.2892, 0.1549, 0.3688, 0.2048, 0.2107, 0.3459, 0.3148, 0.2991,
        0.2365, 0.1301, 0.2942, 0.2303, 0.1273, 0.1282, 0.2407, 0.3677, 0.1708,
        0.2179, 0.2531, 0.2995, 0.2601, 0.2283, 0.2218, 0.3840, 0.3183, 0.1021,
        0.3847, 0.2336, 0.2285, 0.1274, 0.3454, 0.2407, 0.2530, 0.2506, 0.2316,
        0.2165, 0.2189, 0.2294, 0.2339, 0.2262, 0.3140, 0.1638, 0.3858, 0.1941,
        0.2646, 0.1531, 0.2219, 0.2281, 0.2299, 0.2326, 0.2520, 0.1972, 0.2274,
        0.2106, 0.2362, 0.2347, 0.2132, 0.2597, 0.2435, 0.2329, 0.2140, 0.2060,
        0.2818, 0.3860, 0.1857, 0.1384, 0.2348, 0.2662, 0.2329, 0.2427, 0.2434,
        0.2029])
true tensor([ 0.4000,  0.2800,  0.5500,  0.3300,  0.6600,  0.4500,  0.4300, -0.1200,
         0.3300,  0.6600,  0.4500,  0.4300,  0.5500,  0.3300,  0.6600,  0.4500,
         0.6400,  0.3200,  0.0800,  0.4800,  0.5500,  0.3300,  0.6600,  0.4500,
         0.0800,  0.4800,  0.5200,  0.4000,  0.4000,  0.6400,  0.3200,  0.0800,
         0.5500,  0.3300,  0.6600,  0.4500, -0.0400,  0.4000,  0.6400,  0.3200,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4800,  0.5200,  0.4000,  0.2800,
         0.0800,  0.4800,  0.5200,  0.4000,  0.2800,  0.5500,  0.3300,  0.6600,
         0.4500,  0.4300, -0.1200,  0.1700,  0.6400,  0.3200,  0.0800,  0.4800,
        -0.1200,  0.1700,  0.3600,  1.0300,  0.4300, -0.1200,  0.1700,  0.3600,
         0.4500,  0.4300, -0.1200,  0.1700,  0.4800,  0.5200,  0.4000,  0.2800,
         0.3300,  0.6600,  0.4500,  0.4300,  0.5200,  0.4000,  0.2800,  0.5500,
         0.6600,  0.4500,  0.4300, -0.1200,  0.6400,  0.3200,  0.0800,  0.4800,
         0.0800,  0.4800,  0.5200,  0.4000,  0.5200,  0.4000,  0.2800,  0.5500,
         0.6600,  0.4500,  0.4300, -0.1200,  0.3300,  0.6600,  0.4500,  0.4300,
         0.5200,  0.4000,  0.2800,  0.5500,  0.4300, -0.1200,  0.1700,  0.3600,
         0.2800,  0.5500,  0.3300,  0.6600,  0.4300, -0.1200,  0.1700,  0.3600,
         0.4800,  0.5200,  0.4000,  0.2800,  0.4000,  0.6400,  0.3200,  0.0800,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4000,  0.2800,  0.5500,  0.3300,
         0.4500,  0.4300, -0.1200,  0.1700,  0.3200,  0.0800,  0.4800,  0.5200,
         0.4000,  0.6400,  0.3200,  0.0800, -0.0400,  0.4000,  0.6400,  0.3200,
         0.4000,  0.2800,  0.5500,  0.3300,  0.2800,  0.5500,  0.3300,  0.6600,
        -0.0400,  0.4000,  0.6400,  0.3200])
Epoch: 3, Steps: 1 | Train Loss: 0.5975762 Vali Loss: 0.0670537
lr = 0.0000793913
Validation loss decreased (0.071253 --> 0.067054).  Saving model ...
1it [00:00, 12.51it/s]
1it [00:00,  5.96it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.5186781883239746
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2081, 0.2198, 0.2412, 0.2707, 0.2131, 0.2805, 0.2334, 0.3301, 0.2613,
        0.1725, 0.3614, 0.2152, 0.2415, 0.2333, 0.2281, 0.3456, 0.1390, 0.2885,
        0.2933, 0.2075, 0.2449, 0.0683, 0.4346, 0.2097, 0.3208, 0.1575, 0.3084,
        0.2449, 0.2250, 0.2244, 0.2200, 0.2337, 0.2039, 0.2617, 0.2363, 0.2940,
        0.2589, 0.0920, 0.3985, 0.1775, 0.2216, 0.2026, 0.2116, 0.2373, 0.2268,
        0.1890, 0.2033, 0.2686, 0.2373, 0.2204, 0.2355, 0.2238, 0.1679, 0.2280,
        0.2692, 0.1556, 0.2556, 0.1026, 0.3140, 0.2977, 0.1463, 0.2468, 0.2033,
        0.3287, 0.2888, 0.2028, 0.3291, 0.2933, 0.2392, 0.2156, 0.2454, 0.2088,
        0.3255, 0.1279, 0.2931, 0.1948, 0.2149, 0.2185, 0.2452, 0.2143, 0.1383,
        0.1817, 0.2370, 0.3122, 0.2451, 0.2360, 0.2026, 0.2035, 0.2989, 0.1519,
        0.2763, 0.2295, 0.1912, 0.2862, 0.2546, 0.2096, 0.0396, 0.2429, 0.3430,
        0.1734, 0.2227, 0.1935, 0.2589, 0.2279, 0.2207, 0.2505, 0.2470, 0.2261,
        0.1831, 0.2366, 0.2788, 0.1356, 0.1669, 0.2662, 0.2638, 0.2144, 0.2508,
        0.2726, 0.2692, 0.2614, 0.2346, 0.2286, 0.2291, 0.2280, 0.2514, 0.2445,
        0.2509, 0.2342, 0.2225, 0.2232, 0.2002, 0.2475, 0.1241, 0.2104, 0.3063,
        0.3687, 0.2921, 0.0811, 0.2669, 0.3447, 0.1405, 0.1982, 0.2664, 0.3542,
        0.1296, 0.2743, 0.2979, 0.2917, 0.2403, 0.2327, 0.2213, 0.2256, 0.2829,
        0.2270, 0.2920, 0.2303, 0.2654, 0.1794, 0.2346, 0.1939, 0.1554, 0.2752,
        0.2927, 0.2051, 0.2257, 0.2244, 0.2247, 0.2191, 0.2317, 0.1474, 0.2723,
        0.3188])
true tensor([ 0.4300, -0.1200,  0.1700,  0.3600,  0.2800,  0.5500,  0.3300,  0.6600,
         0.4000,  0.2800,  0.5500,  0.3300,  0.4800,  0.5200,  0.4000,  0.2800,
        -0.1200,  0.1700,  0.3600,  1.0300,  0.3200,  0.0800,  0.4800,  0.5200,
         0.4800,  0.5200,  0.4000,  0.2800, -0.0400,  0.4000,  0.6400,  0.3200,
         0.5500,  0.3300,  0.6600,  0.4500,  0.3300,  0.6600,  0.4500,  0.4300,
         0.4000,  0.6400,  0.3200,  0.0800,  0.2800,  0.5500,  0.3300,  0.6600,
         0.0800,  0.4800,  0.5200,  0.4000,  0.5200,  0.4000,  0.2800,  0.5500,
         0.6600,  0.4500,  0.4300, -0.1200,  0.5200,  0.4000,  0.2800,  0.5500,
         0.5200,  0.4000,  0.2800,  0.5500, -0.0400,  0.4000,  0.6400,  0.3200,
         0.2800,  0.5500,  0.3300,  0.6600,  0.4800,  0.5200,  0.4000,  0.2800,
         0.4000,  0.2800,  0.5500,  0.3300,  0.5500,  0.3300,  0.6600,  0.4500,
         0.4300, -0.1200,  0.1700,  0.3600,  0.3300,  0.6600,  0.4500,  0.4300,
         0.3300,  0.6600,  0.4500,  0.4300,  0.3200,  0.0800,  0.4800,  0.5200,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.6600,  0.4500,  0.4300, -0.1200,
         0.6400,  0.3200,  0.0800,  0.4800,  0.4000,  0.2800,  0.5500,  0.3300,
         0.6400,  0.3200,  0.0800,  0.4800,  0.4000,  0.6400,  0.3200,  0.0800,
         0.6400,  0.3200,  0.0800,  0.4800,  0.0800,  0.4800,  0.5200,  0.4000,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4500,  0.4300, -0.1200,  0.1700,
         0.4500,  0.4300, -0.1200,  0.1700,  0.4000,  0.6400,  0.3200,  0.0800,
         0.5500,  0.3300,  0.6600,  0.4500,  0.4500,  0.4300, -0.1200,  0.1700,
         0.4300, -0.1200,  0.1700,  0.3600,  0.0800,  0.4800,  0.5200,  0.4000,
         0.6600,  0.4500,  0.4300, -0.1200])
Epoch: 4, Steps: 1 | Train Loss: 0.5931580 Vali Loss: 0.0648963
lr = 0.0000654543
Validation loss decreased (0.067054 --> 0.064896).  Saving model ...
1it [00:00, 11.81it/s]
1it [00:00,  5.70it/s]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.5376558303833008
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.1545,  0.2381,  0.2794,  0.3198,  0.2519,  0.2236,  0.2810,  0.1693,
         0.2288,  0.2242,  0.2475,  0.2139,  0.1877,  0.2570,  0.2578,  0.1159,
         0.1558,  0.2348,  0.2512,  0.1682,  0.2187,  0.2083,  0.2276,  0.2357,
         0.3023,  0.1904,  0.3039,  0.2174,  0.2331,  0.1964,  0.2234,  0.1818,
         0.2310,  0.2185,  0.2580,  0.3377,  0.2005,  0.2133,  0.2571,  0.2183,
         0.1991,  0.2294,  0.2063,  0.2291,  0.2353,  0.2314,  0.2142,  0.2277,
         0.2139,  0.2508,  0.2372,  0.2371,  0.2931,  0.1613,  0.2737,  0.1274,
         0.2912,  0.2702,  0.2225,  0.1808,  0.3475,  0.0836,  0.3608,  0.2332,
         0.2637,  0.2927,  0.2686,  0.3518,  0.2317,  0.2536,  0.2884,  0.2931,
         0.2725,  0.2170,  0.3027,  0.3465,  0.2055,  0.2138,  0.2053,  0.2515,
         0.1631,  0.2120,  0.2822,  0.3467,  0.2698,  0.1704,  0.3879,  0.1428,
         0.3298,  0.1267,  0.3580,  0.1199, -0.0066,  0.0572,  0.2778,  0.3604,
         0.1896,  0.2796,  0.3271,  0.3920,  0.2375,  0.1860,  0.3822,  0.2528,
         0.2718,  0.1783,  0.2544,  0.1795,  0.2279,  0.2250,  0.2120,  0.2203,
         0.2410,  0.2001,  0.2976,  0.2275,  0.2369,  0.2495,  0.3135,  0.1542,
         0.1999,  0.2211,  0.2315,  0.2347,  0.2326,  0.1214,  0.3829,  0.2221,
         0.3220,  0.1677,  0.4080,  0.2838,  0.2117,  0.2373,  0.2398,  0.2161,
         0.2164,  0.2105,  0.2739,  0.2205,  0.2308,  0.2341,  0.2357,  0.2004,
         0.1888,  0.2290,  0.2456,  0.1797,  0.2381,  0.2170,  0.2242,  0.2147,
         0.2264,  0.2273,  0.2367,  0.2535,  0.2359,  0.1641,  0.1823,  0.2181,
         0.1958,  0.2339,  0.2824,  0.3368,  0.2363,  0.2140,  0.2358,  0.2172,
         0.2515,  0.2256,  0.2146,  0.1992])
true tensor([ 0.5200,  0.4000,  0.2800,  0.5500,  0.4300, -0.1200,  0.1700,  0.3600,
         0.3200,  0.0800,  0.4800,  0.5200,  0.3300,  0.6600,  0.4500,  0.4300,
        -0.1200,  0.1700,  0.3600,  1.0300,  0.6400,  0.3200,  0.0800,  0.4800,
         0.4500,  0.4300, -0.1200,  0.1700,  0.5200,  0.4000,  0.2800,  0.5500,
         0.4500,  0.4300, -0.1200,  0.1700, -0.0400,  0.4000,  0.6400,  0.3200,
         0.3300,  0.6600,  0.4500,  0.4300,  0.4000,  0.6400,  0.3200,  0.0800,
         0.6400,  0.3200,  0.0800,  0.4800,  0.5200,  0.4000,  0.2800,  0.5500,
         0.6600,  0.4500,  0.4300, -0.1200,  0.4800,  0.5200,  0.4000,  0.2800,
         0.0800,  0.4800,  0.5200,  0.4000,  0.5500,  0.3300,  0.6600,  0.4500,
         0.4000,  0.2800,  0.5500,  0.3300,  0.4800,  0.5200,  0.4000,  0.2800,
         0.4800,  0.5200,  0.4000,  0.2800,  0.3200,  0.0800,  0.4800,  0.5200,
         0.3200,  0.0800,  0.4800,  0.5200,  0.3300,  0.6600,  0.4500,  0.4300,
         0.2800,  0.5500,  0.3300,  0.6600,  0.6600,  0.4500,  0.4300, -0.1200,
         0.2800,  0.5500,  0.3300,  0.6600, -0.0400,  0.4000,  0.6400,  0.3200,
         0.4300, -0.1200,  0.1700,  0.3600,  0.4000,  0.2800,  0.5500,  0.3300,
         0.0800,  0.4800,  0.5200,  0.4000,  0.4300, -0.1200,  0.1700,  0.3600,
         0.5500,  0.3300,  0.6600,  0.4500,  0.4000,  0.6400,  0.3200,  0.0800,
         0.4500,  0.4300, -0.1200,  0.1700,  0.4000,  0.6400,  0.3200,  0.0800,
         0.5500,  0.3300,  0.6600,  0.4500,  0.0800,  0.4800,  0.5200,  0.4000,
         0.6400,  0.3200,  0.0800,  0.4800,  0.2800,  0.5500,  0.3300,  0.6600,
         0.6600,  0.4500,  0.4300, -0.1200,  0.4000,  0.2800,  0.5500,  0.3300,
        -0.0400,  0.4000,  0.6400,  0.3200])
Epoch: 5, Steps: 1 | Train Loss: 0.5896930 Vali Loss: 0.0656895
lr = 0.0000500050
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
1it [00:00, 11.40it/s]
1it [00:00,  6.01it/s]
1it [00:00, 11.26it/s]
1it [00:00,  6.06it/s]
1it [00:00, 12.31it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.3565, 0.1506, 0.3376, 0.2326, 0.1500, 0.2974, 0.2612, 0.2518, 0.2025,
        0.1562, 0.3076, 0.2997, 0.1994, 0.2424, 0.2154, 0.2444, 0.2420, 0.2516,
        0.2611, 0.3274, 0.2878, 0.2786, 0.3458, 0.1353, 0.1715, 0.2197, 0.2792,
        0.3368, 0.2446, 0.2040, 0.2263, 0.2031, 0.1663, 0.2518, 0.1996, 0.1415,
        0.1442, 0.2373, 0.2432, 0.3125, 0.2463, 0.1724, 0.4400, 0.2665, 0.2109,
        0.2871, 0.3424, 0.3231, 0.1966, 0.1964, 0.1612, 0.3095, 0.2424, 0.2106,
        0.2458, 0.2330, 0.2417, 0.2492, 0.2416, 0.2102, 0.1658, 0.2539, 0.3549,
        0.3239, 0.2261, 0.1859, 0.2125, 0.2085, 0.1888, 0.1833, 0.3201, 0.2947,
        0.1692, 0.2453, 0.1995, 0.2375, 0.2069, 0.2833, 0.2462, 0.1973, 0.2872,
        0.1783, 0.3796, 0.1559, 0.2325, 0.2317, 0.2236, 0.2560, 0.2806, 0.2635,
        0.3263, 0.2467, 0.2121, 0.2139, 0.2491, 0.2530, 0.2471, 0.2128, 0.2197,
        0.2266, 0.1952, 0.2138, 0.2961, 0.2070, 0.1964, 0.2404, 0.3467, 0.1485,
        0.2581, 0.2520, 0.2197, 0.2797, 0.2519, 0.2332, 0.2316, 0.2167, 0.0856,
        0.2613, 0.2828, 0.3961, 0.2273, 0.2236, 0.2383, 0.2500, 0.1911, 0.0962,
        0.3659, 0.1391, 0.2164, 0.1969, 0.2863, 0.2306, 0.1773, 0.2396, 0.2372,
        0.2248, 0.1788, 0.2054, 0.2398, 0.2947, 0.2246, 0.2594, 0.2199, 0.2492,
        0.2405, 0.2333, 0.1853, 0.2233, 0.2546, 0.2254, 0.3816, 0.2414, 0.2616,
        0.1896, 0.2922, 0.1866, 0.2975, 0.1762, 0.3737, 0.2443, 0.2742, 0.1797,
        0.3575, 0.4026, 0.2070, 0.2244, 0.3285, 0.2021, 0.1947, 0.2499, 0.2524,
        0.2007])
true tensor([ 0.2800,  0.5500,  0.3300,  0.6600,  0.3300,  0.6600,  0.4500,  0.4300,
         0.3300,  0.6600,  0.4500,  0.4300,  0.6400,  0.3200,  0.0800,  0.4800,
         0.5200,  0.4000,  0.2800,  0.5500,  0.4000,  0.2800,  0.5500,  0.3300,
         0.2800,  0.5500,  0.3300,  0.6600,  0.0800,  0.4800,  0.5200,  0.4000,
         0.3300,  0.6600,  0.4500,  0.4300,  0.5500,  0.3300,  0.6600,  0.4500,
         0.6600,  0.4500,  0.4300, -0.1200,  0.4000,  0.2800,  0.5500,  0.3300,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4800,  0.5200,  0.4000,  0.2800,
         0.6400,  0.3200,  0.0800,  0.4800,  0.4500,  0.4300, -0.1200,  0.1700,
        -0.1200,  0.1700,  0.3600,  1.0300,  0.4800,  0.5200,  0.4000,  0.2800,
        -0.0400,  0.4000,  0.6400,  0.3200, -0.0400,  0.4000,  0.6400,  0.3200,
         0.5500,  0.3300,  0.6600,  0.4500,  0.4300, -0.1200,  0.1700,  0.3600,
         0.4300, -0.1200,  0.1700,  0.3600,  0.2800,  0.5500,  0.3300,  0.6600,
         0.4000,  0.6400,  0.3200,  0.0800,  0.5200,  0.4000,  0.2800,  0.5500,
         0.3200,  0.0800,  0.4800,  0.5200,  0.4000,  0.2800,  0.5500,  0.3300,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.6600,  0.4500,  0.4300, -0.1200,
         0.0800,  0.4800,  0.5200,  0.4000,  0.3200,  0.0800,  0.4800,  0.5200,
         0.0800,  0.4800,  0.5200,  0.4000,  0.6400,  0.3200,  0.0800,  0.4800,
         0.4800,  0.5200,  0.4000,  0.2800,  0.4000,  0.6400,  0.3200,  0.0800,
         0.4000,  0.6400,  0.3200,  0.0800,  0.4500,  0.4300, -0.1200,  0.1700,
         0.4500,  0.4300, -0.1200,  0.1700,  0.5200,  0.4000,  0.2800,  0.5500,
         0.4300, -0.1200,  0.1700,  0.3600,  0.5500,  0.3300,  0.6600,  0.4500,
         0.6600,  0.4500,  0.4300, -0.1200])
Epoch: 6, Steps: 1 | Train Loss: 0.5847118 Vali Loss: 0.0663394
lr = 0.0000345557
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 7 cost time: 0.5049355030059814
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2799, 0.2366, 0.2628, 0.2324, 0.2507, 0.2155, 0.2699, 0.2238, 0.1868,
        0.2471, 0.2636, 0.2004, 0.1736, 0.2827, 0.3266, 0.1811, 0.2052, 0.2550,
        0.2257, 0.2208, 0.2163, 0.1994, 0.2814, 0.1659, 0.0012, 0.2495, 0.2976,
        0.1894, 0.1884, 0.2262, 0.2766, 0.1305, 0.1685, 0.2654, 0.2190, 0.2127,
        0.2478, 0.2202, 0.2695, 0.2094, 0.2026, 0.2229, 0.2392, 0.2190, 0.2787,
        0.2148, 0.2868, 0.2530, 0.2345, 0.2431, 0.2277, 0.2379, 0.1444, 0.2490,
        0.3761, 0.1658, 0.2483, 0.2068, 0.2035, 0.2428, 0.1391, 0.2463, 0.2021,
        0.2799, 0.1917, 0.2289, 0.2274, 0.2041, 0.1748, 0.2322, 0.2697, 0.3387,
        0.2673, 0.2474, 0.2013, 0.2416, 0.2244, 0.3445, 0.1614, 0.1571, 0.1560,
        0.3310, 0.2591, 0.3339, 0.0202, 0.3918, 0.1755, 0.1683, 0.2620, 0.2562,
        0.2720, 0.1760, 0.2052, 0.1222, 0.3489, 0.2477, 0.1917, 0.2192, 0.2412,
        0.1858, 0.2710, 0.2391, 0.2507, 0.3856, 0.2639, 0.1602, 0.3379, 0.2550,
        0.2271, 0.2116, 0.2187, 0.2634, 0.2246, 0.2016, 0.2056, 0.2166, 0.2429,
        0.2013, 0.2915, 0.2370, 0.2050, 0.1919, 0.3200, 0.3710, 0.2990, 0.2226,
        0.3126, 0.2593, 0.3125, 0.1920, 0.3174, 0.2218, 0.1189, 0.2583, 0.3225,
        0.3061, 0.3454, 0.0934, 0.2604, 0.2770, 0.3623, 0.1049, 0.4310, 0.1757,
        0.2486, 0.2466, 0.2197, 0.2202, 0.0729, 0.2698, 0.2197, 0.2970, 0.2879,
        0.1546, 0.2683, 0.3630, 0.2216, 0.2378, 0.2219, 0.2284, 0.2306, 0.2491,
        0.2417, 0.2011, 0.2383, 0.1675, 0.3218, 0.3608, 0.2036, 0.2804, 0.2507,
        0.2488])
true tensor([ 0.4800,  0.5200,  0.4000,  0.2800,  0.0800,  0.4800,  0.5200,  0.4000,
         0.4500,  0.4300, -0.1200,  0.1700,  0.4800,  0.5200,  0.4000,  0.2800,
         0.3300,  0.6600,  0.4500,  0.4300,  0.5500,  0.3300,  0.6600,  0.4500,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.2800,  0.5500,  0.3300,  0.6600,
         0.4500,  0.4300, -0.1200,  0.1700,  0.4000,  0.2800,  0.5500,  0.3300,
         0.3200,  0.0800,  0.4800,  0.5200,  0.5500,  0.3300,  0.6600,  0.4500,
         0.4000,  0.6400,  0.3200,  0.0800,  0.3200,  0.0800,  0.4800,  0.5200,
         0.4000,  0.6400,  0.3200,  0.0800,  0.4300, -0.1200,  0.1700,  0.3600,
         0.6400,  0.3200,  0.0800,  0.4800,  0.3300,  0.6600,  0.4500,  0.4300,
         0.6600,  0.4500,  0.4300, -0.1200,  0.5200,  0.4000,  0.2800,  0.5500,
         0.4500,  0.4300, -0.1200,  0.1700,  0.5500,  0.3300,  0.6600,  0.4500,
        -0.1200,  0.1700,  0.3600,  1.0300,  0.3200,  0.0800,  0.4800,  0.5200,
         0.0800,  0.4800,  0.5200,  0.4000,  0.2800,  0.5500,  0.3300,  0.6600,
         0.6600,  0.4500,  0.4300, -0.1200,  0.6400,  0.3200,  0.0800,  0.4800,
         0.0800,  0.4800,  0.5200,  0.4000,  0.3300,  0.6600,  0.4500,  0.4300,
         0.4800,  0.5200,  0.4000,  0.2800,  0.4300, -0.1200,  0.1700,  0.3600,
         0.2800,  0.5500,  0.3300,  0.6600,  0.6600,  0.4500,  0.4300, -0.1200,
         0.5200,  0.4000,  0.2800,  0.5500,  0.4000,  0.2800,  0.5500,  0.3300,
         0.4000,  0.6400,  0.3200,  0.0800,  0.6400,  0.3200,  0.0800,  0.4800,
         0.4000,  0.2800,  0.5500,  0.3300, -0.0400,  0.4000,  0.6400,  0.3200,
        -0.0400,  0.4000,  0.6400,  0.3200,  0.4300, -0.1200,  0.1700,  0.3600,
         0.5200,  0.4000,  0.2800,  0.5500])
Epoch: 7, Steps: 1 | Train Loss: 0.5825247 Vali Loss: 0.0654928
lr = 0.0000206187
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 372) (1, 372)
test shape: (1, 1, 372) (1, 1, 372)
mae:0.8403, mse:1.5079, rmse:1.2279, r2:-0.5601
mse_mean = 1.5079, mse_std = 0.0000
r2_mean = -0.5601, mae_std = 0.0000
1it [00:00, 10.18it/s]