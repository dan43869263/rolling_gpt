['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.12s/it]
1it [00:00, 11.83it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3983619213104248
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2324, 0.1749, 0.2925, 0.2023, 0.2598, 0.1981, 0.2638, 0.2409, 0.2329,
        0.2560, 0.2252, 0.2244, 0.2291, 0.2299, 0.2356, 0.2133, 0.2533, 0.2106,
        0.2414, 0.2136, 0.2107, 0.2385, 0.2300, 0.2016, 0.2638, 0.1926, 0.2400,
        0.2106, 0.2210, 0.2078, 0.2277, 0.2428, 0.2123, 0.2350, 0.1769, 0.2315,
        0.2193, 0.2164, 0.1984, 0.1986, 0.2017, 0.2125, 0.2131, 0.1966, 0.2421,
        0.2153, 0.1917, 0.1946, 0.2329, 0.2227, 0.2327, 0.2311, 0.2285, 0.2234,
        0.2620, 0.2239, 0.2347, 0.2201, 0.2726, 0.2385, 0.2088, 0.2433, 0.1991,
        0.2718, 0.1700, 0.2170, 0.1586, 0.2772, 0.2268, 0.2140, 0.2345, 0.2120,
        0.2497, 0.2055, 0.1971, 0.2124, 0.1912, 0.2716, 0.2286, 0.2215, 0.2542,
        0.1916, 0.2535, 0.2043, 0.2569, 0.2525, 0.2293, 0.2319, 0.2015, 0.2207,
        0.2076, 0.2228, 0.2626, 0.1912, 0.2182, 0.2436, 0.2008, 0.2271, 0.2020,
        0.2135, 0.2362, 0.1960, 0.2377, 0.2318, 0.2507, 0.2288, 0.2797, 0.2172,
        0.2436, 0.2073, 0.2442, 0.2460, 0.1903, 0.2572, 0.2251, 0.2349, 0.2295,
        0.2209, 0.2258, 0.2286, 0.2143, 0.2332, 0.2298, 0.2396, 0.2339, 0.2252,
        0.2502, 0.2055, 0.2533, 0.2201, 0.2321, 0.2448, 0.2226, 0.2382, 0.2171,
        0.2027, 0.2008, 0.2492, 0.2065, 0.2371, 0.2338, 0.1980, 0.2201, 0.2099,
        0.2003, 0.2392, 0.2482, 0.1740, 0.2174, 0.2299, 0.1793, 0.2652, 0.2529,
        0.2141, 0.2411, 0.2113, 0.2256, 0.2482, 0.2363, 0.2294, 0.2347, 0.2240,
        0.2428, 0.1985, 0.2626, 0.2038, 0.2576, 0.2684, 0.2058, 0.2355, 0.2576,
        0.2270])
true tensor([0.2200, 0.2500, 0.2900, 0.2300, 0.3500, 0.3200, 0.2600, 0.1900, 0.3500,
        0.3200, 0.2600, 0.1900, 0.4000, 0.3500, 0.3200, 0.2600, 0.3100, 0.4000,
        0.3500, 0.3200, 0.2400, 0.2800, 0.2500, 0.2200, 0.2900, 0.2300, 0.2100,
        0.4100, 0.2500, 0.2900, 0.2300, 0.2100, 0.4600, 0.3100, 0.4000, 0.3500,
        0.2600, 0.1900, 0.2400, 0.2800, 0.1900, 0.2400, 0.2800, 0.2500, 0.2300,
        0.2100, 0.4100, 0.2400, 0.3200, 0.2600, 0.1900, 0.2400, 0.2200, 0.2500,
        0.2900, 0.2300, 0.2500, 0.2200, 0.2500, 0.2900, 0.4000, 0.3500, 0.3200,
        0.2600, 0.2900, 0.2300, 0.2100, 0.4100, 0.2800, 0.2500, 0.2200, 0.2500,
        0.1900, 0.2400, 0.2800, 0.2500, 0.2300, 0.2100, 0.4100, 0.2400, 0.2600,
        0.1900, 0.2400, 0.2800, 0.2900, 0.2300, 0.2100, 0.4100, 0.2500, 0.2200,
        0.2500, 0.2900, 0.3200, 0.2600, 0.1900, 0.2400, 0.2500, 0.2900, 0.2300,
        0.2100, 0.4600, 0.3100, 0.4000, 0.3500, 0.2400, 0.2800, 0.2500, 0.2200,
        0.2200, 0.2500, 0.2900, 0.2300, 0.3200, 0.2600, 0.1900, 0.2400, 0.3100,
        0.4000, 0.3500, 0.3200, 0.2300, 0.2100, 0.4100, 0.2400, 0.1900, 0.2400,
        0.2800, 0.2500, 0.2800, 0.2500, 0.2200, 0.2500, 0.2500, 0.2900, 0.2300,
        0.2100, 0.2400, 0.2800, 0.2500, 0.2200, 0.2500, 0.2200, 0.2500, 0.2900,
        0.2100, 0.4100, 0.2400, 0.1200, 0.2100, 0.4100, 0.2400, 0.1200, 0.2800,
        0.2500, 0.2200, 0.2500, 0.4000, 0.3500, 0.3200, 0.2600, 0.3500, 0.3200,
        0.2600, 0.1900, 0.3100, 0.4000, 0.3500, 0.3200, 0.2600, 0.1900, 0.2400,
        0.2800])
Epoch: 1, Steps: 1 | Train Loss: 0.0430200 Vali Loss: 0.0065744
lr = 0.0000975531
Validation loss decreased (inf --> 0.006574).  Saving model ...
1it [00:00,  6.11it/s]
1it [00:00, 11.25it/s]
1it [00:00,  6.10it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.511913537979126
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2363, 0.1903, 0.2493, 0.2319, 0.2424, 0.1715, 0.2396, 0.2212, 0.2569,
        0.1849, 0.2492, 0.2676, 0.2048, 0.2175, 0.1538, 0.1986, 0.2276, 0.2499,
        0.1955, 0.2598, 0.2094, 0.2508, 0.2463, 0.2497, 0.3018, 0.1640, 0.1743,
        0.2615, 0.2415, 0.2468, 0.2143, 0.2366, 0.2438, 0.2422, 0.2223, 0.1935,
        0.1824, 0.2459, 0.2165, 0.2408, 0.1880, 0.1891, 0.1934, 0.2747, 0.2613,
        0.2137, 0.2173, 0.2791, 0.2396, 0.2326, 0.2473, 0.2251, 0.2529, 0.1725,
        0.2576, 0.2267, 0.1634, 0.2641, 0.2427, 0.2195, 0.2282, 0.2093, 0.2258,
        0.2122, 0.2227, 0.2053, 0.2157, 0.2063, 0.2206, 0.2020, 0.1978, 0.2311,
        0.2828, 0.1872, 0.1683, 0.2120, 0.2557, 0.2127, 0.2503, 0.2134, 0.2903,
        0.2263, 0.2339, 0.2263, 0.2369, 0.2075, 0.1959, 0.2376, 0.2268, 0.1885,
        0.2012, 0.2048, 0.3054, 0.0454, 0.3230, 0.1611, 0.2275, 0.2398, 0.2502,
        0.2187, 0.2079, 0.2355, 0.2410, 0.2177, 0.1998, 0.2478, 0.2338, 0.2435,
        0.2147, 0.2314, 0.2163, 0.2140, 0.2187, 0.2139, 0.2336, 0.2113, 0.2190,
        0.2188, 0.2465, 0.2031, 0.2275, 0.2071, 0.2048, 0.2256, 0.2120, 0.2515,
        0.2131, 0.2095, 0.2480, 0.2078, 0.2493, 0.2456, 0.2316, 0.2134, 0.2252,
        0.2087, 0.2223, 0.1893, 0.2462, 0.2046, 0.2171, 0.1845, 0.2376, 0.2591,
        0.2071, 0.2161, 0.2495, 0.1991, 0.2413, 0.2514, 0.2120, 0.2046, 0.2211,
        0.2071, 0.2248, 0.2351, 0.2243, 0.2490, 0.2053, 0.2422, 0.2248, 0.2035,
        0.2389, 0.2215, 0.2310, 0.2140, 0.2149, 0.2312, 0.1925, 0.2391, 0.2337,
        0.2214])
true tensor([0.2800, 0.2500, 0.2200, 0.2500, 0.2200, 0.2500, 0.2900, 0.2300, 0.3100,
        0.4000, 0.3500, 0.3200, 0.2400, 0.2800, 0.2500, 0.2200, 0.4000, 0.3500,
        0.3200, 0.2600, 0.2300, 0.2100, 0.4100, 0.2400, 0.2500, 0.2200, 0.2500,
        0.2900, 0.2900, 0.2300, 0.2100, 0.4100, 0.2800, 0.2500, 0.2200, 0.2500,
        0.3200, 0.2600, 0.1900, 0.2400, 0.4600, 0.3100, 0.4000, 0.3500, 0.2100,
        0.4100, 0.2400, 0.1200, 0.3500, 0.3200, 0.2600, 0.1900, 0.3200, 0.2600,
        0.1900, 0.2400, 0.4000, 0.3500, 0.3200, 0.2600, 0.1900, 0.2400, 0.2800,
        0.2500, 0.2500, 0.2900, 0.2300, 0.2100, 0.4000, 0.3500, 0.3200, 0.2600,
        0.2300, 0.2100, 0.4100, 0.2400, 0.2100, 0.4100, 0.2400, 0.1200, 0.3100,
        0.4000, 0.3500, 0.3200, 0.2900, 0.2300, 0.2100, 0.4100, 0.1900, 0.2400,
        0.2800, 0.2500, 0.2900, 0.2300, 0.2100, 0.4100, 0.2500, 0.2200, 0.2500,
        0.2900, 0.2400, 0.2800, 0.2500, 0.2200, 0.2300, 0.2100, 0.4100, 0.2400,
        0.2500, 0.2900, 0.2300, 0.2100, 0.1900, 0.2400, 0.2800, 0.2500, 0.2500,
        0.2200, 0.2500, 0.2900, 0.2600, 0.1900, 0.2400, 0.2800, 0.2500, 0.2900,
        0.2300, 0.2100, 0.2200, 0.2500, 0.2900, 0.2300, 0.3100, 0.4000, 0.3500,
        0.3200, 0.2200, 0.2500, 0.2900, 0.2300, 0.2600, 0.1900, 0.2400, 0.2800,
        0.3500, 0.3200, 0.2600, 0.1900, 0.2400, 0.2800, 0.2500, 0.2200, 0.4600,
        0.3100, 0.4000, 0.3500, 0.3500, 0.3200, 0.2600, 0.1900, 0.2600, 0.1900,
        0.2400, 0.2800, 0.2800, 0.2500, 0.2200, 0.2500, 0.3200, 0.2600, 0.1900,
        0.2400])
Epoch: 2, Steps: 1 | Train Loss: 0.0410110 Vali Loss: 0.0076485
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5079977512359619
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2378, 0.2300, 0.2432, 0.2203, 0.2120, 0.2050, 0.2400, 0.2524, 0.2449,
        0.1790, 0.2619, 0.1982, 0.2165, 0.1940, 0.2569, 0.2204, 0.2133, 0.2361,
        0.2269, 0.2320, 0.2407, 0.2255, 0.2200, 0.2544, 0.1459, 0.2035, 0.2651,
        0.2434, 0.2368, 0.2069, 0.2829, 0.2377, 0.1997, 0.2232, 0.2259, 0.2237,
        0.2422, 0.2114, 0.2203, 0.2202, 0.2460, 0.1930, 0.2113, 0.2197, 0.2761,
        0.1846, 0.2786, 0.2162, 0.2315, 0.2099, 0.2385, 0.2176, 0.2393, 0.2136,
        0.2408, 0.1730, 0.3341, 0.1052, 0.2463, 0.2141, 0.2217, 0.2660, 0.1725,
        0.2556, 0.2609, 0.1973, 0.2519, 0.2190, 0.1974, 0.2254, 0.2158, 0.2149,
        0.2477, 0.1668, 0.2940, 0.2052, 0.2349, 0.2291, 0.2400, 0.2046, 0.2075,
        0.2376, 0.2457, 0.1770, 0.2096, 0.2167, 0.2453, 0.2073, 0.2096, 0.2338,
        0.2302, 0.2180, 0.2376, 0.2614, 0.3126, 0.1869, 0.2020, 0.2386, 0.2326,
        0.2522, 0.2330, 0.1864, 0.1967, 0.1887, 0.2407, 0.2428, 0.2347, 0.2075,
        0.2512, 0.1560, 0.2282, 0.2717, 0.2235, 0.2613, 0.2567, 0.2000, 0.2333,
        0.2066, 0.2320, 0.2636, 0.2269, 0.2439, 0.2023, 0.2451, 0.2278, 0.2378,
        0.2297, 0.2207, 0.2224, 0.2312, 0.2033, 0.2181, 0.2572, 0.1832, 0.2347,
        0.2921, 0.2252, 0.2069, 0.2278, 0.2137, 0.1875, 0.2424, 0.2079, 0.2300,
        0.1969, 0.2294, 0.2205, 0.2085, 0.2393, 0.1987, 0.2607, 0.2166, 0.2080,
        0.2278, 0.2229, 0.2186, 0.1591, 0.2144, 0.1444, 0.2459, 0.2382, 0.2324,
        0.1642, 0.2196, 0.2856, 0.1797, 0.2536, 0.2206, 0.2337, 0.2289, 0.2664,
        0.2157])
true tensor([0.2400, 0.2800, 0.2500, 0.2200, 0.2500, 0.2900, 0.2300, 0.2100, 0.2200,
        0.2500, 0.2900, 0.2300, 0.2500, 0.2200, 0.2500, 0.2900, 0.4000, 0.3500,
        0.3200, 0.2600, 0.2200, 0.2500, 0.2900, 0.2300, 0.2600, 0.1900, 0.2400,
        0.2800, 0.3100, 0.4000, 0.3500, 0.3200, 0.2500, 0.2200, 0.2500, 0.2900,
        0.3100, 0.4000, 0.3500, 0.3200, 0.3200, 0.2600, 0.1900, 0.2400, 0.2600,
        0.1900, 0.2400, 0.2800, 0.3200, 0.2600, 0.1900, 0.2400, 0.2800, 0.2500,
        0.2200, 0.2500, 0.2300, 0.2100, 0.4100, 0.2400, 0.4000, 0.3500, 0.3200,
        0.2600, 0.2100, 0.4100, 0.2400, 0.1200, 0.2300, 0.2100, 0.4100, 0.2400,
        0.2900, 0.2300, 0.2100, 0.4100, 0.1900, 0.2400, 0.2800, 0.2500, 0.2500,
        0.2900, 0.2300, 0.2100, 0.1900, 0.2400, 0.2800, 0.2500, 0.2500, 0.2900,
        0.2300, 0.2100, 0.3500, 0.3200, 0.2600, 0.1900, 0.3200, 0.2600, 0.1900,
        0.2400, 0.1900, 0.2400, 0.2800, 0.2500, 0.2900, 0.2300, 0.2100, 0.4100,
        0.2200, 0.2500, 0.2900, 0.2300, 0.2400, 0.2800, 0.2500, 0.2200, 0.2100,
        0.4100, 0.2400, 0.1200, 0.2500, 0.2200, 0.2500, 0.2900, 0.2300, 0.2100,
        0.4100, 0.2400, 0.2600, 0.1900, 0.2400, 0.2800, 0.3100, 0.4000, 0.3500,
        0.3200, 0.3500, 0.3200, 0.2600, 0.1900, 0.2400, 0.2800, 0.2500, 0.2200,
        0.2900, 0.2300, 0.2100, 0.4100, 0.3500, 0.3200, 0.2600, 0.1900, 0.4000,
        0.3500, 0.3200, 0.2600, 0.4600, 0.3100, 0.4000, 0.3500, 0.2800, 0.2500,
        0.2200, 0.2500, 0.2800, 0.2500, 0.2200, 0.2500, 0.4600, 0.3100, 0.4000,
        0.3500])
Epoch: 3, Steps: 1 | Train Loss: 0.0406421 Vali Loss: 0.0075592
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
1it [00:00, 11.11it/s]
1it [00:00,  6.21it/s]
1it [00:00, 11.66it/s]
1it [00:00,  9.90it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.5075733661651611
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2242, 0.2131, 0.2386, 0.2594, 0.2638, 0.1937, 0.2235, 0.2378, 0.2133,
        0.2308, 0.2023, 0.2345, 0.2253, 0.2276, 0.2065, 0.2022, 0.2199, 0.1910,
        0.2763, 0.2307, 0.2146, 0.2046, 0.2603, 0.2372, 0.2263, 0.2261, 0.2144,
        0.1891, 0.1867, 0.2210, 0.1961, 0.2277, 0.2185, 0.1935, 0.2431, 0.2452,
        0.2419, 0.1805, 0.2433, 0.2495, 0.2222, 0.2158, 0.2428, 0.2386, 0.2455,
        0.2314, 0.2087, 0.2092, 0.1937, 0.2325, 0.2316, 0.2500, 0.1989, 0.2000,
        0.2523, 0.1889, 0.2156, 0.2194, 0.2155, 0.2085, 0.2344, 0.2635, 0.2482,
        0.2247, 0.1985, 0.2038, 0.2002, 0.2274, 0.2324, 0.1736, 0.2051, 0.2232,
        0.2435, 0.1910, 0.2189, 0.1994, 0.2433, 0.1642, 0.2382, 0.2238, 0.2467,
        0.2255, 0.2480, 0.2199, 0.2214, 0.2404, 0.2511, 0.2283, 0.2327, 0.2383,
        0.2093, 0.2350, 0.1825, 0.2341, 0.2597, 0.2513, 0.2106, 0.2676, 0.2203,
        0.1834, 0.2050, 0.1719, 0.1946, 0.2333, 0.2447, 0.2197, 0.2312, 0.2036,
        0.1972, 0.2261, 0.2152, 0.2542, 0.2169, 0.2474, 0.2032, 0.2243, 0.2327,
        0.2285, 0.2486, 0.2305, 0.2255, 0.2197, 0.2255, 0.2311, 0.2591, 0.1806,
        0.2431, 0.2768, 0.2143, 0.2448, 0.1985, 0.2105, 0.1952, 0.2457, 0.2366,
        0.2489, 0.2314, 0.2013, 0.2332, 0.1941, 0.3047, 0.2192, 0.2656, 0.2526,
        0.2484, 0.1702, 0.2174, 0.2676, 0.2317, 0.2171, 0.2069, 0.2151, 0.2034,
        0.2703, 0.2397, 0.2003, 0.2660, 0.1645, 0.2059, 0.1851, 0.1697, 0.2601,
        0.2181, 0.2419, 0.2072, 0.2058, 0.2229, 0.2214, 0.2414, 0.2512, 0.2556,
        0.2301])
true tensor([0.2100, 0.4100, 0.2400, 0.1200, 0.2500, 0.2200, 0.2500, 0.2900, 0.2400,
        0.2800, 0.2500, 0.2200, 0.1900, 0.2400, 0.2800, 0.2500, 0.2100, 0.4100,
        0.2400, 0.1200, 0.3500, 0.3200, 0.2600, 0.1900, 0.2600, 0.1900, 0.2400,
        0.2800, 0.4600, 0.3100, 0.4000, 0.3500, 0.2200, 0.2500, 0.2900, 0.2300,
        0.2200, 0.2500, 0.2900, 0.2300, 0.3100, 0.4000, 0.3500, 0.3200, 0.2800,
        0.2500, 0.2200, 0.2500, 0.3200, 0.2600, 0.1900, 0.2400, 0.1900, 0.2400,
        0.2800, 0.2500, 0.2500, 0.2900, 0.2300, 0.2100, 0.2400, 0.2800, 0.2500,
        0.2200, 0.1900, 0.2400, 0.2800, 0.2500, 0.4600, 0.3100, 0.4000, 0.3500,
        0.2800, 0.2500, 0.2200, 0.2500, 0.2600, 0.1900, 0.2400, 0.2800, 0.2800,
        0.2500, 0.2200, 0.2500, 0.2500, 0.2200, 0.2500, 0.2900, 0.2300, 0.2100,
        0.4100, 0.2400, 0.2200, 0.2500, 0.2900, 0.2300, 0.2500, 0.2900, 0.2300,
        0.2100, 0.3200, 0.2600, 0.1900, 0.2400, 0.3100, 0.4000, 0.3500, 0.3200,
        0.2500, 0.2900, 0.2300, 0.2100, 0.3500, 0.3200, 0.2600, 0.1900, 0.2400,
        0.2800, 0.2500, 0.2200, 0.4000, 0.3500, 0.3200, 0.2600, 0.3100, 0.4000,
        0.3500, 0.3200, 0.4000, 0.3500, 0.3200, 0.2600, 0.2600, 0.1900, 0.2400,
        0.2800, 0.3500, 0.3200, 0.2600, 0.1900, 0.2300, 0.2100, 0.4100, 0.2400,
        0.2900, 0.2300, 0.2100, 0.4100, 0.4000, 0.3500, 0.3200, 0.2600, 0.2500,
        0.2200, 0.2500, 0.2900, 0.2900, 0.2300, 0.2100, 0.4100, 0.2300, 0.2100,
        0.4100, 0.2400, 0.3200, 0.2600, 0.1900, 0.2400, 0.2900, 0.2300, 0.2100,
        0.4100])
Epoch: 4, Steps: 1 | Train Loss: 0.0402252 Vali Loss: 0.0073014
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 170) (1, 170)
test shape: (1, 1, 170) (1, 1, 170)
mae:0.0970, mse:0.0124, rmse:0.1114, r2:-2.6374
mse_mean = 0.0124, mse_std = 0.0000
r2_mean = -2.6374, mae_std = 0.0000