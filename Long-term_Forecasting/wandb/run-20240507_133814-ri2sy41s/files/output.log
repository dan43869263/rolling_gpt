['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.10s/it]
1it [00:00, 11.32it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3790109157562256
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2122, 0.2092, 0.2380, 0.2224, 0.2270, 0.1888, 0.2588, 0.2332, 0.2375,
        0.2417, 0.2504, 0.2021, 0.1887, 0.2453, 0.2336, 0.2212, 0.2363, 0.2076,
        0.2258, 0.2304, 0.1872, 0.2343, 0.2186, 0.2089, 0.2436, 0.2247, 0.1912,
        0.2362, 0.2101, 0.2120, 0.2230, 0.2052, 0.2508, 0.2803, 0.2444, 0.2243,
        0.2380, 0.1942, 0.1853, 0.2149, 0.1884, 0.2390, 0.1769, 0.1927, 0.2371,
        0.2181, 0.1936, 0.2168, 0.2380, 0.2391, 0.2574, 0.2345, 0.2079, 0.2347,
        0.2342, 0.2074, 0.2493, 0.2067, 0.2601, 0.2080, 0.2307, 0.2472, 0.2251,
        0.2298, 0.1881, 0.2176, 0.2598, 0.2342, 0.1983, 0.2365, 0.1875, 0.2395,
        0.2274, 0.2237, 0.2225, 0.2356, 0.2159, 0.2345, 0.2390, 0.2228, 0.2675,
        0.2046, 0.2710, 0.2260, 0.2646, 0.2222, 0.2443, 0.2084, 0.2725, 0.2162,
        0.2481, 0.2339, 0.2772, 0.2150, 0.2285, 0.2295, 0.1837, 0.2067, 0.1963,
        0.2473, 0.2249, 0.1959, 0.2450, 0.2231, 0.2551, 0.2285, 0.2537, 0.1879,
        0.2447, 0.2136, 0.2277, 0.2314, 0.2096, 0.2612, 0.2292, 0.2082, 0.2215,
        0.3002, 0.1908, 0.3442, 0.2421, 0.2046, 0.2361, 0.2296, 0.2213, 0.2308,
        0.2295, 0.2225, 0.2392, 0.2249, 0.2093, 0.2249, 0.2387, 0.2213, 0.2108,
        0.2052, 0.1917, 0.2091, 0.1865, 0.2634, 0.2239, 0.2098, 0.1778, 0.2476,
        0.2012, 0.2643, 0.2529, 0.1843, 0.2029, 0.2490, 0.1988, 0.2372, 0.2426,
        0.2357, 0.2621, 0.2381, 0.1880, 0.2087, 0.1947, 0.2075, 0.2138, 0.1923,
        0.2372, 0.1796, 0.2734, 0.2419, 0.2546, 0.2214, 0.2164, 0.2102, 0.2340,
        0.2415])
true tensor([0.3650, 0.3800, 0.4300, 0.2950, 0.3100, 0.3400, 0.2500, 0.3000, 0.3100,
        0.3400, 0.2500, 0.3000, 0.2700, 0.3100, 0.3400, 0.2500, 0.2350, 0.2700,
        0.3100, 0.3400, 0.2925, 0.3075, 0.2850, 0.3650, 0.4300, 0.2950, 0.3800,
        0.3900, 0.3800, 0.4300, 0.2950, 0.3800, 0.2850, 0.2350, 0.2700, 0.3100,
        0.2500, 0.3000, 0.2925, 0.3075, 0.3000, 0.2925, 0.3075, 0.2850, 0.2950,
        0.3800, 0.3900, 0.5450, 0.3400, 0.2500, 0.3000, 0.2925, 0.3650, 0.3800,
        0.4300, 0.2950, 0.2850, 0.3650, 0.3800, 0.4300, 0.2700, 0.3100, 0.3400,
        0.2500, 0.4300, 0.2950, 0.3800, 0.3900, 0.3075, 0.2850, 0.3650, 0.3800,
        0.3000, 0.2925, 0.3075, 0.2850, 0.2950, 0.3800, 0.3900, 0.5450, 0.2500,
        0.3000, 0.2925, 0.3075, 0.4300, 0.2950, 0.3800, 0.3900, 0.2850, 0.3650,
        0.3800, 0.4300, 0.3400, 0.2500, 0.3000, 0.2925, 0.3800, 0.4300, 0.2950,
        0.3800, 0.2850, 0.2350, 0.2700, 0.3100, 0.2925, 0.3075, 0.2850, 0.3650,
        0.3650, 0.3800, 0.4300, 0.2950, 0.3400, 0.2500, 0.3000, 0.2925, 0.2350,
        0.2700, 0.3100, 0.3400, 0.2950, 0.3800, 0.3900, 0.5450, 0.3000, 0.2925,
        0.3075, 0.2850, 0.3075, 0.2850, 0.3650, 0.3800, 0.3800, 0.4300, 0.2950,
        0.3800, 0.2925, 0.3075, 0.2850, 0.3650, 0.2850, 0.3650, 0.3800, 0.4300,
        0.3800, 0.3900, 0.5450, 0.3700, 0.3800, 0.3900, 0.5450, 0.3700, 0.3075,
        0.2850, 0.3650, 0.3800, 0.2700, 0.3100, 0.3400, 0.2500, 0.3100, 0.3400,
        0.2500, 0.3000, 0.2350, 0.2700, 0.3100, 0.3400, 0.2500, 0.3000, 0.2925,
        0.3075])
Epoch: 1, Steps: 1 | Train Loss: 0.0323490 Vali Loss: 0.0160460
lr = 0.0000975531
Validation loss decreased (inf --> 0.016046).  Saving model ...
1it [00:00,  5.59it/s]
1it [00:00, 11.54it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5216469764709473
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2587, 0.2013, 0.2712, 0.2699, 0.2092, 0.2123, 0.2301, 0.1975, 0.2650,
        0.2353, 0.2627, 0.2247, 0.2188, 0.1942, 0.1441, 0.2350, 0.2402, 0.2094,
        0.2539, 0.2261, 0.2347, 0.2270, 0.2179, 0.2365, 0.2779, 0.1814, 0.2766,
        0.2635, 0.2447, 0.2303, 0.1863, 0.2163, 0.2417, 0.2330, 0.2125, 0.2057,
        0.2092, 0.2389, 0.2297, 0.2323, 0.2238, 0.2031, 0.2453, 0.2918, 0.2202,
        0.2422, 0.2079, 0.2689, 0.2251, 0.2150, 0.2268, 0.2309, 0.2702, 0.1815,
        0.2330, 0.2565, 0.1492, 0.2314, 0.1973, 0.2363, 0.2179, 0.2510, 0.2367,
        0.2161, 0.2256, 0.2088, 0.2364, 0.2009, 0.2027, 0.2406, 0.1935, 0.2127,
        0.2448, 0.2140, 0.1802, 0.2229, 0.2425, 0.2316, 0.2448, 0.2155, 0.2427,
        0.1981, 0.1936, 0.2502, 0.2389, 0.2038, 0.2385, 0.2711, 0.1742, 0.2077,
        0.1866, 0.1884, 0.2286, 0.2031, 0.2329, 0.2286, 0.2259, 0.2363, 0.2167,
        0.2334, 0.2155, 0.2446, 0.2427, 0.2075, 0.2417, 0.2310, 0.2301, 0.2209,
        0.2186, 0.2257, 0.2293, 0.2295, 0.2224, 0.2282, 0.2248, 0.2239, 0.2081,
        0.2318, 0.2326, 0.2271, 0.2620, 0.2012, 0.2275, 0.2348, 0.2233, 0.2417,
        0.2280, 0.2077, 0.2346, 0.2167, 0.2251, 0.2343, 0.2237, 0.2022, 0.2361,
        0.2313, 0.2203, 0.2112, 0.2284, 0.2054, 0.2027, 0.2029, 0.2149, 0.2772,
        0.1878, 0.2134, 0.2423, 0.2005, 0.2390, 0.2110, 0.1991, 0.2093, 0.2041,
        0.2132, 0.2377, 0.2291, 0.2367, 0.2305, 0.2397, 0.1993, 0.2379, 0.2123,
        0.2092, 0.2331, 0.2497, 0.2095, 0.2280, 0.2001, 0.1942, 0.2439, 0.2355,
        0.2400])
true tensor([0.3075, 0.2850, 0.3650, 0.3800, 0.3650, 0.3800, 0.4300, 0.2950, 0.2350,
        0.2700, 0.3100, 0.3400, 0.2925, 0.3075, 0.2850, 0.3650, 0.2700, 0.3100,
        0.3400, 0.2500, 0.2950, 0.3800, 0.3900, 0.5450, 0.2850, 0.3650, 0.3800,
        0.4300, 0.4300, 0.2950, 0.3800, 0.3900, 0.3075, 0.2850, 0.3650, 0.3800,
        0.3400, 0.2500, 0.3000, 0.2925, 0.2850, 0.2350, 0.2700, 0.3100, 0.3800,
        0.3900, 0.5450, 0.3700, 0.3100, 0.3400, 0.2500, 0.3000, 0.3400, 0.2500,
        0.3000, 0.2925, 0.2700, 0.3100, 0.3400, 0.2500, 0.3000, 0.2925, 0.3075,
        0.2850, 0.3800, 0.4300, 0.2950, 0.3800, 0.2700, 0.3100, 0.3400, 0.2500,
        0.2950, 0.3800, 0.3900, 0.5450, 0.3800, 0.3900, 0.5450, 0.3700, 0.2350,
        0.2700, 0.3100, 0.3400, 0.4300, 0.2950, 0.3800, 0.3900, 0.3000, 0.2925,
        0.3075, 0.2850, 0.4300, 0.2950, 0.3800, 0.3900, 0.2850, 0.3650, 0.3800,
        0.4300, 0.2925, 0.3075, 0.2850, 0.3650, 0.2950, 0.3800, 0.3900, 0.5450,
        0.3800, 0.4300, 0.2950, 0.3800, 0.3000, 0.2925, 0.3075, 0.2850, 0.2850,
        0.3650, 0.3800, 0.4300, 0.2500, 0.3000, 0.2925, 0.3075, 0.3800, 0.4300,
        0.2950, 0.3800, 0.3650, 0.3800, 0.4300, 0.2950, 0.2350, 0.2700, 0.3100,
        0.3400, 0.3650, 0.3800, 0.4300, 0.2950, 0.2500, 0.3000, 0.2925, 0.3075,
        0.3100, 0.3400, 0.2500, 0.3000, 0.2925, 0.3075, 0.2850, 0.3650, 0.2850,
        0.2350, 0.2700, 0.3100, 0.3100, 0.3400, 0.2500, 0.3000, 0.2500, 0.3000,
        0.2925, 0.3075, 0.3075, 0.2850, 0.3650, 0.3800, 0.3400, 0.2500, 0.3000,
        0.2925])
Epoch: 2, Steps: 1 | Train Loss: 0.0323783 Vali Loss: 0.0157160
lr = 0.0000904518
Validation loss decreased (0.016046 --> 0.015716).  Saving model ...
1it [00:00,  5.52it/s]
1it [00:00, 10.12it/s]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5393555164337158
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2054, 0.2144, 0.2095, 0.2155, 0.2241, 0.2205, 0.2404, 0.2191, 0.2520,
        0.1987, 0.2296, 0.1924, 0.2179, 0.2365, 0.2141, 0.2290, 0.1784, 0.2038,
        0.2035, 0.2133, 0.2076, 0.2265, 0.2190, 0.2248, 0.1586, 0.2181, 0.2068,
        0.1933, 0.2532, 0.2149, 0.2525, 0.2621, 0.2371, 0.2148, 0.2334, 0.2313,
        0.2103, 0.2114, 0.2123, 0.2495, 0.2583, 0.2017, 0.2074, 0.2322, 0.2577,
        0.1844, 0.2655, 0.1944, 0.2459, 0.1999, 0.2466, 0.2480, 0.2306, 0.2098,
        0.2247, 0.2331, 0.2210, 0.2010, 0.2099, 0.2135, 0.2352, 0.2465, 0.2313,
        0.2176, 0.2519, 0.2065, 0.2543, 0.2355, 0.2218, 0.2289, 0.2341, 0.2142,
        0.2420, 0.2125, 0.2631, 0.1938, 0.2159, 0.2562, 0.2410, 0.2093, 0.2283,
        0.2387, 0.2644, 0.1839, 0.1945, 0.2356, 0.2257, 0.2223, 0.2150, 0.2091,
        0.2233, 0.2485, 0.2466, 0.2426, 0.2737, 0.1879, 0.2075, 0.2438, 0.1995,
        0.2616, 0.2400, 0.1806, 0.1667, 0.1986, 0.2616, 0.2218, 0.2285, 0.2055,
        0.2359, 0.1697, 0.2133, 0.2498, 0.2294, 0.2536, 0.2462, 0.2117, 0.2190,
        0.2475, 0.2193, 0.2288, 0.2086, 0.2249, 0.2216, 0.2756, 0.2590, 0.2148,
        0.2428, 0.2154, 0.2671, 0.2042, 0.2252, 0.2292, 0.2709, 0.2260, 0.2526,
        0.2294, 0.2288, 0.1978, 0.2392, 0.2000, 0.1645, 0.2291, 0.2265, 0.2403,
        0.2021, 0.2185, 0.2614, 0.2701, 0.2274, 0.1814, 0.2598, 0.2262, 0.1961,
        0.2445, 0.2208, 0.2078, 0.1947, 0.2327, 0.2077, 0.2436, 0.2412, 0.2320,
        0.1768, 0.2121, 0.2995, 0.2169, 0.2887, 0.2453, 0.2291, 0.2317, 0.2829,
        0.2357])
true tensor([0.2925, 0.3075, 0.2850, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.3650,
        0.3800, 0.4300, 0.2950, 0.2850, 0.3650, 0.3800, 0.4300, 0.2700, 0.3100,
        0.3400, 0.2500, 0.3650, 0.3800, 0.4300, 0.2950, 0.2500, 0.3000, 0.2925,
        0.3075, 0.2350, 0.2700, 0.3100, 0.3400, 0.2850, 0.3650, 0.3800, 0.4300,
        0.2350, 0.2700, 0.3100, 0.3400, 0.3400, 0.2500, 0.3000, 0.2925, 0.2500,
        0.3000, 0.2925, 0.3075, 0.3400, 0.2500, 0.3000, 0.2925, 0.3075, 0.2850,
        0.3650, 0.3800, 0.2950, 0.3800, 0.3900, 0.5450, 0.2700, 0.3100, 0.3400,
        0.2500, 0.3800, 0.3900, 0.5450, 0.3700, 0.2950, 0.3800, 0.3900, 0.5450,
        0.4300, 0.2950, 0.3800, 0.3900, 0.3000, 0.2925, 0.3075, 0.2850, 0.3800,
        0.4300, 0.2950, 0.3800, 0.3000, 0.2925, 0.3075, 0.2850, 0.3800, 0.4300,
        0.2950, 0.3800, 0.3100, 0.3400, 0.2500, 0.3000, 0.3400, 0.2500, 0.3000,
        0.2925, 0.3000, 0.2925, 0.3075, 0.2850, 0.4300, 0.2950, 0.3800, 0.3900,
        0.3650, 0.3800, 0.4300, 0.2950, 0.2925, 0.3075, 0.2850, 0.3650, 0.3800,
        0.3900, 0.5450, 0.3700, 0.2850, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800,
        0.3900, 0.5450, 0.2500, 0.3000, 0.2925, 0.3075, 0.2350, 0.2700, 0.3100,
        0.3400, 0.3100, 0.3400, 0.2500, 0.3000, 0.2925, 0.3075, 0.2850, 0.3650,
        0.4300, 0.2950, 0.3800, 0.3900, 0.3100, 0.3400, 0.2500, 0.3000, 0.2700,
        0.3100, 0.3400, 0.2500, 0.2850, 0.2350, 0.2700, 0.3100, 0.3075, 0.2850,
        0.3650, 0.3800, 0.3075, 0.2850, 0.3650, 0.3800, 0.2850, 0.2350, 0.2700,
        0.3100])
Epoch: 3, Steps: 1 | Train Loss: 0.0321481 Vali Loss: 0.0157749
lr = 0.0000793913
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.4983851909637451
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2113, 0.2249, 0.2312, 0.2100, 0.2353, 0.2075, 0.2161, 0.2824, 0.1950,
        0.1967, 0.1916, 0.2621, 0.2075, 0.2376, 0.2302, 0.2037, 0.2221, 0.2013,
        0.2632, 0.2209, 0.2169, 0.1908, 0.2368, 0.2548, 0.2656, 0.1892, 0.2192,
        0.1947, 0.2101, 0.2288, 0.2205, 0.2344, 0.1979, 0.2289, 0.2256, 0.2276,
        0.2148, 0.1873, 0.2373, 0.2192, 0.2413, 0.2061, 0.2502, 0.2510, 0.2359,
        0.2028, 0.2224, 0.2017, 0.2088, 0.2380, 0.2247, 0.2662, 0.2105, 0.2310,
        0.2214, 0.2450, 0.2357, 0.2025, 0.2162, 0.2450, 0.2429, 0.2499, 0.2495,
        0.2233, 0.1752, 0.2279, 0.1828, 0.2223, 0.2268, 0.2121, 0.2199, 0.2078,
        0.2542, 0.2169, 0.2584, 0.2387, 0.2613, 0.1575, 0.2481, 0.2029, 0.2532,
        0.2240, 0.2302, 0.2209, 0.2328, 0.2241, 0.2330, 0.2109, 0.2435, 0.2195,
        0.2217, 0.2319, 0.1955, 0.2328, 0.2055, 0.2600, 0.2640, 0.2142, 0.2241,
        0.1941, 0.2211, 0.1851, 0.1942, 0.2253, 0.2274, 0.2153, 0.2168, 0.2281,
        0.2061, 0.2213, 0.2588, 0.2111, 0.2213, 0.2430, 0.2142, 0.2068, 0.2182,
        0.2257, 0.2340, 0.2063, 0.2325, 0.2176, 0.2674, 0.2015, 0.2976, 0.2205,
        0.2707, 0.2124, 0.1994, 0.2127, 0.1768, 0.2114, 0.2018, 0.2219, 0.2256,
        0.2450, 0.2212, 0.1874, 0.2363, 0.1925, 0.2102, 0.2130, 0.2167, 0.2422,
        0.2285, 0.2291, 0.2104, 0.2672, 0.1878, 0.2360, 0.2245, 0.2085, 0.2201,
        0.2511, 0.2448, 0.2107, 0.2185, 0.2213, 0.2299, 0.2349, 0.1862, 0.2418,
        0.2385, 0.2743, 0.2213, 0.2431, 0.2409, 0.2252, 0.2651, 0.2289, 0.2436,
        0.2038])
true tensor([0.3800, 0.3900, 0.5450, 0.3700, 0.2850, 0.3650, 0.3800, 0.4300, 0.2925,
        0.3075, 0.2850, 0.3650, 0.3000, 0.2925, 0.3075, 0.2850, 0.3800, 0.3900,
        0.5450, 0.3700, 0.3100, 0.3400, 0.2500, 0.3000, 0.2500, 0.3000, 0.2925,
        0.3075, 0.2850, 0.2350, 0.2700, 0.3100, 0.3650, 0.3800, 0.4300, 0.2950,
        0.3650, 0.3800, 0.4300, 0.2950, 0.2350, 0.2700, 0.3100, 0.3400, 0.3075,
        0.2850, 0.3650, 0.3800, 0.3400, 0.2500, 0.3000, 0.2925, 0.3000, 0.2925,
        0.3075, 0.2850, 0.3800, 0.4300, 0.2950, 0.3800, 0.2925, 0.3075, 0.2850,
        0.3650, 0.3000, 0.2925, 0.3075, 0.2850, 0.2850, 0.2350, 0.2700, 0.3100,
        0.3075, 0.2850, 0.3650, 0.3800, 0.2500, 0.3000, 0.2925, 0.3075, 0.3075,
        0.2850, 0.3650, 0.3800, 0.2850, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800,
        0.3900, 0.5450, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.4300, 0.2950,
        0.3800, 0.3400, 0.2500, 0.3000, 0.2925, 0.2350, 0.2700, 0.3100, 0.3400,
        0.3800, 0.4300, 0.2950, 0.3800, 0.3100, 0.3400, 0.2500, 0.3000, 0.2925,
        0.3075, 0.2850, 0.3650, 0.2700, 0.3100, 0.3400, 0.2500, 0.2350, 0.2700,
        0.3100, 0.3400, 0.2700, 0.3100, 0.3400, 0.2500, 0.2500, 0.3000, 0.2925,
        0.3075, 0.3100, 0.3400, 0.2500, 0.3000, 0.2950, 0.3800, 0.3900, 0.5450,
        0.4300, 0.2950, 0.3800, 0.3900, 0.2700, 0.3100, 0.3400, 0.2500, 0.2850,
        0.3650, 0.3800, 0.4300, 0.4300, 0.2950, 0.3800, 0.3900, 0.2950, 0.3800,
        0.3900, 0.5450, 0.3400, 0.2500, 0.3000, 0.2925, 0.4300, 0.2950, 0.3800,
        0.3900])
Epoch: 4, Steps: 1 | Train Loss: 0.0316849 Vali Loss: 0.0156755
lr = 0.0000654543
1it [00:00,  6.21it/s]
1it [00:00, 11.81it/s]
1it [00:00,  6.36it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.5016722679138184
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2383, 0.2398, 0.2252, 0.2133, 0.2198, 0.2410, 0.2164, 0.2269, 0.2352,
        0.2045, 0.2080, 0.2425, 0.2268, 0.1991, 0.2519, 0.1950, 0.2355, 0.2296,
        0.2422, 0.2271, 0.2283, 0.2100, 0.2327, 0.2192, 0.2334, 0.2143, 0.2426,
        0.2520, 0.2060, 0.2352, 0.2367, 0.2303, 0.2182, 0.2138, 0.2024, 0.2299,
        0.2153, 0.2274, 0.2250, 0.2095, 0.2002, 0.2116, 0.2358, 0.2177, 0.2804,
        0.2469, 0.2600, 0.2300, 0.2704, 0.2275, 0.2197, 0.2247, 0.1781, 0.2245,
        0.1885, 0.2124, 0.2070, 0.2084, 0.2283, 0.2109, 0.2579, 0.1921, 0.2108,
        0.2410, 0.2046, 0.2189, 0.2081, 0.2459, 0.2140, 0.2270, 0.2211, 0.2347,
        0.2284, 0.2025, 0.2193, 0.2395, 0.2482, 0.1904, 0.2148, 0.1880, 0.2015,
        0.2242, 0.2660, 0.1810, 0.2189, 0.2167, 0.2354, 0.2140, 0.2294, 0.1866,
        0.2407, 0.1889, 0.2371, 0.2109, 0.1845, 0.2264, 0.2271, 0.2169, 0.2218,
        0.2543, 0.1783, 0.1920, 0.1704, 0.2609, 0.2261, 0.2383, 0.2287, 0.2432,
        0.2029, 0.1949, 0.2410, 0.2451, 0.2492, 0.2151, 0.2228, 0.2089, 0.2299,
        0.2218, 0.2127, 0.1926, 0.2141, 0.2361, 0.2489, 0.2241, 0.1343, 0.3058,
        0.1651, 0.0707, 0.2206, 0.2352, 0.2348, 0.2244, 0.2498, 0.2016, 0.2294,
        0.2264, 0.2177, 0.1893, 0.1951, 0.2200, 0.1706, 0.2553, 0.2160, 0.2194,
        0.2500, 0.2108, 0.2230, 0.2186, 0.2259, 0.2418, 0.2112, 0.2149, 0.1664,
        0.2124, 0.2007, 0.2263, 0.2183, 0.2164, 0.2065, 0.2233, 0.2086, 0.2234,
        0.2293, 0.2014, 0.2204, 0.2187, 0.2151, 0.2523, 0.2261, 0.2012, 0.2418,
        0.1850])
true tensor([0.2925, 0.3075, 0.2850, 0.3650, 0.2950, 0.3800, 0.3900, 0.5450, 0.3400,
        0.2500, 0.3000, 0.2925, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.3900,
        0.5450, 0.3700, 0.2700, 0.3100, 0.3400, 0.2500, 0.4300, 0.2950, 0.3800,
        0.3900, 0.3000, 0.2925, 0.3075, 0.2850, 0.2950, 0.3800, 0.3900, 0.5450,
        0.2350, 0.2700, 0.3100, 0.3400, 0.3650, 0.3800, 0.4300, 0.2950, 0.2350,
        0.2700, 0.3100, 0.3400, 0.3100, 0.3400, 0.2500, 0.3000, 0.3000, 0.2925,
        0.3075, 0.2850, 0.3800, 0.4300, 0.2950, 0.3800, 0.2500, 0.3000, 0.2925,
        0.3075, 0.2500, 0.3000, 0.2925, 0.3075, 0.3650, 0.3800, 0.4300, 0.2950,
        0.3075, 0.2850, 0.3650, 0.3800, 0.2500, 0.3000, 0.2925, 0.3075, 0.3000,
        0.2925, 0.3075, 0.2850, 0.3100, 0.3400, 0.2500, 0.3000, 0.3100, 0.3400,
        0.2500, 0.3000, 0.3800, 0.4300, 0.2950, 0.3800, 0.2850, 0.3650, 0.3800,
        0.4300, 0.3800, 0.4300, 0.2950, 0.3800, 0.3075, 0.2850, 0.3650, 0.3800,
        0.2850, 0.2350, 0.2700, 0.3100, 0.2950, 0.3800, 0.3900, 0.5450, 0.2925,
        0.3075, 0.2850, 0.3650, 0.3400, 0.2500, 0.3000, 0.2925, 0.3800, 0.3900,
        0.5450, 0.3700, 0.2850, 0.3650, 0.3800, 0.4300, 0.2350, 0.2700, 0.3100,
        0.3400, 0.4300, 0.2950, 0.3800, 0.3900, 0.2700, 0.3100, 0.3400, 0.2500,
        0.2850, 0.3650, 0.3800, 0.4300, 0.3400, 0.2500, 0.3000, 0.2925, 0.2700,
        0.3100, 0.3400, 0.2500, 0.3075, 0.2850, 0.3650, 0.3800, 0.4300, 0.2950,
        0.3800, 0.3900, 0.2925, 0.3075, 0.2850, 0.3650, 0.2850, 0.2350, 0.2700,
        0.3100])
Epoch: 5, Steps: 1 | Train Loss: 0.0298128 Vali Loss: 0.0171956
lr = 0.0000500050
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 6 cost time: 0.5050632953643799
1it [00:00, 12.47it/s]
1it [00:00,  5.95it/s]
1it [00:00, 12.44it/s]
1it [00:00,  5.64it/s]
1it [00:00, 11.15it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2466, 0.2261, 0.2674, 0.2217, 0.2586, 0.2135, 0.2240, 0.1901, 0.2258,
        0.1806, 0.2283, 0.1599, 0.1784, 0.2304, 0.1841, 0.2165, 0.2515, 0.2438,
        0.2331, 0.2040, 0.2396, 0.2157, 0.2194, 0.2004, 0.2101, 0.2128, 0.2256,
        0.2527, 0.2120, 0.2436, 0.2442, 0.2172, 0.2242, 0.2235, 0.2076, 0.1880,
        0.2175, 0.1934, 0.2172, 0.2236, 0.2357, 0.1665, 0.1036, 0.2681, 0.2425,
        0.2234, 0.2147, 0.2343, 0.2320, 0.2102, 0.2108, 0.2438, 0.2634, 0.2028,
        0.2247, 0.2144, 0.2693, 0.2211, 0.2497, 0.2128, 0.1818, 0.2192, 0.2141,
        0.2153, 0.2405, 0.2443, 0.2058, 0.2191, 0.2611, 0.2405, 0.2423, 0.2083,
        0.2342, 0.1778, 0.2236, 0.2423, 0.2175, 0.2196, 0.2496, 0.2546, 0.2419,
        0.2250, 0.2313, 0.2157, 0.2333, 0.2193, 0.2369, 0.2094, 0.2263, 0.2062,
        0.2218, 0.2434, 0.2204, 0.1977, 0.2195, 0.2027, 0.2294, 0.2133, 0.2379,
        0.2254, 0.2191, 0.2187, 0.2267, 0.2020, 0.2320, 0.2223, 0.2786, 0.2091,
        0.1986, 0.2068, 0.2196, 0.2360, 0.2030, 0.2236, 0.2440, 0.1955, 0.2408,
        0.2198, 0.2428, 0.2176, 0.2356, 0.2262, 0.2363, 0.2070, 0.2308, 0.1790,
        0.2238, 0.2389, 0.2282, 0.2280, 0.2093, 0.2495, 0.2328, 0.2288, 0.2346,
        0.2241, 0.2241, 0.2422, 0.2388, 0.2098, 0.2193, 0.2439, 0.2204, 0.2409,
        0.2707, 0.2228, 0.2490, 0.2394, 0.2372, 0.2097, 0.2504, 0.2586, 0.2522,
        0.2234, 0.2571, 0.2242, 0.2030, 0.2211, 0.1726, 0.2328, 0.1396, 0.3161,
        0.1882, 0.1777, 0.2390, 0.2008, 0.2496, 0.2264, 0.1869, 0.2353, 0.1963,
        0.2239])
true tensor([0.3075, 0.2850, 0.3650, 0.3800, 0.3800, 0.4300, 0.2950, 0.3800, 0.3650,
        0.3800, 0.4300, 0.2950, 0.2700, 0.3100, 0.3400, 0.2500, 0.2925, 0.3075,
        0.2850, 0.3650, 0.2925, 0.3075, 0.2850, 0.3650, 0.2850, 0.3650, 0.3800,
        0.4300, 0.3400, 0.2500, 0.3000, 0.2925, 0.3650, 0.3800, 0.4300, 0.2950,
        0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.4300, 0.2950, 0.3800, 0.3075,
        0.2850, 0.3650, 0.3800, 0.3400, 0.2500, 0.3000, 0.2925, 0.2500, 0.3000,
        0.2925, 0.3075, 0.3100, 0.3400, 0.2500, 0.3000, 0.2950, 0.3800, 0.3900,
        0.5450, 0.3800, 0.3900, 0.5450, 0.3700, 0.2500, 0.3000, 0.2925, 0.3075,
        0.2350, 0.2700, 0.3100, 0.3400, 0.2850, 0.2350, 0.2700, 0.3100, 0.2850,
        0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.3900, 0.5450, 0.2950, 0.3800,
        0.3900, 0.5450, 0.3075, 0.2850, 0.3650, 0.3800, 0.2350, 0.2700, 0.3100,
        0.3400, 0.3000, 0.2925, 0.3075, 0.2850, 0.3100, 0.3400, 0.2500, 0.3000,
        0.2925, 0.3075, 0.2850, 0.3650, 0.2850, 0.2350, 0.2700, 0.3100, 0.4300,
        0.2950, 0.3800, 0.3900, 0.3400, 0.2500, 0.3000, 0.2925, 0.3100, 0.3400,
        0.2500, 0.3000, 0.2500, 0.3000, 0.2925, 0.3075, 0.2700, 0.3100, 0.3400,
        0.2500, 0.3000, 0.2925, 0.3075, 0.2850, 0.2700, 0.3100, 0.3400, 0.2500,
        0.2350, 0.2700, 0.3100, 0.3400, 0.4300, 0.2950, 0.3800, 0.3900, 0.4300,
        0.2950, 0.3800, 0.3900, 0.3000, 0.2925, 0.3075, 0.2850, 0.3800, 0.3900,
        0.5450, 0.3700, 0.2850, 0.3650, 0.3800, 0.4300, 0.3800, 0.4300, 0.2950,
        0.3800])
Epoch: 6, Steps: 1 | Train Loss: 0.0307122 Vali Loss: 0.0165286
lr = 0.0000345557
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 7 cost time: 0.5119283199310303
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2505, 0.2066, 0.2165, 0.2281, 0.2075, 0.2186, 0.2261, 0.2061, 0.2256,
        0.1986, 0.2266, 0.1966, 0.2312, 0.2222, 0.2093, 0.2206, 0.2388, 0.1783,
        0.2296, 0.1963, 0.2269, 0.2168, 0.2305, 0.2320, 0.2256, 0.2116, 0.2269,
        0.2366, 0.2171, 0.2167, 0.2236, 0.2124, 0.2352, 0.1854, 0.2229, 0.2604,
        0.2211, 0.2039, 0.2297, 0.2025, 0.2218, 0.1984, 0.2181, 0.2447, 0.2530,
        0.2237, 0.2325, 0.1974, 0.2059, 0.2432, 0.2271, 0.2186, 0.2040, 0.2110,
        0.2326, 0.1980, 0.2138, 0.2257, 0.2156, 0.2093, 0.2349, 0.2284, 0.2428,
        0.2425, 0.2096, 0.2180, 0.2565, 0.2341, 0.2635, 0.1982, 0.2451, 0.2109,
        0.2217, 0.2068, 0.2304, 0.1833, 0.2305, 0.2288, 0.2126, 0.2222, 0.2039,
        0.2249, 0.2007, 0.2405, 0.2295, 0.2394, 0.2364, 0.2273, 0.2239, 0.2546,
        0.2722, 0.2516, 0.2462, 0.1882, 0.2347, 0.2377, 0.2337, 0.2512, 0.2243,
        0.2068, 0.2190, 0.2249, 0.2325, 0.2283, 0.1949, 0.2102, 0.1776, 0.2382,
        0.1849, 0.2394, 0.1784, 0.2140, 0.2040, 0.2157, 0.2616, 0.2236, 0.1966,
        0.1913, 0.2137, 0.2322, 0.2304, 0.2520, 0.2370, 0.2090, 0.2474, 0.2054,
        0.2373, 0.1983, 0.2537, 0.2119, 0.2799, 0.2212, 0.2392, 0.1984, 0.2300,
        0.2413, 0.2355, 0.1511, 0.2101, 0.1712, 0.1629, 0.2007, 0.1440, 0.2431,
        0.2685, 0.2283, 0.2543, 0.2094, 0.2296, 0.2449, 0.2248, 0.1816, 0.2599,
        0.2090, 0.2249, 0.2197, 0.2242, 0.2165, 0.2620, 0.2569, 0.2122, 0.2425,
        0.2708, 0.2522, 0.2117, 0.2366, 0.2161, 0.2215, 0.2108, 0.2345, 0.2232,
        0.2053])
true tensor([0.2500, 0.3000, 0.2925, 0.3075, 0.2500, 0.3000, 0.2925, 0.3075, 0.4300,
        0.2950, 0.3800, 0.3900, 0.2500, 0.3000, 0.2925, 0.3075, 0.3650, 0.3800,
        0.4300, 0.2950, 0.2850, 0.3650, 0.3800, 0.4300, 0.2350, 0.2700, 0.3100,
        0.3400, 0.3075, 0.2850, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.3900,
        0.2925, 0.3075, 0.2850, 0.3650, 0.3400, 0.2500, 0.3000, 0.2925, 0.2850,
        0.3650, 0.3800, 0.4300, 0.2700, 0.3100, 0.3400, 0.2500, 0.3100, 0.3400,
        0.2500, 0.3000, 0.2350, 0.2700, 0.3100, 0.3400, 0.2950, 0.3800, 0.3900,
        0.5450, 0.2700, 0.3100, 0.3400, 0.2500, 0.3800, 0.4300, 0.2950, 0.3800,
        0.3800, 0.4300, 0.2950, 0.3800, 0.3000, 0.2925, 0.3075, 0.2850, 0.2950,
        0.3800, 0.3900, 0.5450, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800, 0.3900,
        0.5450, 0.3700, 0.3100, 0.3400, 0.2500, 0.3000, 0.3400, 0.2500, 0.3000,
        0.2925, 0.2850, 0.3650, 0.3800, 0.4300, 0.3800, 0.4300, 0.2950, 0.3800,
        0.2700, 0.3100, 0.3400, 0.2500, 0.3400, 0.2500, 0.3000, 0.2925, 0.3650,
        0.3800, 0.4300, 0.2950, 0.3000, 0.2925, 0.3075, 0.2850, 0.2950, 0.3800,
        0.3900, 0.5450, 0.3075, 0.2850, 0.3650, 0.3800, 0.4300, 0.2950, 0.3800,
        0.3900, 0.3000, 0.2925, 0.3075, 0.2850, 0.2925, 0.3075, 0.2850, 0.3650,
        0.2350, 0.2700, 0.3100, 0.3400, 0.3100, 0.3400, 0.2500, 0.3000, 0.3075,
        0.2850, 0.3650, 0.3800, 0.2850, 0.2350, 0.2700, 0.3100, 0.2850, 0.2350,
        0.2700, 0.3100, 0.3800, 0.3900, 0.5450, 0.3700, 0.2925, 0.3075, 0.2850,
        0.3650])
Epoch: 7, Steps: 1 | Train Loss: 0.0300052 Vali Loss: 0.0162120
lr = 0.0000206187
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 371) (1, 371)
test shape: (1, 1, 371) (1, 1, 371)
mae:0.5050, mse:0.2855, rmse:0.5343, r2:-2.7710
mse_mean = 0.2855, mse_std = 0.0000
r2_mean = -2.7710, mae_std = 0.0000
1it [00:00, 10.51it/s]