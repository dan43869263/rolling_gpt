['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.10s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.397367000579834
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2011, 0.1884, 0.2659, 0.2287, 0.1234, 0.2320, 0.2768, 0.2605, 0.1647,
        0.2294, 0.2480, 0.1627, 0.1747, 0.2110, 0.2845, 0.1724, 0.2582, 0.2549,
        0.2938, 0.1098, 0.2079, 0.2157, 0.2312, 0.1974, 0.2122, 0.2969, 0.1733,
        0.2547, 0.2338, 0.2359, 0.2343, 0.2564, 0.1845, 0.2312, 0.2297, 0.2972,
        0.2542, 0.1812, 0.2044, 0.2121, 0.1977, 0.2426, 0.1885, 0.2005, 0.2535,
        0.2514, 0.2468, 0.2125, 0.1817, 0.1606, 0.2326, 0.3087, 0.2275, 0.2419,
        0.2124, 0.2147, 0.2701, 0.2080, 0.2529, 0.2253, 0.2100, 0.2101, 0.2420,
        0.2260, 0.1900, 0.2960, 0.1727, 0.1563, 0.1958, 0.2497, 0.2073, 0.2735,
        0.1820, 0.2276, 0.2661, 0.1577, 0.2290, 0.2194, 0.1955, 0.1669, 0.2343,
        0.2175, 0.2461, 0.2369, 0.2354, 0.2400, 0.2644, 0.2261, 0.2824, 0.2167,
        0.2299, 0.1558, 0.1962, 0.1974, 0.2178, 0.1532, 0.2676, 0.1633, 0.2193,
        0.1816, 0.2587, 0.0937, 0.2244, 0.2079, 0.2664, 0.2563, 0.2565, 0.2049,
        0.2536, 0.1859, 0.2349, 0.2504, 0.1634, 0.1568, 0.2924, 0.1730, 0.2831,
        0.2560, 0.2881, 0.2313, 0.2354, 0.2225, 0.2295, 0.1988, 0.2172, 0.2286,
        0.2040, 0.2316, 0.2362, 0.2239, 0.2157, 0.2935, 0.2669, 0.2130, 0.2048,
        0.2790, 0.2500, 0.2462, 0.2511, 0.2099, 0.2516, 0.2244, 0.1713, 0.2429,
        0.1957, 0.2681, 0.2179, 0.1924, 0.2609, 0.2302, 0.1971, 0.2334, 0.2557,
        0.2481, 0.2637, 0.1596, 0.1426, 0.1769, 0.2511, 0.2989, 0.2125, 0.2046,
        0.2223, 0.2052, 0.1882, 0.1970, 0.2629, 0.2649, 0.2271, 0.1901, 0.2341,
        0.1680])
true tensor([0.2100, 0.2600, 0.2300, 0.2300, 0.2600, 0.2200, 0.2500, 0.2100, 0.2600,
        0.2200, 0.2500, 0.2100, 0.2100, 0.2600, 0.2200, 0.2500, 0.3000, 0.2100,
        0.2600, 0.2200, 0.2600, 0.2100, 0.2600, 0.2100, 0.2300, 0.2300, 0.1900,
        0.1900, 0.2600, 0.2300, 0.2300, 0.1900, 0.2200, 0.3000, 0.2100, 0.2600,
        0.2500, 0.2100, 0.2600, 0.2100, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300,
        0.1900, 0.1900, 0.2000, 0.2200, 0.2500, 0.2100, 0.2600, 0.2100, 0.2600,
        0.2300, 0.2300, 0.2600, 0.2100, 0.2600, 0.2300, 0.2100, 0.2600, 0.2200,
        0.2500, 0.2300, 0.2300, 0.1900, 0.1900, 0.2100, 0.2600, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2100, 0.2600, 0.2300, 0.1900, 0.1900, 0.2000, 0.2500,
        0.2100, 0.2600, 0.2100, 0.2300, 0.2300, 0.1900, 0.1900, 0.2600, 0.2100,
        0.2600, 0.2300, 0.2200, 0.2500, 0.2100, 0.2600, 0.2600, 0.2300, 0.2300,
        0.1900, 0.2200, 0.3000, 0.2100, 0.2600, 0.2600, 0.2100, 0.2600, 0.2100,
        0.2100, 0.2600, 0.2300, 0.2300, 0.2200, 0.2500, 0.2100, 0.2600, 0.3000,
        0.2100, 0.2600, 0.2200, 0.2300, 0.1900, 0.1900, 0.2000, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2600, 0.2300, 0.2300,
        0.1900, 0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300,
        0.1900, 0.1900, 0.2000, 0.2000, 0.1900, 0.1900, 0.2000, 0.2000, 0.2100,
        0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2200, 0.2500, 0.2600, 0.2200,
        0.2500, 0.2100, 0.3000, 0.2100, 0.2600, 0.2200, 0.2500, 0.2100, 0.2600,
        0.2100])
Epoch: 1, Steps: 1 | Train Loss: 0.0234302 Vali Loss: 0.0021437
lr = 0.0000975531
1it [00:00, 11.45it/s]
1it [00:00,  5.78it/s]
1it [00:00, 11.98it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5227131843566895
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2141, 0.2562, 0.2551, 0.1861, 0.2073, 0.1581, 0.2282, 0.2068, 0.2040,
        0.1703, 0.2699, 0.2906, 0.2525, 0.2104, 0.1757, 0.1974, 0.2261, 0.1870,
        0.1838, 0.1995, 0.2164, 0.2664, 0.1808, 0.2308, 0.3403, 0.1539, 0.2256,
        0.2215, 0.2307, 0.2408, 0.2529, 0.2048, 0.2408, 0.2285, 0.2240, 0.2293,
        0.2034, 0.1842, 0.1865, 0.2545, 0.0978, 0.1386, 0.2106, 0.3421, 0.2984,
        0.2106, 0.2328, 0.2652, 0.1066, 0.1920, 0.2359, 0.2610, 0.1490, 0.2073,
        0.2782, 0.2062, 0.0762, 0.1710, 0.2097, 0.2859, 0.2300, 0.2349, 0.2508,
        0.2054, 0.2504, 0.1882, 0.2573, 0.2022, 0.2449, 0.1633, 0.1857, 0.1631,
        0.2437, 0.2838, 0.2252, 0.2142, 0.2229, 0.2741, 0.2153, 0.2259, 0.2297,
        0.2227, 0.2288, 0.1757, 0.2339, 0.2936, 0.1729, 0.1660, 0.2390, 0.2490,
        0.2088, 0.1424, 0.2185, 0.2762, 0.1298, 0.2677, 0.2298, 0.2550, 0.2535,
        0.2590, 0.2209, 0.2601, 0.2205, 0.2412, 0.2182, 0.2156, 0.1799, 0.2270,
        0.3098, 0.1608, 0.2514, 0.1894, 0.2033, 0.2823, 0.1856, 0.2582, 0.2461,
        0.2346, 0.2228, 0.2549, 0.2455, 0.1989, 0.2363, 0.2395, 0.2453, 0.2471,
        0.2043, 0.2795, 0.2416, 0.2250, 0.2176, 0.2663, 0.2153, 0.2114, 0.2744,
        0.1082, 0.2191, 0.1937, 0.2796, 0.2297, 0.1516, 0.1546, 0.2302, 0.2292,
        0.2055, 0.1056, 0.2731, 0.2245, 0.2386, 0.2507, 0.1938, 0.2444, 0.2756,
        0.1163, 0.2326, 0.1694, 0.2091, 0.2337, 0.2201, 0.2591, 0.2271, 0.2477,
        0.2165, 0.2621, 0.2700, 0.2001, 0.2066, 0.2839, 0.1500, 0.2240, 0.1968,
        0.3268])
true tensor([0.2100, 0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300, 0.2300, 0.3000,
        0.2100, 0.2600, 0.2200, 0.2600, 0.2100, 0.2600, 0.2100, 0.2100, 0.2600,
        0.2200, 0.2500, 0.2300, 0.1900, 0.1900, 0.2000, 0.2600, 0.2100, 0.2600,
        0.2300, 0.2300, 0.2300, 0.1900, 0.1900, 0.2100, 0.2600, 0.2100, 0.2600,
        0.2200, 0.2500, 0.2100, 0.2600, 0.2200, 0.3000, 0.2100, 0.2600, 0.1900,
        0.1900, 0.2000, 0.2000, 0.2600, 0.2200, 0.2500, 0.2100, 0.2200, 0.2500,
        0.2100, 0.2600, 0.2100, 0.2600, 0.2200, 0.2500, 0.2100, 0.2600, 0.2100,
        0.2600, 0.2600, 0.2300, 0.2300, 0.1900, 0.2100, 0.2600, 0.2200, 0.2500,
        0.2300, 0.1900, 0.1900, 0.2000, 0.1900, 0.1900, 0.2000, 0.2000, 0.3000,
        0.2100, 0.2600, 0.2200, 0.2300, 0.2300, 0.1900, 0.1900, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2300, 0.2300, 0.1900, 0.1900, 0.2600, 0.2100, 0.2600,
        0.2300, 0.2600, 0.2100, 0.2600, 0.2100, 0.2300, 0.1900, 0.1900, 0.2000,
        0.2600, 0.2300, 0.2300, 0.1900, 0.2100, 0.2600, 0.2100, 0.2600, 0.2600,
        0.2100, 0.2600, 0.2300, 0.2500, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300,
        0.2300, 0.1900, 0.2100, 0.2600, 0.2300, 0.2300, 0.3000, 0.2100, 0.2600,
        0.2200, 0.2100, 0.2600, 0.2300, 0.2300, 0.2500, 0.2100, 0.2600, 0.2100,
        0.2600, 0.2200, 0.2500, 0.2100, 0.2600, 0.2100, 0.2600, 0.2100, 0.2200,
        0.3000, 0.2100, 0.2600, 0.2600, 0.2200, 0.2500, 0.2100, 0.2500, 0.2100,
        0.2600, 0.2100, 0.2100, 0.2600, 0.2100, 0.2600, 0.2200, 0.2500, 0.2100,
        0.2600])
Epoch: 2, Steps: 1 | Train Loss: 0.0230918 Vali Loss: 0.0028028
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5155882835388184
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2152, 0.2173, 0.2149, 0.2127, 0.2336, 0.2020, 0.2373, 0.2343, 0.2269,
        0.2239, 0.2419, 0.2216, 0.2458, 0.2211, 0.2380, 0.2224, 0.1278, 0.2190,
        0.2223, 0.2578, 0.2531, 0.2577, 0.2192, 0.2388, 0.2465, 0.1802, 0.2683,
        0.1734, 0.2950, 0.2278, 0.2883, 0.2127, 0.2561, 0.1939, 0.2354, 0.2211,
        0.1745, 0.1624, 0.2316, 0.1414, 0.1683, 0.1508, 0.2518, 0.1658, 0.2132,
        0.2889, 0.2033, 0.1730, 0.2203, 0.1533, 0.1915, 0.2960, 0.2225, 0.2216,
        0.2337, 0.2304, 0.2508, 0.2229, 0.2411, 0.2637, 0.2196, 0.2232, 0.2354,
        0.1892, 0.2507, 0.2203, 0.2462, 0.2483, 0.2197, 0.2401, 0.1983, 0.2212,
        0.2650, 0.2311, 0.2435, 0.2156, 0.2637, 0.2566, 0.2749, 0.2391, 0.2626,
        0.2035, 0.2923, 0.2412, 0.2070, 0.2237, 0.2229, 0.2310, 0.2599, 0.2094,
        0.2825, 0.1899, 0.1610, 0.2006, 0.2342, 0.1466, 0.1963, 0.1913, 0.1963,
        0.1815, 0.2531, 0.2145, 0.1897, 0.2021, 0.2383, 0.2596, 0.2036, 0.2331,
        0.1707, 0.1770, 0.2188, 0.1929, 0.2485, 0.2555, 0.2263, 0.2386, 0.2215,
        0.2501, 0.2494, 0.2158, 0.1755, 0.2257, 0.2833, 0.1110, 0.2254, 0.2129,
        0.2199, 0.1794, 0.2325, 0.2369, 0.0779, 0.3322, 0.1574, 0.1895, 0.2312,
        0.2325, 0.2049, 0.1242, 0.2433, 0.1862, 0.2075, 0.2399, 0.2315, 0.2391,
        0.2500, 0.2673, 0.1840, 0.1652, 0.1307, 0.1917, 0.2166, 0.2280, 0.1538,
        0.1986, 0.2358, 0.1403, 0.1867, 0.2177, 0.1490, 0.2264, 0.2327, 0.2040,
        0.1601, 0.2599, 0.2731, 0.2356, 0.3115, 0.2083, 0.2411, 0.0938, 0.3188,
        0.1718])
true tensor([0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300, 0.2300, 0.1900, 0.2100,
        0.2600, 0.2300, 0.2300, 0.2600, 0.2100, 0.2600, 0.2300, 0.2100, 0.2600,
        0.2200, 0.2500, 0.2100, 0.2600, 0.2300, 0.2300, 0.2500, 0.2100, 0.2600,
        0.2100, 0.3000, 0.2100, 0.2600, 0.2200, 0.2600, 0.2100, 0.2600, 0.2300,
        0.3000, 0.2100, 0.2600, 0.2200, 0.2200, 0.2500, 0.2100, 0.2600, 0.2500,
        0.2100, 0.2600, 0.2100, 0.2200, 0.2500, 0.2100, 0.2600, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2300, 0.1900, 0.1900, 0.2000, 0.2100, 0.2600, 0.2200,
        0.2500, 0.1900, 0.1900, 0.2000, 0.2000, 0.2300, 0.1900, 0.1900, 0.2000,
        0.2300, 0.2300, 0.1900, 0.1900, 0.2100, 0.2600, 0.2100, 0.2600, 0.2600,
        0.2300, 0.2300, 0.1900, 0.2100, 0.2600, 0.2100, 0.2600, 0.2600, 0.2300,
        0.2300, 0.1900, 0.2600, 0.2200, 0.2500, 0.2100, 0.2200, 0.2500, 0.2100,
        0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300, 0.2300, 0.1900, 0.1900,
        0.2100, 0.2600, 0.2300, 0.2300, 0.2600, 0.2100, 0.2600, 0.2100, 0.1900,
        0.1900, 0.2000, 0.2000, 0.2600, 0.2100, 0.2600, 0.2300, 0.2300, 0.1900,
        0.1900, 0.2000, 0.2500, 0.2100, 0.2600, 0.2100, 0.3000, 0.2100, 0.2600,
        0.2200, 0.2600, 0.2200, 0.2500, 0.2100, 0.2600, 0.2100, 0.2600, 0.2100,
        0.2300, 0.2300, 0.1900, 0.1900, 0.2600, 0.2200, 0.2500, 0.2100, 0.2100,
        0.2600, 0.2200, 0.2500, 0.2200, 0.3000, 0.2100, 0.2600, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2100, 0.2600, 0.2100, 0.2600, 0.2200, 0.3000, 0.2100,
        0.2600])
Epoch: 3, Steps: 1 | Train Loss: 0.0211889 Vali Loss: 0.0026739
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
1it [00:00,  5.42it/s]
1it [00:00, 11.97it/s]
1it [00:00,  6.34it/s]
1it [00:00, 11.73it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.4993398189544678
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2528, 0.2075, 0.2710, 0.2097, 0.2405, 0.2287, 0.2134, 0.2483, 0.2448,
        0.2001, 0.2190, 0.2545, 0.2907, 0.2312, 0.2547, 0.1936, 0.2147, 0.2422,
        0.2372, 0.2621, 0.2112, 0.2165, 0.2105, 0.2971, 0.1654, 0.2186, 0.1266,
        0.2413, 0.1688, 0.2270, 0.2317, 0.3040, 0.1994, 0.2216, 0.2539, 0.2415,
        0.1997, 0.2159, 0.2286, 0.2323, 0.2127, 0.2318, 0.2625, 0.2185, 0.2399,
        0.1974, 0.2660, 0.2356, 0.2063, 0.1761, 0.1725, 0.1964, 0.2107, 0.2731,
        0.2456, 0.2517, 0.2976, 0.1806, 0.2428, 0.2015, 0.2763, 0.2634, 0.2677,
        0.2484, 0.1750, 0.2492, 0.2009, 0.2234, 0.2442, 0.1994, 0.1410, 0.1986,
        0.2841, 0.2271, 0.2708, 0.1962, 0.1399, 0.1994, 0.3140, 0.1932, 0.2442,
        0.2261, 0.2212, 0.2661, 0.2260, 0.2671, 0.2862, 0.2498, 0.2248, 0.2558,
        0.2184, 0.1752, 0.1658, 0.2067, 0.1885, 0.2719, 0.2923, 0.2166, 0.2164,
        0.2339, 0.1520, 0.1270, 0.2536, 0.2231, 0.2082, 0.1688, 0.2422, 0.1960,
        0.2236, 0.2519, 0.2382, 0.2541, 0.2107, 0.2374, 0.2125, 0.2265, 0.2469,
        0.2363, 0.2648, 0.2148, 0.2276, 0.0702, 0.3152, 0.1128, 0.2408, 0.2147,
        0.2662, 0.2621, 0.2081, 0.1872, 0.2029, 0.2160, 0.2254, 0.2158, 0.2317,
        0.2411, 0.2029, 0.1557, 0.2605, 0.2159, 0.2292, 0.2336, 0.2248, 0.2576,
        0.2372, 0.2594, 0.1848, 0.1820, 0.1389, 0.1772, 0.1676, 0.1520, 0.2909,
        0.2361, 0.2424, 0.2049, 0.2133, 0.2636, 0.1986, 0.2612, 0.1689, 0.2596,
        0.2069, 0.2565, 0.2048, 0.2475, 0.2176, 0.2415, 0.2130, 0.2585, 0.2833,
        0.2467])
true tensor([0.1900, 0.1900, 0.2000, 0.2000, 0.2600, 0.2100, 0.2600, 0.2300, 0.2600,
        0.2100, 0.2600, 0.2100, 0.2100, 0.2600, 0.2100, 0.2600, 0.1900, 0.1900,
        0.2000, 0.2000, 0.2600, 0.2200, 0.2500, 0.2100, 0.2500, 0.2100, 0.2600,
        0.2100, 0.2200, 0.3000, 0.2100, 0.2600, 0.2100, 0.2600, 0.2300, 0.2300,
        0.2100, 0.2600, 0.2300, 0.2300, 0.3000, 0.2100, 0.2600, 0.2200, 0.2100,
        0.2600, 0.2100, 0.2600, 0.2200, 0.2500, 0.2100, 0.2600, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2600, 0.2300, 0.2300, 0.1900, 0.2600, 0.2100, 0.2600,
        0.2100, 0.2100, 0.2600, 0.2100, 0.2600, 0.2200, 0.3000, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2100, 0.2600, 0.2500, 0.2100, 0.2600, 0.2100, 0.2100,
        0.2600, 0.2100, 0.2600, 0.2600, 0.2100, 0.2600, 0.2300, 0.2300, 0.1900,
        0.1900, 0.2000, 0.2100, 0.2600, 0.2300, 0.2300, 0.2600, 0.2300, 0.2300,
        0.1900, 0.2200, 0.2500, 0.2100, 0.2600, 0.3000, 0.2100, 0.2600, 0.2200,
        0.2600, 0.2300, 0.2300, 0.1900, 0.2600, 0.2200, 0.2500, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2100, 0.2100, 0.2600, 0.2200, 0.2500, 0.3000, 0.2100,
        0.2600, 0.2200, 0.2100, 0.2600, 0.2200, 0.2500, 0.2500, 0.2100, 0.2600,
        0.2100, 0.2600, 0.2200, 0.2500, 0.2100, 0.2300, 0.1900, 0.1900, 0.2000,
        0.2300, 0.2300, 0.1900, 0.1900, 0.2100, 0.2600, 0.2200, 0.2500, 0.2600,
        0.2100, 0.2600, 0.2300, 0.2300, 0.2300, 0.1900, 0.1900, 0.2300, 0.1900,
        0.1900, 0.2000, 0.2200, 0.2500, 0.2100, 0.2600, 0.2300, 0.2300, 0.1900,
        0.1900])
Epoch: 4, Steps: 1 | Train Loss: 0.0214485 Vali Loss: 0.0023516
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 38) (1, 38)
test shape: (1, 1, 38) (1, 1, 38)
mae:0.1440, mse:0.0218, rmse:0.1477, r2:-19.1260
mse_mean = 0.0218, mse_std = 0.0000
r2_mean = -19.1260, mae_std = 0.0000
1it [00:00, 11.08it/s]