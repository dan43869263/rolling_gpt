['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.09s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3967328071594238
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2299, 0.1867, 0.2513, 0.1924, 0.2320, 0.2386, 0.2396, 0.2439, 0.2165,
        0.2253, 0.2228, 0.2461, 0.2442, 0.2370, 0.2115, 0.1989, 0.2309, 0.2450,
        0.2441, 0.2270, 0.2231, 0.2511, 0.2084, 0.2255, 0.2415, 0.2247, 0.2261,
        0.2252, 0.2216, 0.1970, 0.2211, 0.2263, 0.1873, 0.2262, 0.1978, 0.1631,
        0.1964, 0.2215, 0.2186, 0.1937, 0.2528, 0.1919, 0.2469, 0.2117, 0.2511,
        0.2393, 0.2224, 0.2119, 0.2531, 0.2034, 0.2489, 0.2071, 0.2427, 0.2526,
        0.2537, 0.2309, 0.2249, 0.2454, 0.2202, 0.2065, 0.2333, 0.2319, 0.2393,
        0.2210, 0.1637, 0.1759, 0.1577, 0.1653, 0.2300, 0.2426, 0.1744, 0.2376,
        0.2457, 0.2250, 0.2206, 0.2295, 0.2318, 0.2103, 0.2324, 0.2510, 0.2503,
        0.2041, 0.2351, 0.2336, 0.2183, 0.2364, 0.2368, 0.2429, 0.2309, 0.2100,
        0.2312, 0.2330, 0.2299, 0.2077, 0.2110, 0.2367, 0.2168, 0.2191, 0.2068,
        0.2223, 0.2367, 0.2060, 0.2295, 0.2425, 0.2357, 0.2297, 0.2461, 0.2121,
        0.2540, 0.1918, 0.2103, 0.2588, 0.2356, 0.2130, 0.2651, 0.2177, 0.2593,
        0.2248, 0.2599, 0.2126, 0.2108, 0.1909, 0.2465, 0.2049, 0.2267, 0.2392,
        0.2454, 0.2150, 0.2538, 0.2501, 0.2320, 0.2249, 0.2100, 0.2315, 0.2273,
        0.2327, 0.2324, 0.2707, 0.1972, 0.2518, 0.2317, 0.2174, 0.1972, 0.2344,
        0.2074, 0.2654, 0.2374, 0.2279, 0.2326, 0.2396, 0.1757, 0.2177, 0.2669,
        0.2313, 0.2129, 0.2436, 0.2054, 0.2134, 0.1987, 0.2255, 0.2270, 0.2253,
        0.2489, 0.2040, 0.2120, 0.2233, 0.2149, 0.2231, 0.2215, 0.2089, 0.3091,
        0.2454])
true tensor([ 0.1500,  0.1400,  0.2100,  0.3300, -0.0800, -0.0600,  0.2000,  0.1100,
        -0.0800, -0.0600,  0.2000,  0.1100, -0.1200, -0.0800, -0.0600,  0.2000,
        -0.0800, -0.1200, -0.0800, -0.0600,  0.0600,  0.1700,  0.2800,  0.1500,
         0.2100,  0.3300,  0.2700,  0.2100,  0.1400,  0.2100,  0.3300,  0.2700,
        -0.1800, -0.0800, -0.1200, -0.0800,  0.2000,  0.1100,  0.0600,  0.1700,
         0.1100,  0.0600,  0.1700,  0.2800,  0.3300,  0.2700,  0.2100,  0.3500,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.1500,  0.1400,  0.2100,  0.3300,
         0.2800,  0.1500,  0.1400,  0.2100, -0.1200, -0.0800, -0.0600,  0.2000,
         0.2100,  0.3300,  0.2700,  0.2100,  0.1700,  0.2800,  0.1500,  0.1400,
         0.1100,  0.0600,  0.1700,  0.2800,  0.3300,  0.2700,  0.2100,  0.3500,
         0.2000,  0.1100,  0.0600,  0.1700,  0.2100,  0.3300,  0.2700,  0.2100,
         0.2800,  0.1500,  0.1400,  0.2100, -0.0600,  0.2000,  0.1100,  0.0600,
         0.1400,  0.2100,  0.3300,  0.2700, -0.1800, -0.0800, -0.1200, -0.0800,
         0.0600,  0.1700,  0.2800,  0.1500,  0.1500,  0.1400,  0.2100,  0.3300,
        -0.0600,  0.2000,  0.1100,  0.0600, -0.0800, -0.1200, -0.0800, -0.0600,
         0.3300,  0.2700,  0.2100,  0.3500,  0.1100,  0.0600,  0.1700,  0.2800,
         0.1700,  0.2800,  0.1500,  0.1400,  0.1400,  0.2100,  0.3300,  0.2700,
         0.0600,  0.1700,  0.2800,  0.1500,  0.2800,  0.1500,  0.1400,  0.2100,
         0.2700,  0.2100,  0.3500,  0.4700,  0.2700,  0.2100,  0.3500,  0.4700,
         0.1700,  0.2800,  0.1500,  0.1400, -0.1200, -0.0800, -0.0600,  0.2000,
        -0.0800, -0.0600,  0.2000,  0.1100, -0.0800, -0.1200, -0.0800, -0.0600,
         0.2000,  0.1100,  0.0600,  0.1700])
Epoch: 1, Steps: 1 | Train Loss: 0.0336509 Vali Loss: 0.0289694
lr = 0.0000975531
1it [00:00, 11.44it/s]
1it [00:00,  5.55it/s]
1it [00:00, 12.70it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5334916114807129
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2945, 0.2202, 0.2540, 0.2512, 0.2498, 0.2108, 0.2841, 0.2268, 0.2113,
        0.2052, 0.2398, 0.2133, 0.2105, 0.1971, 0.1620, 0.2831, 0.1769, 0.2641,
        0.2445, 0.2567, 0.2246, 0.2126, 0.2297, 0.2016, 0.1918, 0.2198, 0.2871,
        0.2320, 0.2087, 0.2270, 0.2085, 0.2462, 0.2425, 0.2663, 0.1924, 0.2357,
        0.2308, 0.2286, 0.2468, 0.2207, 0.1980, 0.2242, 0.1989, 0.2135, 0.2668,
        0.2455, 0.2108, 0.2266, 0.2207, 0.2297, 0.2351, 0.2365, 0.2290, 0.1956,
        0.2111, 0.2547, 0.2031, 0.2214, 0.2039, 0.2375, 0.3103, 0.2187, 0.3110,
        0.2401, 0.2356, 0.1899, 0.2469, 0.2229, 0.2028, 0.2401, 0.2087, 0.1943,
        0.2229, 0.2165, 0.1961, 0.2216, 0.2352, 0.2275, 0.2192, 0.2366, 0.2318,
        0.2204, 0.2386, 0.2327, 0.1918, 0.1893, 0.2054, 0.2073, 0.2592, 0.1936,
        0.2210, 0.2266, 0.2536, 0.1981, 0.2312, 0.2067, 0.1950, 0.2433, 0.2226,
        0.2470, 0.2281, 0.2389, 0.2430, 0.1950, 0.2215, 0.1851, 0.2355, 0.2680,
        0.2295, 0.2269, 0.2554, 0.2200, 0.2203, 0.2273, 0.2267, 0.2256, 0.2256,
        0.2391, 0.2543, 0.2009, 0.2075, 0.2334, 0.1990, 0.2105, 0.1830, 0.2117,
        0.1988, 0.2391, 0.2319, 0.2137, 0.2019, 0.2666, 0.2392, 0.1700, 0.2835,
        0.2038, 0.2027, 0.1918, 0.2471, 0.2092, 0.2055, 0.2153, 0.2418, 0.2262,
        0.2249, 0.2105, 0.2446, 0.2165, 0.2354, 0.2447, 0.2061, 0.2330, 0.2380,
        0.2318, 0.2273, 0.2435, 0.2250, 0.2402, 0.2284, 0.2560, 0.2263, 0.2056,
        0.2342, 0.2245, 0.2429, 0.2550, 0.2275, 0.1854, 0.2371, 0.2300, 0.2325,
        0.1971])
true tensor([ 0.1700,  0.2800,  0.1500,  0.1400,  0.1500,  0.1400,  0.2100,  0.3300,
        -0.0800, -0.1200, -0.0800, -0.0600,  0.0600,  0.1700,  0.2800,  0.1500,
        -0.1200, -0.0800, -0.0600,  0.2000,  0.3300,  0.2700,  0.2100,  0.3500,
         0.2800,  0.1500,  0.1400,  0.2100,  0.2100,  0.3300,  0.2700,  0.2100,
         0.1700,  0.2800,  0.1500,  0.1400, -0.0600,  0.2000,  0.1100,  0.0600,
        -0.1800, -0.0800, -0.1200, -0.0800,  0.2700,  0.2100,  0.3500,  0.4700,
        -0.0800, -0.0600,  0.2000,  0.1100, -0.0600,  0.2000,  0.1100,  0.0600,
        -0.1200, -0.0800, -0.0600,  0.2000,  0.1100,  0.0600,  0.1700,  0.2800,
         0.1400,  0.2100,  0.3300,  0.2700, -0.1200, -0.0800, -0.0600,  0.2000,
         0.3300,  0.2700,  0.2100,  0.3500,  0.2700,  0.2100,  0.3500,  0.4700,
        -0.0800, -0.1200, -0.0800, -0.0600,  0.2100,  0.3300,  0.2700,  0.2100,
         0.1100,  0.0600,  0.1700,  0.2800,  0.2100,  0.3300,  0.2700,  0.2100,
         0.2800,  0.1500,  0.1400,  0.2100,  0.0600,  0.1700,  0.2800,  0.1500,
         0.3300,  0.2700,  0.2100,  0.3500,  0.1400,  0.2100,  0.3300,  0.2700,
         0.1100,  0.0600,  0.1700,  0.2800,  0.2800,  0.1500,  0.1400,  0.2100,
         0.2000,  0.1100,  0.0600,  0.1700,  0.1400,  0.2100,  0.3300,  0.2700,
         0.1500,  0.1400,  0.2100,  0.3300, -0.0800, -0.1200, -0.0800, -0.0600,
         0.1500,  0.1400,  0.2100,  0.3300,  0.2000,  0.1100,  0.0600,  0.1700,
        -0.0800, -0.0600,  0.2000,  0.1100,  0.0600,  0.1700,  0.2800,  0.1500,
        -0.1800, -0.0800, -0.1200, -0.0800, -0.0800, -0.0600,  0.2000,  0.1100,
         0.2000,  0.1100,  0.0600,  0.1700,  0.1700,  0.2800,  0.1500,  0.1400,
        -0.0600,  0.2000,  0.1100,  0.0600])
Epoch: 2, Steps: 1 | Train Loss: 0.0325038 Vali Loss: 0.0285892
lr = 0.0000904518
Validation loss decreased (0.028969 --> 0.028589).  Saving model ...
1it [00:00,  6.02it/s]
1it [00:00, 12.65it/s]
1it [00:00,  6.22it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.506000280380249
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2175, 0.2338, 0.2197, 0.2385, 0.2446, 0.1953, 0.2452, 0.2448, 0.2351,
        0.2061, 0.2430, 0.1944, 0.1934, 0.2413, 0.2055, 0.2074, 0.2135, 0.2312,
        0.2277, 0.2181, 0.2869, 0.1923, 0.1866, 0.2832, 0.1586, 0.2637, 0.3970,
        0.2256, 0.2457, 0.2089, 0.2491, 0.2193, 0.1871, 0.2372, 0.2292, 0.2258,
        0.2344, 0.2351, 0.2608, 0.2006, 0.2344, 0.1839, 0.2235, 0.2222, 0.2304,
        0.2031, 0.2625, 0.2149, 0.2447, 0.1961, 0.2459, 0.2085, 0.2239, 0.2244,
        0.2034, 0.2452, 0.2476, 0.2141, 0.2268, 0.2146, 0.2273, 0.2287, 0.2595,
        0.2234, 0.2607, 0.1816, 0.2468, 0.2183, 0.1741, 0.1821, 0.2015, 0.2114,
        0.2217, 0.2230, 0.2283, 0.1966, 0.2676, 0.2384, 0.2590, 0.1907, 0.2027,
        0.2031, 0.2018, 0.2625, 0.2208, 0.2345, 0.2292, 0.1939, 0.2075, 0.2370,
        0.2515, 0.2097, 0.2153, 0.2332, 0.2067, 0.2634, 0.2531, 0.1932, 0.2551,
        0.2195, 0.2411, 0.1534, 0.1866, 0.2042, 0.2162, 0.2293, 0.2189, 0.2062,
        0.2622, 0.1950, 0.3115, 0.2467, 0.2186, 0.2576, 0.2390, 0.1912, 0.2279,
        0.2143, 0.2318, 0.1818, 0.2216, 0.2333, 0.2302, 0.2659, 0.2315, 0.1910,
        0.2345, 0.2554, 0.2256, 0.2192, 0.2088, 0.2226, 0.2149, 0.1926, 0.2216,
        0.2176, 0.2269, 0.2296, 0.2331, 0.2180, 0.1984, 0.2511, 0.1671, 0.2404,
        0.2061, 0.1895, 0.2398, 0.2197, 0.2113, 0.2341, 0.2686, 0.1981, 0.2171,
        0.2211, 0.1990, 0.2319, 0.1813, 0.2206, 0.1975, 0.1965, 0.2466, 0.2556,
        0.1868, 0.2519, 0.2827, 0.1970, 0.2111, 0.1878, 0.2297, 0.2407, 0.2855,
        0.2349])
true tensor([ 0.0600,  0.1700,  0.2800,  0.1500,  0.1400,  0.2100,  0.3300,  0.2700,
         0.1500,  0.1400,  0.2100,  0.3300,  0.2800,  0.1500,  0.1400,  0.2100,
        -0.1200, -0.0800, -0.0600,  0.2000,  0.1500,  0.1400,  0.2100,  0.3300,
         0.2000,  0.1100,  0.0600,  0.1700, -0.0800, -0.1200, -0.0800, -0.0600,
         0.2800,  0.1500,  0.1400,  0.2100, -0.0800, -0.1200, -0.0800, -0.0600,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.2000,  0.1100,  0.0600,  0.1700,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.1700,  0.2800,  0.1500,  0.1400,
         0.3300,  0.2700,  0.2100,  0.3500, -0.1200, -0.0800, -0.0600,  0.2000,
         0.2700,  0.2100,  0.3500,  0.4700,  0.3300,  0.2700,  0.2100,  0.3500,
         0.2100,  0.3300,  0.2700,  0.2100,  0.1100,  0.0600,  0.1700,  0.2800,
         0.1400,  0.2100,  0.3300,  0.2700,  0.1100,  0.0600,  0.1700,  0.2800,
         0.1400,  0.2100,  0.3300,  0.2700, -0.0800, -0.0600,  0.2000,  0.1100,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.1100,  0.0600,  0.1700,  0.2800,
         0.2100,  0.3300,  0.2700,  0.2100,  0.1500,  0.1400,  0.2100,  0.3300,
         0.0600,  0.1700,  0.2800,  0.1500,  0.2700,  0.2100,  0.3500,  0.4700,
         0.2800,  0.1500,  0.1400,  0.2100,  0.3300,  0.2700,  0.2100,  0.3500,
         0.2000,  0.1100,  0.0600,  0.1700, -0.0800, -0.1200, -0.0800, -0.0600,
        -0.0800, -0.0600,  0.2000,  0.1100,  0.0600,  0.1700,  0.2800,  0.1500,
         0.2100,  0.3300,  0.2700,  0.2100, -0.0800, -0.0600,  0.2000,  0.1100,
        -0.1200, -0.0800, -0.0600,  0.2000, -0.1800, -0.0800, -0.1200, -0.0800,
         0.1700,  0.2800,  0.1500,  0.1400,  0.1700,  0.2800,  0.1500,  0.1400,
        -0.1800, -0.0800, -0.1200, -0.0800])
Epoch: 3, Steps: 1 | Train Loss: 0.0319278 Vali Loss: 0.0294572
lr = 0.0000793913
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.4943380355834961
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2402, 0.2027, 0.2489, 0.1959, 0.2585, 0.2107, 0.2326, 0.2088, 0.2314,
        0.2537, 0.1622, 0.2540, 0.2489, 0.2145, 0.2254, 0.2032, 0.2316, 0.2013,
        0.2363, 0.2480, 0.2143, 0.2351, 0.2372, 0.2283, 0.2060, 0.2407, 0.2160,
        0.1907, 0.1966, 0.2011, 0.1755, 0.2187, 0.2421, 0.2150, 0.2032, 0.2461,
        0.2359, 0.1787, 0.2632, 0.2407, 0.2184, 0.2315, 0.2412, 0.2266, 0.2651,
        0.2240, 0.2154, 0.2472, 0.2330, 0.1986, 0.2594, 0.2285, 0.2188, 0.2336,
        0.2412, 0.2093, 0.2277, 0.2388, 0.2538, 0.2316, 0.2211, 0.2439, 0.2055,
        0.1967, 0.2296, 0.1939, 0.2260, 0.2417, 0.2365, 0.2273, 0.2572, 0.2286,
        0.2592, 0.2287, 0.2244, 0.2403, 0.2418, 0.1731, 0.2190, 0.2207, 0.2418,
        0.2636, 0.2228, 0.2498, 0.1997, 0.2700, 0.1876, 0.2439, 0.2108, 0.2072,
        0.2382, 0.2461, 0.2204, 0.2321, 0.2554, 0.2819, 0.1950, 0.2061, 0.2097,
        0.2328, 0.1881, 0.2546, 0.1357, 0.2706, 0.2269, 0.2335, 0.2670, 0.2201,
        0.2257, 0.2050, 0.2532, 0.2170, 0.2059, 0.1842, 0.2389, 0.2339, 0.2440,
        0.2486, 0.2265, 0.2343, 0.2249, 0.2461, 0.2646, 0.2437, 0.2169, 0.2094,
        0.2516, 0.2049, 0.2108, 0.2119, 0.1934, 0.2113, 0.2292, 0.2150, 0.2456,
        0.2224, 0.2353, 0.2290, 0.2293, 0.2369, 0.2419, 0.2204, 0.2452, 0.2107,
        0.2352, 0.1910, 0.2154, 0.2208, 0.2504, 0.2289, 0.2294, 0.1903, 0.1857,
        0.2605, 0.2347, 0.2155, 0.2085, 0.2084, 0.1934, 0.2121, 0.2090, 0.2117,
        0.2644, 0.1954, 0.2517, 0.2098, 0.2457, 0.2380, 0.2184, 0.2433, 0.2502,
        0.2158])
true tensor([ 0.2700,  0.2100,  0.3500,  0.4700,  0.2800,  0.1500,  0.1400,  0.2100,
         0.0600,  0.1700,  0.2800,  0.1500,  0.1100,  0.0600,  0.1700,  0.2800,
         0.2700,  0.2100,  0.3500,  0.4700, -0.0800, -0.0600,  0.2000,  0.1100,
         0.2000,  0.1100,  0.0600,  0.1700, -0.1800, -0.0800, -0.1200, -0.0800,
         0.1500,  0.1400,  0.2100,  0.3300,  0.1500,  0.1400,  0.2100,  0.3300,
        -0.0800, -0.1200, -0.0800, -0.0600,  0.1700,  0.2800,  0.1500,  0.1400,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.1100,  0.0600,  0.1700,  0.2800,
         0.1400,  0.2100,  0.3300,  0.2700,  0.0600,  0.1700,  0.2800,  0.1500,
         0.1100,  0.0600,  0.1700,  0.2800, -0.1800, -0.0800, -0.1200, -0.0800,
         0.1700,  0.2800,  0.1500,  0.1400,  0.2000,  0.1100,  0.0600,  0.1700,
         0.1700,  0.2800,  0.1500,  0.1400,  0.2800,  0.1500,  0.1400,  0.2100,
         0.3300,  0.2700,  0.2100,  0.3500,  0.1500,  0.1400,  0.2100,  0.3300,
         0.1400,  0.2100,  0.3300,  0.2700, -0.0600,  0.2000,  0.1100,  0.0600,
        -0.0800, -0.1200, -0.0800, -0.0600,  0.1400,  0.2100,  0.3300,  0.2700,
        -0.0800, -0.0600,  0.2000,  0.1100,  0.0600,  0.1700,  0.2800,  0.1500,
        -0.1200, -0.0800, -0.0600,  0.2000, -0.0800, -0.1200, -0.0800, -0.0600,
        -0.1200, -0.0800, -0.0600,  0.2000,  0.2000,  0.1100,  0.0600,  0.1700,
        -0.0800, -0.0600,  0.2000,  0.1100,  0.3300,  0.2700,  0.2100,  0.3500,
         0.2100,  0.3300,  0.2700,  0.2100, -0.1200, -0.0800, -0.0600,  0.2000,
         0.2800,  0.1500,  0.1400,  0.2100,  0.2100,  0.3300,  0.2700,  0.2100,
         0.3300,  0.2700,  0.2100,  0.3500, -0.0600,  0.2000,  0.1100,  0.0600,
         0.2100,  0.3300,  0.2700,  0.2100])
Epoch: 4, Steps: 1 | Train Loss: 0.0324473 Vali Loss: 0.0286095
lr = 0.0000654543
EarlyStopping counter: 2 out of 3
1it [00:00, 11.74it/s]
1it [00:00,  5.93it/s]
1it [00:00, 12.26it/s]
1it [00:00, 10.43it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.499478816986084
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2479, 0.2159, 0.2321, 0.1827, 0.1910, 0.2264, 0.2169, 0.2233, 0.2418,
        0.1969, 0.2107, 0.2445, 0.2220, 0.2046, 0.2521, 0.2062, 0.2332, 0.2179,
        0.2221, 0.2356, 0.2368, 0.2600, 0.2246, 0.2403, 0.1659, 0.2204, 0.2124,
        0.2138, 0.2263, 0.2050, 0.2179, 0.1811, 0.2421, 0.2159, 0.2293, 0.2058,
        0.2344, 0.2546, 0.2290, 0.2003, 0.2590, 0.1732, 0.2807, 0.2694, 0.2267,
        0.2086, 0.2317, 0.2218, 0.2249, 0.2350, 0.2313, 0.2504, 0.2346, 0.1821,
        0.2096, 0.2301, 0.2056, 0.1874, 0.2405, 0.2275, 0.2118, 0.2517, 0.1998,
        0.1982, 0.2007, 0.2195, 0.2381, 0.2031, 0.2407, 0.2081, 0.1889, 0.2819,
        0.2764, 0.2229, 0.2633, 0.2115, 0.2460, 0.1942, 0.2428, 0.1834, 0.2263,
        0.2363, 0.2183, 0.2192, 0.2195, 0.2238, 0.2454, 0.2354, 0.2328, 0.2189,
        0.2532, 0.2001, 0.1441, 0.2141, 0.1423, 0.2468, 0.2032, 0.2463, 0.2562,
        0.1928, 0.1773, 0.3098, 0.2399, 0.1730, 0.2500, 0.2352, 0.1919, 0.2334,
        0.2193, 0.1922, 0.1905, 0.2043, 0.1993, 0.1872, 0.2373, 0.2526, 0.2210,
        0.2240, 0.2154, 0.2383, 0.2530, 0.1513, 0.2889, 0.2413, 0.2305, 0.2074,
        0.2439, 0.1086, 0.2105, 0.2477, 0.2301, 0.2238, 0.2464, 0.2190, 0.2242,
        0.2181, 0.2094, 0.1853, 0.2021, 0.2120, 0.2373, 0.2524, 0.2308, 0.1957,
        0.2390, 0.2184, 0.2161, 0.1972, 0.2562, 0.1998, 0.2735, 0.1886, 0.1858,
        0.2345, 0.2000, 0.2361, 0.2526, 0.2301, 0.2038, 0.2323, 0.2198, 0.2243,
        0.2459, 0.2128, 0.2184, 0.2094, 0.1800, 0.2590, 0.2404, 0.2332, 0.2320,
        0.2260])
true tensor([ 0.0600,  0.1700,  0.2800,  0.1500,  0.3300,  0.2700,  0.2100,  0.3500,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.1500,  0.1400,  0.2100,  0.3300,
         0.2700,  0.2100,  0.3500,  0.4700, -0.1200, -0.0800, -0.0600,  0.2000,
         0.2100,  0.3300,  0.2700,  0.2100,  0.1100,  0.0600,  0.1700,  0.2800,
         0.3300,  0.2700,  0.2100,  0.3500, -0.0800, -0.1200, -0.0800, -0.0600,
         0.1500,  0.1400,  0.2100,  0.3300, -0.0800, -0.1200, -0.0800, -0.0600,
        -0.0800, -0.0600,  0.2000,  0.1100,  0.1100,  0.0600,  0.1700,  0.2800,
         0.1400,  0.2100,  0.3300,  0.2700,  0.2000,  0.1100,  0.0600,  0.1700,
         0.2000,  0.1100,  0.0600,  0.1700,  0.1500,  0.1400,  0.2100,  0.3300,
         0.1700,  0.2800,  0.1500,  0.1400,  0.2000,  0.1100,  0.0600,  0.1700,
         0.1100,  0.0600,  0.1700,  0.2800, -0.0800, -0.0600,  0.2000,  0.1100,
        -0.0800, -0.0600,  0.2000,  0.1100,  0.1400,  0.2100,  0.3300,  0.2700,
         0.2800,  0.1500,  0.1400,  0.2100,  0.1400,  0.2100,  0.3300,  0.2700,
         0.1700,  0.2800,  0.1500,  0.1400, -0.1800, -0.0800, -0.1200, -0.0800,
         0.3300,  0.2700,  0.2100,  0.3500,  0.0600,  0.1700,  0.2800,  0.1500,
        -0.0600,  0.2000,  0.1100,  0.0600,  0.2700,  0.2100,  0.3500,  0.4700,
         0.2800,  0.1500,  0.1400,  0.2100, -0.0800, -0.1200, -0.0800, -0.0600,
         0.2100,  0.3300,  0.2700,  0.2100, -0.1200, -0.0800, -0.0600,  0.2000,
         0.2800,  0.1500,  0.1400,  0.2100, -0.0600,  0.2000,  0.1100,  0.0600,
        -0.1200, -0.0800, -0.0600,  0.2000,  0.1700,  0.2800,  0.1500,  0.1400,
         0.2100,  0.3300,  0.2700,  0.2100,  0.0600,  0.1700,  0.2800,  0.1500,
        -0.1800, -0.0800, -0.1200, -0.0800])
Epoch: 5, Steps: 1 | Train Loss: 0.0311477 Vali Loss: 0.0293457
lr = 0.0000500050
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 371) (1, 371)
test shape: (1, 1, 371) (1, 1, 371)
mae:0.4833, mse:0.2675, rmse:0.5172, r2:-5.9298
mse_mean = 0.2675, mse_std = 0.0000
r2_mean = -5.9298, mae_std = 0.0000