['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.12s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3926968574523926
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.1836, 0.1961, 0.2200, 0.2394, 0.2211, 0.2221, 0.2124, 0.2405, 0.1873,
        0.2279, 0.2329, 0.1836, 0.2159, 0.2366, 0.2346, 0.2092, 0.2379, 0.2286,
        0.2361, 0.2336, 0.2252, 0.2670, 0.2576, 0.1884, 0.2333, 0.1973, 0.2163,
        0.1969, 0.2589, 0.2050, 0.2204, 0.2281, 0.1751, 0.2666, 0.2155, 0.2161,
        0.2538, 0.2427, 0.2625, 0.2247, 0.2040, 0.2397, 0.2393, 0.2204, 0.2127,
        0.2201, 0.2080, 0.2567, 0.1839, 0.2289, 0.2105, 0.2123, 0.2415, 0.2126,
        0.2247, 0.1888, 0.2591, 0.1767, 0.1907, 0.2482, 0.1574, 0.2595, 0.2297,
        0.2370, 0.2461, 0.1895, 0.2541, 0.2018, 0.2281, 0.1941, 0.2428, 0.2066,
        0.2266, 0.2357, 0.2368, 0.2278, 0.2308, 0.1804, 0.2713, 0.1762, 0.2442,
        0.2001, 0.2021, 0.2448, 0.2031, 0.1864, 0.2662, 0.2446, 0.2438, 0.2228,
        0.2386, 0.1946, 0.2119, 0.2157, 0.2164, 0.2534, 0.2199, 0.1979, 0.2345,
        0.1809, 0.2391, 0.1984, 0.2445, 0.2033, 0.2106, 0.2293, 0.2291, 0.2004,
        0.2250, 0.2340, 0.2353, 0.2418, 0.2456, 0.2321, 0.2119, 0.2114, 0.2163,
        0.2352, 0.3059, 0.3006, 0.2433, 0.2270, 0.2506, 0.2464, 0.1981, 0.2373,
        0.2359, 0.2219, 0.2009, 0.1802, 0.2258, 0.2483, 0.2241, 0.1807, 0.2243,
        0.2030, 0.2315, 0.1898, 0.2623, 0.1897, 0.2031, 0.1979, 0.2719, 0.2416,
        0.1865, 0.1974, 0.2095, 0.2458, 0.2278, 0.2108, 0.2253, 0.2370, 0.2165,
        0.2264, 0.2283, 0.2421, 0.2312, 0.1895, 0.2364, 0.2127, 0.2175, 0.2443,
        0.2160, 0.2330, 0.2606, 0.1870, 0.2792, 0.2059, 0.1000, 0.2090, 0.1886,
        0.2860])
true tensor([0.2400, 0.2700, 0.3200, 0.3800, 0.2500, 0.2400, 0.3100, 0.2300, 0.1600,
        0.2500, 0.2400, 0.3100, 0.1900, 0.1600, 0.2500, 0.2400, 0.1700, 0.1900,
        0.1600, 0.2500, 0.3100, 0.3200, 0.3200, 0.2400, 0.3200, 0.3800, 0.2200,
        0.4200, 0.2700, 0.3200, 0.3800, 0.2200, 0.1700, 0.1900, 0.1600, 0.2500,
        0.3100, 0.2300, 0.3100, 0.3200, 0.2300, 0.3100, 0.3200, 0.3200, 0.3200,
        0.3800, 0.2200, 0.4200, 0.2400, 0.3100, 0.2300, 0.3100, 0.2400, 0.2700,
        0.3200, 0.3800, 0.3200, 0.2400, 0.2700, 0.3200, 0.1600, 0.2500, 0.2400,
        0.3100, 0.3200, 0.3800, 0.2200, 0.4200, 0.3200, 0.3200, 0.2400, 0.2700,
        0.3100, 0.2300, 0.3100, 0.3200, 0.3800, 0.2200, 0.4200, 0.3700, 0.3100,
        0.2300, 0.3100, 0.3200, 0.2700, 0.3200, 0.3800, 0.2200, 0.3200, 0.2400,
        0.2700, 0.3200, 0.2500, 0.2400, 0.3100, 0.2300, 0.2700, 0.3200, 0.3800,
        0.2200, 0.1700, 0.1900, 0.1600, 0.2500, 0.2300, 0.3100, 0.3200, 0.3200,
        0.3200, 0.2400, 0.2700, 0.3200, 0.2400, 0.3100, 0.2300, 0.3100, 0.1900,
        0.1600, 0.2500, 0.2400, 0.3800, 0.2200, 0.4200, 0.3700, 0.2300, 0.3100,
        0.3200, 0.3200, 0.3100, 0.3200, 0.3200, 0.2400, 0.2400, 0.2700, 0.3200,
        0.3800, 0.3100, 0.3200, 0.3200, 0.2400, 0.3200, 0.3200, 0.2400, 0.2700,
        0.2200, 0.4200, 0.3700, 0.4300, 0.3800, 0.2200, 0.4200, 0.3700, 0.3200,
        0.3200, 0.2400, 0.2700, 0.1600, 0.2500, 0.2400, 0.3100, 0.2500, 0.2400,
        0.3100, 0.2300, 0.1900, 0.1600, 0.2500, 0.2400, 0.2400, 0.3100, 0.2300,
        0.3100])
Epoch: 1, Steps: 1 | Train Loss: 1.9412413 Vali Loss: 0.0081008
lr = 0.0000975531
1it [00:00, 11.50it/s]
1it [00:00,  6.36it/s]
1it [00:00, 12.60it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.495241641998291
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2389, 0.1834, 0.2440, 0.1800, 0.2359, 0.1860, 0.2367, 0.2265, 0.2752,
        0.1847, 0.2745, 0.2084, 0.2838, 0.2354, 0.3177, 0.1363, 0.1981, 0.2169,
        0.2032, 0.2461, 0.2546, 0.2139, 0.2377, 0.2449, 0.3260, 0.0942, 0.3082,
        0.1429, 0.2098, 0.1824, 0.2275, 0.2039, 0.2372, 0.2163, 0.2192, 0.2107,
        0.2383, 0.2082, 0.2227, 0.2352, 0.2041, 0.2074, 0.2509, 0.2158, 0.2549,
        0.2011, 0.2235, 0.2308, 0.2295, 0.2057, 0.2524, 0.2023, 0.1961, 0.2109,
        0.1934, 0.2214, 0.2074, 0.2160, 0.2282, 0.2106, 0.2724, 0.2295, 0.2439,
        0.2215, 0.2409, 0.2372, 0.2152, 0.2251, 0.2440, 0.2209, 0.2518, 0.2312,
        0.1865, 0.2103, 0.2087, 0.2653, 0.2033, 0.2040, 0.2092, 0.2555, 0.1891,
        0.2295, 0.2282, 0.2233, 0.2218, 0.1891, 0.2315, 0.2022, 0.2319, 0.2093,
        0.2481, 0.2090, 0.2568, 0.2287, 0.2236, 0.1871, 0.3150, 0.0973, 0.2277,
        0.2028, 0.2199, 0.2299, 0.2031, 0.2306, 0.2403, 0.2172, 0.2031, 0.2202,
        0.2476, 0.1696, 0.2986, 0.1700, 0.2033, 0.2304, 0.2127, 0.2115, 0.1888,
        0.2375, 0.2213, 0.2521, 0.2644, 0.2139, 0.2487, 0.1871, 0.1809, 0.2403,
        0.2215, 0.1997, 0.2782, 0.2159, 0.2679, 0.2670, 0.2392, 0.2218, 0.2593,
        0.2329, 0.2010, 0.2551, 0.1990, 0.2049, 0.1941, 0.1943, 0.2499, 0.2688,
        0.2071, 0.2153, 0.2322, 0.2295, 0.2322, 0.2584, 0.2513, 0.1668, 0.2397,
        0.2106, 0.1996, 0.2334, 0.2269, 0.2159, 0.2356, 0.2068, 0.2326, 0.2003,
        0.2211, 0.2258, 0.1803, 0.1732, 0.2348, 0.2301, 0.2183, 0.2126, 0.2379,
        0.1920])
true tensor([0.3200, 0.3200, 0.2400, 0.2700, 0.2400, 0.2700, 0.3200, 0.3800, 0.1900,
        0.1600, 0.2500, 0.2400, 0.3100, 0.3200, 0.3200, 0.2400, 0.1600, 0.2500,
        0.2400, 0.3100, 0.3800, 0.2200, 0.4200, 0.3700, 0.3200, 0.2400, 0.2700,
        0.3200, 0.2700, 0.3200, 0.3800, 0.2200, 0.3200, 0.3200, 0.2400, 0.2700,
        0.2400, 0.3100, 0.2300, 0.3100, 0.1700, 0.1900, 0.1600, 0.2500, 0.3800,
        0.2200, 0.4200, 0.3700, 0.2500, 0.2400, 0.3100, 0.2300, 0.2500, 0.2400,
        0.3100, 0.2300, 0.1600, 0.2500, 0.2400, 0.3100, 0.3100, 0.2300, 0.3100,
        0.3200, 0.2700, 0.3200, 0.3800, 0.2200, 0.1900, 0.1600, 0.2500, 0.2400,
        0.3200, 0.3800, 0.2200, 0.4200, 0.2200, 0.4200, 0.3700, 0.4300, 0.1700,
        0.1900, 0.1600, 0.2500, 0.3200, 0.3800, 0.2200, 0.4200, 0.2300, 0.3100,
        0.3200, 0.3200, 0.3200, 0.3800, 0.2200, 0.4200, 0.3200, 0.2400, 0.2700,
        0.3200, 0.2300, 0.3100, 0.3200, 0.3200, 0.3800, 0.2200, 0.4200, 0.3700,
        0.2700, 0.3200, 0.3800, 0.2200, 0.2300, 0.3100, 0.3200, 0.3200, 0.3200,
        0.3200, 0.2400, 0.2700, 0.3100, 0.2300, 0.3100, 0.3200, 0.2400, 0.2700,
        0.3200, 0.3800, 0.3200, 0.2400, 0.2700, 0.3200, 0.1900, 0.1600, 0.2500,
        0.2400, 0.2400, 0.2700, 0.3200, 0.3800, 0.2400, 0.3100, 0.2300, 0.3100,
        0.2500, 0.2400, 0.3100, 0.2300, 0.3100, 0.3200, 0.3200, 0.2400, 0.1700,
        0.1900, 0.1600, 0.2500, 0.1600, 0.2500, 0.2400, 0.3100, 0.3100, 0.2300,
        0.3100, 0.3200, 0.3100, 0.3200, 0.3200, 0.2400, 0.2400, 0.3100, 0.2300,
        0.3100])
Epoch: 2, Steps: 1 | Train Loss: 1.9377341 Vali Loss: 0.0081606
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5006098747253418
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2271, 0.2573, 0.2400, 0.1889, 0.2193, 0.2155, 0.2176, 0.2069, 0.1977,
        0.2118, 0.2302, 0.2392, 0.2554, 0.2043, 0.1937, 0.2517, 0.2122, 0.2060,
        0.2306, 0.2065, 0.2606, 0.2434, 0.2912, 0.2166, 0.2071, 0.1816, 0.2150,
        0.2697, 0.2232, 0.1992, 0.2809, 0.2441, 0.2499, 0.2093, 0.2490, 0.2350,
        0.1838, 0.2574, 0.2310, 0.2264, 0.1713, 0.2282, 0.2036, 0.2387, 0.2764,
        0.0909, 0.2057, 0.1203, 0.1913, 0.2285, 0.2067, 0.2159, 0.2624, 0.1944,
        0.2484, 0.1877, 0.1948, 0.2196, 0.2192, 0.2457, 0.2024, 0.2174, 0.2856,
        0.2070, 0.1990, 0.2322, 0.2282, 0.2365, 0.2173, 0.2110, 0.2399, 0.2401,
        0.2306, 0.2157, 0.2241, 0.1871, 0.2408, 0.2362, 0.2682, 0.2680, 0.1936,
        0.2674, 0.2205, 0.2133, 0.2039, 0.2478, 0.2080, 0.2100, 0.2120, 0.2091,
        0.2439, 0.1841, 0.1866, 0.2135, 0.2024, 0.2126, 0.2593, 0.2170, 0.2337,
        0.1810, 0.2347, 0.2020, 0.2163, 0.2143, 0.2086, 0.1847, 0.2358, 0.2322,
        0.2197, 0.1947, 0.2120, 0.2357, 0.2134, 0.2351, 0.2149, 0.2102, 0.2297,
        0.2118, 0.2484, 0.2266, 0.1735, 0.2172, 0.2497, 0.2670, 0.2503, 0.2114,
        0.2396, 0.2001, 0.2062, 0.2324, 0.2358, 0.2049, 0.2731, 0.2075, 0.2587,
        0.1804, 0.1948, 0.2380, 0.2237, 0.2142, 0.2210, 0.2054, 0.2194, 0.1969,
        0.2175, 0.2207, 0.2457, 0.2184, 0.2557, 0.1903, 0.2399, 0.1967, 0.2487,
        0.2404, 0.2487, 0.2098, 0.2008, 0.2399, 0.2735, 0.2239, 0.1988, 0.2021,
        0.2439, 0.2327, 0.2250, 0.1191, 0.2419, 0.2317, 0.2172, 0.1970, 0.2360,
        0.1890])
true tensor([0.3100, 0.3200, 0.3200, 0.2400, 0.2700, 0.3200, 0.3800, 0.2200, 0.2400,
        0.2700, 0.3200, 0.3800, 0.3200, 0.2400, 0.2700, 0.3200, 0.1600, 0.2500,
        0.2400, 0.3100, 0.3200, 0.2400, 0.2700, 0.3200, 0.2400, 0.3100, 0.2300,
        0.3100, 0.1900, 0.1600, 0.2500, 0.2400, 0.3200, 0.2400, 0.2700, 0.3200,
        0.1700, 0.1900, 0.1600, 0.2500, 0.2500, 0.2400, 0.3100, 0.2300, 0.3100,
        0.2300, 0.3100, 0.3200, 0.2400, 0.3100, 0.2300, 0.3100, 0.3200, 0.3200,
        0.2400, 0.2700, 0.3200, 0.3800, 0.2200, 0.4200, 0.1600, 0.2500, 0.2400,
        0.3100, 0.2200, 0.4200, 0.3700, 0.4300, 0.3800, 0.2200, 0.4200, 0.3700,
        0.3200, 0.3800, 0.2200, 0.4200, 0.3100, 0.2300, 0.3100, 0.3200, 0.2400,
        0.2700, 0.3200, 0.3800, 0.2300, 0.3100, 0.3200, 0.3200, 0.2700, 0.3200,
        0.3800, 0.2200, 0.1600, 0.2500, 0.2400, 0.3100, 0.2400, 0.3100, 0.2300,
        0.3100, 0.2300, 0.3100, 0.3200, 0.3200, 0.2700, 0.3200, 0.3800, 0.2200,
        0.2400, 0.2700, 0.3200, 0.3800, 0.2300, 0.3100, 0.3200, 0.3200, 0.3800,
        0.2200, 0.4200, 0.3700, 0.3200, 0.3200, 0.2400, 0.2700, 0.3800, 0.2200,
        0.4200, 0.3700, 0.3100, 0.2300, 0.3100, 0.3200, 0.1900, 0.1600, 0.2500,
        0.2400, 0.2500, 0.2400, 0.3100, 0.2300, 0.3100, 0.3200, 0.3200, 0.2400,
        0.3200, 0.3800, 0.2200, 0.4200, 0.2500, 0.2400, 0.3100, 0.2300, 0.1900,
        0.1600, 0.2500, 0.2400, 0.1700, 0.1900, 0.1600, 0.2500, 0.3100, 0.3200,
        0.3200, 0.2400, 0.3200, 0.3200, 0.2400, 0.2700, 0.1700, 0.1900, 0.1600,
        0.2500])
Epoch: 3, Steps: 1 | Train Loss: 1.9404771 Vali Loss: 0.0083667
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
1it [00:00,  6.21it/s]
1it [00:00, 11.97it/s]
1it [00:00,  6.29it/s]
1it [00:00, 11.22it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.4959418773651123
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2347, 0.1992, 0.2463, 0.1975, 0.1714, 0.2120, 0.2070, 0.2646, 0.2178,
        0.2257, 0.2496, 0.1962, 0.2195, 0.2352, 0.2348, 0.2437, 0.1943, 0.2338,
        0.2298, 0.2148, 0.2442, 0.2100, 0.2430, 0.1936, 0.2685, 0.2200, 0.2504,
        0.1961, 0.2105, 0.1965, 0.2421, 0.2131, 0.2379, 0.2105, 0.2570, 0.2577,
        0.2388, 0.1692, 0.2519, 0.2094, 0.2042, 0.1905, 0.2249, 0.2404, 0.2377,
        0.2107, 0.2415, 0.2040, 0.2308, 0.2399, 0.2274, 0.2015, 0.2152, 0.2120,
        0.2187, 0.2383, 0.2393, 0.1606, 0.2731, 0.1962, 0.2033, 0.2520, 0.2058,
        0.1573, 0.2337, 0.2055, 0.2091, 0.2193, 0.2225, 0.2143, 0.2495, 0.2072,
        0.2049, 0.2008, 0.2360, 0.1994, 0.2330, 0.1928, 0.1676, 0.2865, 0.1822,
        0.1922, 0.1790, 0.2139, 0.2539, 0.2097, 0.2340, 0.2636, 0.2592, 0.1915,
        0.2543, 0.2013, 0.1916, 0.2519, 0.2091, 0.2262, 0.1818, 0.2019, 0.2181,
        0.2197, 0.2562, 0.2049, 0.2009, 0.2178, 0.2123, 0.2575, 0.2358, 0.2191,
        0.2114, 0.2444, 0.2155, 0.2081, 0.1979, 0.2189, 0.2265, 0.1963, 0.2133,
        0.2903, 0.2311, 0.2276, 0.3301, 0.3343, 0.2868, 0.3591, 0.2497, 0.2245,
        0.2337, 0.2068, 0.2118, 0.1565, 0.2461, 0.2011, 0.2064, 0.2026, 0.2503,
        0.2547, 0.2112, 0.2344, 0.2261, 0.2057, 0.2174, 0.1940, 0.2006, 0.2424,
        0.1932, 0.2281, 0.2498, 0.2550, 0.2089, 0.2219, 0.2307, 0.2258, 0.2505,
        0.1977, 0.2368, 0.2182, 0.2445, 0.2125, 0.2057, 0.2061, 0.2038, 0.2131,
        0.3025, 0.2330, 0.1943, 0.2285, 0.2090, 0.2025, 0.2247, 0.1729, 0.2130,
        0.2234])
true tensor([0.3800, 0.2200, 0.4200, 0.3700, 0.3200, 0.3200, 0.2400, 0.2700, 0.3100,
        0.3200, 0.3200, 0.2400, 0.3100, 0.2300, 0.3100, 0.3200, 0.2200, 0.4200,
        0.3700, 0.4300, 0.2500, 0.2400, 0.3100, 0.2300, 0.3100, 0.2300, 0.3100,
        0.3200, 0.1700, 0.1900, 0.1600, 0.2500, 0.3200, 0.2400, 0.2700, 0.3200,
        0.2400, 0.2700, 0.3200, 0.3800, 0.1900, 0.1600, 0.2500, 0.2400, 0.3200,
        0.3200, 0.2400, 0.2700, 0.2400, 0.3100, 0.2300, 0.3100, 0.2300, 0.3100,
        0.3200, 0.3200, 0.2700, 0.3200, 0.3800, 0.2200, 0.2300, 0.3100, 0.3200,
        0.3200, 0.2300, 0.3100, 0.3200, 0.3200, 0.1700, 0.1900, 0.1600, 0.2500,
        0.3200, 0.3200, 0.2400, 0.2700, 0.3100, 0.2300, 0.3100, 0.3200, 0.3100,
        0.3200, 0.3200, 0.2400, 0.3200, 0.2400, 0.2700, 0.3200, 0.3800, 0.2200,
        0.4200, 0.3700, 0.2400, 0.2700, 0.3200, 0.3800, 0.2400, 0.2700, 0.3200,
        0.3800, 0.2500, 0.2400, 0.3100, 0.2300, 0.1700, 0.1900, 0.1600, 0.2500,
        0.2700, 0.3200, 0.3800, 0.2200, 0.1600, 0.2500, 0.2400, 0.3100, 0.3100,
        0.3200, 0.3200, 0.2400, 0.1600, 0.2500, 0.2400, 0.3100, 0.1900, 0.1600,
        0.2500, 0.2400, 0.1600, 0.2500, 0.2400, 0.3100, 0.2400, 0.3100, 0.2300,
        0.3100, 0.2500, 0.2400, 0.3100, 0.2300, 0.3200, 0.3800, 0.2200, 0.4200,
        0.3200, 0.3800, 0.2200, 0.4200, 0.1900, 0.1600, 0.2500, 0.2400, 0.3200,
        0.2400, 0.2700, 0.3200, 0.3200, 0.3800, 0.2200, 0.4200, 0.3800, 0.2200,
        0.4200, 0.3700, 0.2400, 0.3100, 0.2300, 0.3100, 0.2700, 0.3200, 0.3800,
        0.2200])
Epoch: 4, Steps: 1 | Train Loss: 1.9381840 Vali Loss: 0.0081812
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 294) (1, 294)
test shape: (1, 1, 294) (1, 1, 294)
mae:0.1163, mse:0.0207, rmse:0.1439, r2:-0.1654
mse_mean = 0.0207, mse_std = 0.0000
r2_mean = -0.1654, mae_std = 0.0000
1it [00:00, 10.22it/s]