['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.12s/it]
1it [00:00, 11.66it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3934767246246338
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2355, 0.2285, 0.1943, 0.2093, 0.1866, 0.2284, 0.2172, 0.2341, 0.2194,
        0.2809, 0.2397, 0.2268, 0.2171, 0.2494, 0.2062, 0.2595, 0.2276, 0.1695,
        0.2088, 0.2526, 0.2438, 0.2447, 0.2232, 0.1599, 0.2520, 0.1974, 0.2166,
        0.2516, 0.2397, 0.2046, 0.2071, 0.2089, 0.1962, 0.2733, 0.1913, 0.1950,
        0.2416, 0.2100, 0.2699, 0.2256, 0.2239, 0.1829, 0.2540, 0.2051, 0.2584,
        0.2382, 0.2227, 0.2492, 0.1999, 0.2117, 0.2152, 0.2260, 0.2415, 0.2153,
        0.2572, 0.1586, 0.2158, 0.2285, 0.2051, 0.2652, 0.1882, 0.2446, 0.2273,
        0.2215, 0.2765, 0.2241, 0.2223, 0.2062, 0.2206, 0.1852, 0.2132, 0.2460,
        0.2163, 0.2602, 0.2594, 0.1692, 0.1915, 0.2013, 0.2315, 0.2316, 0.1841,
        0.2010, 0.1682, 0.2591, 0.2012, 0.2081, 0.2416, 0.2772, 0.2340, 0.2229,
        0.2214, 0.2222, 0.0991, 0.2166, 0.2102, 0.3279, 0.2231, 0.2091, 0.2204,
        0.2013, 0.2310, 0.2184, 0.2466, 0.2014, 0.1699, 0.1851, 0.1923, 0.2067,
        0.2202, 0.2339, 0.2194, 0.2150, 0.2682, 0.1664, 0.1498, 0.2428, 0.2365,
        0.2133, 0.2396, 0.2201, 0.2290, 0.2071, 0.2312, 0.2494, 0.2038, 0.2311,
        0.2178, 0.2221, 0.0300, 0.1743, 0.0909, 0.4929, 0.2099, 0.1678, 0.2049,
        0.2307, 0.2045, 0.1924, 0.3284, 0.2032, 0.2712, 0.2303, 0.2641, 0.2502,
        0.2621, 0.1215, 0.2043, 0.2918, 0.2366, 0.1905, 0.2030, 0.2285, 0.2363,
        0.2274, 0.2565, 0.2285, 0.2416, 0.2298, 0.1853, 0.2405, 0.2137, 0.2457,
        0.2032, 0.2106, 0.2219, 0.2446, 0.2167, 0.2527, 0.2645, 0.1927, 0.2852,
        0.2481])
true tensor([ 0.1000,  0.2500,  0.3900, -0.0300,  0.9500,  0.3100,  0.1100,  0.2200,
         0.5400,  0.9500,  0.3100,  0.1100,  0.2100,  0.5400,  0.9500,  0.3100,
         0.7800,  0.2100,  0.5400,  0.9500,  0.9000,  0.8900,  0.0500,  0.1000,
         0.3900, -0.0300,  0.1200,  0.3400,  0.2500,  0.3900, -0.0300,  0.1200,
         0.7800,  0.2100,  0.5400,  0.9500,  0.1100,  0.2200,  0.9000,  0.8900,
         0.2200,  0.9000,  0.8900,  0.0500,  0.3900, -0.0300,  0.1200,  0.3400,
         0.3100,  0.1100,  0.2200,  0.9000,  0.1000,  0.2500,  0.3900, -0.0300,
         0.0500,  0.1000,  0.2500,  0.3900,  0.5400,  0.9500,  0.3100,  0.1100,
         0.3900, -0.0300,  0.1200,  0.3400,  0.8900,  0.0500,  0.1000,  0.2500,
         0.1100,  0.2200,  0.9000,  0.8900, -0.0300,  0.1200,  0.3400,  0.3800,
         0.1100,  0.2200,  0.9000,  0.8900,  0.2500,  0.3900, -0.0300,  0.1200,
         0.0500,  0.1000,  0.2500,  0.3900,  0.9500,  0.3100,  0.1100,  0.2200,
         0.2500,  0.3900, -0.0300,  0.1200,  0.7800,  0.2100,  0.5400,  0.9500,
         0.2200,  0.9000,  0.8900,  0.0500,  0.0500,  0.1000,  0.2500,  0.3900,
         0.3100,  0.1100,  0.2200,  0.9000,  0.2100,  0.5400,  0.9500,  0.3100,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.2200,  0.9000,  0.8900,  0.0500,
         0.9000,  0.8900,  0.0500,  0.1000,  0.1000,  0.2500,  0.3900, -0.0300,
         0.9000,  0.8900,  0.0500,  0.1000,  0.8900,  0.0500,  0.1000,  0.2500,
         0.1200,  0.3400,  0.3800,  0.1000, -0.0300,  0.1200,  0.3400,  0.3800,
         0.8900,  0.0500,  0.1000,  0.2500,  0.5400,  0.9500,  0.3100,  0.1100,
         0.9500,  0.3100,  0.1100,  0.2200,  0.2100,  0.5400,  0.9500,  0.3100,
         0.3100,  0.1100,  0.2200,  0.9000])
Epoch: 1, Steps: 1 | Train Loss: 0.0847114 Vali Loss: 0.1273778
lr = 0.0000975531
Validation loss decreased (inf --> 0.127378).  Saving model ...
1it [00:00,  5.99it/s]
1it [00:00, 11.40it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5038681030273438
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2495, 0.2140, 0.2464, 0.2116, 0.2237, 0.1866, 0.2496, 0.1910, 0.2507,
        0.2174, 0.2122, 0.2310, 0.2272, 0.2018, 0.3056, 0.1556, 0.2245, 0.2363,
        0.2109, 0.2336, 0.2338, 0.2321, 0.2231, 0.2377, 0.2198, 0.1817, 0.2522,
        0.2115, 0.1973, 0.1979, 0.2178, 0.2396, 0.2355, 0.2001, 0.2148, 0.2555,
        0.2403, 0.1801, 0.1898, 0.2390, 0.2183, 0.1666, 0.3040, 0.1858, 0.2361,
        0.1808, 0.2286, 0.2435, 0.2114, 0.2256, 0.2337, 0.2171, 0.1797, 0.2429,
        0.2181, 0.2190, 0.2351, 0.2442, 0.1757, 0.2525, 0.2591, 0.2351, 0.2408,
        0.1921, 0.2245, 0.2110, 0.2243, 0.2266, 0.2146, 0.1988, 0.1985, 0.3009,
        0.2261, 0.2250, 0.2583, 0.2787, 0.2394, 0.2238, 0.2135, 0.2297, 0.1968,
        0.1768, 0.2089, 0.2606, 0.2242, 0.1991, 0.2387, 0.2091, 0.2374, 0.1927,
        0.2448, 0.1974, 0.2472, 0.2580, 0.2037, 0.2082, 0.2191, 0.2078, 0.2169,
        0.2402, 0.1626, 0.1850, 0.1642, 0.2191, 0.2251, 0.2059, 0.2066, 0.2144,
        0.2157, 0.2086, 0.2313, 0.2363, 0.2021, 0.2277, 0.2179, 0.2222, 0.2583,
        0.2448, 0.2469, 0.2524, 0.2272, 0.2147, 0.2410, 0.2196, 0.1903, 0.1856,
        0.2066, 0.2010, 0.2462, 0.2539, 0.2248, 0.2078, 0.2398, 0.2185, 0.2732,
        0.1948, 0.2346, 0.2643, 0.2098, 0.2180, 0.2210, 0.2024, 0.2919, 0.2670,
        0.2152, 0.2170, 0.2189, 0.2098, 0.2592, 0.2313, 0.2408, 0.1693, 0.2328,
        0.2473, 0.2342, 0.2213, 0.2412, 0.2363, 0.2320, 0.2561, 0.1904, 0.2192,
        0.1907, 0.2504, 0.1509, 0.1799, 0.2242, 0.2612, 0.2243, 0.1814, 0.2625,
        0.2161])
true tensor([ 0.8900,  0.0500,  0.1000,  0.2500,  0.1000,  0.2500,  0.3900, -0.0300,
         0.2100,  0.5400,  0.9500,  0.3100,  0.9000,  0.8900,  0.0500,  0.1000,
         0.5400,  0.9500,  0.3100,  0.1100, -0.0300,  0.1200,  0.3400,  0.3800,
         0.0500,  0.1000,  0.2500,  0.3900,  0.2500,  0.3900, -0.0300,  0.1200,
         0.8900,  0.0500,  0.1000,  0.2500,  0.3100,  0.1100,  0.2200,  0.9000,
         0.7800,  0.2100,  0.5400,  0.9500, -0.0300,  0.1200,  0.3400,  0.3800,
         0.9500,  0.3100,  0.1100,  0.2200,  0.9500,  0.3100,  0.1100,  0.2200,
         0.5400,  0.9500,  0.3100,  0.1100,  0.1100,  0.2200,  0.9000,  0.8900,
         0.2500,  0.3900, -0.0300,  0.1200,  0.2100,  0.5400,  0.9500,  0.3100,
         0.3900, -0.0300,  0.1200,  0.3400,  0.1200,  0.3400,  0.3800,  0.1000,
         0.7800,  0.2100,  0.5400,  0.9500,  0.3900, -0.0300,  0.1200,  0.3400,
         0.2200,  0.9000,  0.8900,  0.0500,  0.3900, -0.0300,  0.1200,  0.3400,
         0.0500,  0.1000,  0.2500,  0.3900,  0.2200,  0.9000,  0.8900,  0.0500,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.2500,  0.3900, -0.0300,  0.1200,
         0.2200,  0.9000,  0.8900,  0.0500,  0.8900,  0.0500,  0.1000,  0.2500,
         0.1100,  0.2200,  0.9000,  0.8900,  0.1000,  0.2500,  0.3900, -0.0300,
         0.0500,  0.1000,  0.2500,  0.3900,  0.2100,  0.5400,  0.9500,  0.3100,
         0.1000,  0.2500,  0.3900, -0.0300,  0.3100,  0.1100,  0.2200,  0.9000,
         0.9500,  0.3100,  0.1100,  0.2200,  0.9000,  0.8900,  0.0500,  0.1000,
         0.7800,  0.2100,  0.5400,  0.9500,  0.5400,  0.9500,  0.3100,  0.1100,
         0.1100,  0.2200,  0.9000,  0.8900,  0.9000,  0.8900,  0.0500,  0.1000,
         0.3100,  0.1100,  0.2200,  0.9000])
Epoch: 2, Steps: 1 | Train Loss: 0.0842371 Vali Loss: 0.1245357
lr = 0.0000904518
Validation loss decreased (0.127378 --> 0.124536).  Saving model ...
1it [00:00,  5.97it/s]
1it [00:00, 11.79it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5200190544128418
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2510, 0.2116, 0.2290, 0.2039, 0.2181, 0.2154, 0.2529, 0.2085, 0.2384,
        0.2313, 0.2361, 0.2002, 0.2076, 0.2392, 0.2184, 0.2353, 0.1998, 0.2415,
        0.2602, 0.2199, 0.2318, 0.2273, 0.2364, 0.2044, 0.2269, 0.1895, 0.2747,
        0.2825, 0.2131, 0.1959, 0.2680, 0.2009, 0.2520, 0.2102, 0.2153, 0.2492,
        0.2018, 0.1648, 0.2038, 0.2690, 0.1705, 0.2208, 0.2561, 0.2401, 0.1581,
        0.2016, 0.1690, 0.2422, 0.2156, 0.2338, 0.2635, 0.2166, 0.2349, 0.2155,
        0.2144, 0.2170, 0.2184, 0.2273, 0.2423, 0.2301, 0.2181, 0.2143, 0.2247,
        0.2384, 0.2381, 0.2219, 0.2125, 0.2049, 0.2174, 0.2134, 0.2226, 0.2147,
        0.2078, 0.2458, 0.1868, 0.2369, 0.2368, 0.2315, 0.2610, 0.2290, 0.2180,
        0.1738, 0.2041, 0.2290, 0.2062, 0.2493, 0.2101, 0.2151, 0.2229, 0.2059,
        0.2216, 0.2043, 0.2547, 0.2040, 0.2063, 0.2664, 0.2835, 0.1689, 0.2227,
        0.2244, 0.2409, 0.1323, 0.2377, 0.1720, 0.2025, 0.2223, 0.2134, 0.2597,
        0.2120, 0.2427, 0.1990, 0.2163, 0.1818, 0.1742, 0.1889, 0.2036, 0.2247,
        0.2043, 0.2370, 0.2348, 0.2478, 0.2349, 0.2588, 0.2607, 0.2333, 0.2241,
        0.2569, 0.2174, 0.2210, 0.1998, 0.2380, 0.2061, 0.2495, 0.2515, 0.2027,
        0.2268, 0.1951, 0.2534, 0.2082, 0.1827, 0.2403, 0.2133, 0.2580, 0.1953,
        0.2116, 0.2164, 0.2353, 0.2274, 0.2136, 0.2193, 0.2144, 0.1978, 0.2254,
        0.2018, 0.1923, 0.2798, 0.2347, 0.2074, 0.2544, 0.2130, 0.1961, 0.2364,
        0.2222, 0.2245, 0.2718, 0.1031, 0.2375, 0.2128, 0.2453, 0.2296, 0.2677,
        0.1675])
true tensor([ 0.9000,  0.8900,  0.0500,  0.1000,  0.2500,  0.3900, -0.0300,  0.1200,
         0.1000,  0.2500,  0.3900, -0.0300,  0.0500,  0.1000,  0.2500,  0.3900,
         0.5400,  0.9500,  0.3100,  0.1100,  0.0500,  0.1000,  0.2500,  0.3900,
         0.3100,  0.1100,  0.2200,  0.9000,  0.2100,  0.5400,  0.9500,  0.3100,
         0.0500,  0.1000,  0.2500,  0.3900,  0.7800,  0.2100,  0.5400,  0.9500,
         0.9500,  0.3100,  0.1100,  0.2200,  0.1100,  0.2200,  0.9000,  0.8900,
         0.3100,  0.1100,  0.2200,  0.9000,  0.8900,  0.0500,  0.1000,  0.2500,
         0.3900, -0.0300,  0.1200,  0.3400,  0.5400,  0.9500,  0.3100,  0.1100,
         0.1200,  0.3400,  0.3800,  0.1000, -0.0300,  0.1200,  0.3400,  0.3800,
         0.3900, -0.0300,  0.1200,  0.3400,  0.1100,  0.2200,  0.9000,  0.8900,
         0.1000,  0.2500,  0.3900, -0.0300,  0.2200,  0.9000,  0.8900,  0.0500,
         0.2500,  0.3900, -0.0300,  0.1200,  0.5400,  0.9500,  0.3100,  0.1100,
         0.3100,  0.1100,  0.2200,  0.9000,  0.2200,  0.9000,  0.8900,  0.0500,
         0.2500,  0.3900, -0.0300,  0.1200,  0.1000,  0.2500,  0.3900, -0.0300,
         0.2200,  0.9000,  0.8900,  0.0500, -0.0300,  0.1200,  0.3400,  0.3800,
         0.8900,  0.0500,  0.1000,  0.2500, -0.0300,  0.1200,  0.3400,  0.3800,
         0.1100,  0.2200,  0.9000,  0.8900,  0.2100,  0.5400,  0.9500,  0.3100,
         0.9500,  0.3100,  0.1100,  0.2200,  0.9000,  0.8900,  0.0500,  0.1000,
         0.3900, -0.0300,  0.1200,  0.3400,  0.9500,  0.3100,  0.1100,  0.2200,
         0.2100,  0.5400,  0.9500,  0.3100,  0.7800,  0.2100,  0.5400,  0.9500,
         0.9000,  0.8900,  0.0500,  0.1000,  0.8900,  0.0500,  0.1000,  0.2500,
         0.7800,  0.2100,  0.5400,  0.9500])
Epoch: 3, Steps: 1 | Train Loss: 0.0841802 Vali Loss: 0.1244744
lr = 0.0000793913
Validation loss decreased (0.124536 --> 0.124474).  Saving model ...
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
1it [00:00,  5.38it/s]
1it [00:00, 11.26it/s]
1it [00:00,  6.56it/s]
1it [00:00, 11.76it/s]
Epoch: 4 cost time: 0.5526752471923828
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2222, 0.1960, 0.2499, 0.2373, 0.2594, 0.2282, 0.2282, 0.2585, 0.2119,
        0.2071, 0.2513, 0.1812, 0.2439, 0.2419, 0.2213, 0.1886, 0.2177, 0.2343,
        0.2279, 0.2068, 0.2043, 0.2441, 0.2197, 0.2136, 0.2450, 0.2201, 0.2641,
        0.2197, 0.2365, 0.1649, 0.2042, 0.1901, 0.2125, 0.1985, 0.2278, 0.2272,
        0.2324, 0.1976, 0.2582, 0.2088, 0.2369, 0.1996, 0.2406, 0.1874, 0.2324,
        0.1902, 0.2293, 0.2539, 0.2471, 0.2004, 0.2321, 0.2170, 0.1892, 0.2094,
        0.2321, 0.2071, 0.2194, 0.2028, 0.2460, 0.2488, 0.1810, 0.2037, 0.1773,
        0.1823, 0.2315, 0.1767, 0.2179, 0.2080, 0.2486, 0.2404, 0.2624, 0.1917,
        0.2416, 0.2068, 0.2370, 0.2078, 0.2079, 0.1725, 0.1538, 0.2820, 0.1661,
        0.1888, 0.1807, 0.2715, 0.2289, 0.2333, 0.2377, 0.2485, 0.2441, 0.1923,
        0.2593, 0.2153, 0.1936, 0.2437, 0.2474, 0.2052, 0.1968, 0.1189, 0.1964,
        0.2319, 0.2148, 0.1591, 0.2104, 0.2297, 0.2260, 0.1943, 0.2107, 0.2413,
        0.2240, 0.2458, 0.2375, 0.1682, 0.2308, 0.2586, 0.1979, 0.2260, 0.2311,
        0.2222, 0.2191, 0.1978, 0.2269, 0.2275, 0.2293, 0.2256, 0.2455, 0.2517,
        0.1995, 0.2228, 0.2278, 0.1945, 0.2049, 0.2409, 0.2335, 0.1707, 0.2932,
        0.2513, 0.2216, 0.2291, 0.2222, 0.1892, 0.2388, 0.2441, 0.2346, 0.2233,
        0.2293, 0.2196, 0.2359, 0.2582, 0.2250, 0.2060, 0.1860, 0.2792, 0.2290,
        0.2134, 0.2161, 0.2255, 0.2504, 0.2424, 0.2129, 0.2352, 0.2208, 0.2104,
        0.2668, 0.2200, 0.2163, 0.1971, 0.2249, 0.2100, 0.2109, 0.1924, 0.2203,
        0.2457])
true tensor([-0.0300,  0.1200,  0.3400,  0.3800,  0.8900,  0.0500,  0.1000,  0.2500,
         0.9000,  0.8900,  0.0500,  0.1000,  0.1100,  0.2200,  0.9000,  0.8900,
         0.1200,  0.3400,  0.3800,  0.1000,  0.9500,  0.3100,  0.1100,  0.2200,
         0.1100,  0.2200,  0.9000,  0.8900,  0.7800,  0.2100,  0.5400,  0.9500,
         0.0500,  0.1000,  0.2500,  0.3900,  0.1000,  0.2500,  0.3900, -0.0300,
         0.2100,  0.5400,  0.9500,  0.3100,  0.8900,  0.0500,  0.1000,  0.2500,
         0.3100,  0.1100,  0.2200,  0.9000,  0.2200,  0.9000,  0.8900,  0.0500,
         0.2500,  0.3900, -0.0300,  0.1200,  0.2200,  0.9000,  0.8900,  0.0500,
         0.2200,  0.9000,  0.8900,  0.0500,  0.7800,  0.2100,  0.5400,  0.9500,
         0.8900,  0.0500,  0.1000,  0.2500,  0.1100,  0.2200,  0.9000,  0.8900,
         0.9000,  0.8900,  0.0500,  0.1000,  0.0500,  0.1000,  0.2500,  0.3900,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.1000,  0.2500,  0.3900, -0.0300,
         0.1000,  0.2500,  0.3900, -0.0300,  0.9500,  0.3100,  0.1100,  0.2200,
         0.7800,  0.2100,  0.5400,  0.9500,  0.2500,  0.3900, -0.0300,  0.1200,
         0.5400,  0.9500,  0.3100,  0.1100,  0.9000,  0.8900,  0.0500,  0.1000,
         0.5400,  0.9500,  0.3100,  0.1100,  0.2100,  0.5400,  0.9500,  0.3100,
         0.5400,  0.9500,  0.3100,  0.1100,  0.3100,  0.1100,  0.2200,  0.9000,
         0.9500,  0.3100,  0.1100,  0.2200,  0.3900, -0.0300,  0.1200,  0.3400,
         0.3900, -0.0300,  0.1200,  0.3400,  0.2100,  0.5400,  0.9500,  0.3100,
         0.0500,  0.1000,  0.2500,  0.3900,  0.3900, -0.0300,  0.1200,  0.3400,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.3100,  0.1100,  0.2200,  0.9000,
         0.2500,  0.3900, -0.0300,  0.1200])
Epoch: 4, Steps: 1 | Train Loss: 0.0828948 Vali Loss: 0.1252750
lr = 0.0000654543
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.5108530521392822
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.1861, 0.1838, 0.1652, 0.1943, 0.2118, 0.2112, 0.2142, 0.2342, 0.1880,
        0.1759, 0.2556, 0.2463, 0.2157, 0.2702, 0.2406, 0.1864, 0.1712, 0.2286,
        0.2141, 0.1882, 0.2304, 0.2092, 0.2199, 0.2284, 0.2324, 0.2417, 0.2376,
        0.2365, 0.2054, 0.2309, 0.2318, 0.2119, 0.2073, 0.2369, 0.2431, 0.2357,
        0.2115, 0.1340, 0.2237, 0.2496, 0.2129, 0.2366, 0.2263, 0.2062, 0.2324,
        0.2416, 0.1788, 0.2262, 0.2252, 0.2528, 0.2340, 0.2393, 0.2396, 0.1942,
        0.2290, 0.2184, 0.2407, 0.2402, 0.2044, 0.2086, 0.2132, 0.1786, 0.2513,
        0.2130, 0.2491, 0.2083, 0.2647, 0.2627, 0.2237, 0.2090, 0.2246, 0.2277,
        0.2927, 0.0777, 0.1283, 0.1982, 0.1693, 0.2133, 0.1942, 0.2198, 0.2207,
        0.2295, 0.2493, 0.1883, 0.1462, 0.2655, 0.1160, 0.1881, 0.2146, 0.2322,
        0.1991, 0.1933, 0.2276, 0.1070, 0.2296, 0.2578, 0.2629, 0.2236, 0.2347,
        0.2708, 0.2605, 0.1812, 0.2368, 0.1885, 0.2552, 0.2057, 0.2412, 0.2323,
        0.2139, 0.1494, 0.3014, 0.1970, 0.2221, 0.2057, 0.2486, 0.2054, 0.2265,
        0.2250, 0.2372, 0.1914, 0.2191, 0.2057, 0.2781, 0.2107, 0.1924, 0.3356,
        0.2864, 0.2132, 0.2074, 0.2369, 0.2141, 0.2283, 0.2451, 0.2066, 0.2336,
        0.1860, 0.2507, 0.2208, 0.2244, 0.2323, 0.2148, 0.2134, 0.2089, 0.2444,
        0.1820, 0.2055, 0.2370, 0.2334, 0.2756, 0.1908, 0.1852, 0.2514, 0.2503,
        0.2304, 0.2148, 0.2597, 0.2160, 0.1616, 0.2233, 0.2409, 0.1833, 0.2099,
        0.2398, 0.2509, 0.2446, 0.2111, 0.2503, 0.2159, 0.2570, 0.2391, 0.2485,
        0.1814])
true tensor([ 0.2200,  0.9000,  0.8900,  0.0500, -0.0300,  0.1200,  0.3400,  0.3800,
         0.9500,  0.3100,  0.1100,  0.2200,  0.1000,  0.2500,  0.3900, -0.0300,
         0.1200,  0.3400,  0.3800,  0.1000,  0.5400,  0.9500,  0.3100,  0.1100,
         0.3900, -0.0300,  0.1200,  0.3400,  0.2200,  0.9000,  0.8900,  0.0500,
         0.3900, -0.0300,  0.1200,  0.3400,  0.7800,  0.2100,  0.5400,  0.9500,
         0.1000,  0.2500,  0.3900, -0.0300,  0.2100,  0.5400,  0.9500,  0.3100,
         0.5400,  0.9500,  0.3100,  0.1100,  0.2200,  0.9000,  0.8900,  0.0500,
         0.2500,  0.3900, -0.0300,  0.1200,  0.1100,  0.2200,  0.9000,  0.8900,
         0.3100,  0.1100,  0.2200,  0.9000,  0.0500,  0.1000,  0.2500,  0.3900,
         0.9000,  0.8900,  0.0500,  0.1000,  0.1100,  0.2200,  0.9000,  0.8900,
         0.1100,  0.2200,  0.9000,  0.8900,  0.9500,  0.3100,  0.1100,  0.2200,
         0.9500,  0.3100,  0.1100,  0.2200,  0.1000,  0.2500,  0.3900, -0.0300,
         0.8900,  0.0500,  0.1000,  0.2500,  0.2500,  0.3900, -0.0300,  0.1200,
         0.8900,  0.0500,  0.1000,  0.2500,  0.7800,  0.2100,  0.5400,  0.9500,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.9000,  0.8900,  0.0500,  0.1000,
         0.3100,  0.1100,  0.2200,  0.9000, -0.0300,  0.1200,  0.3400,  0.3800,
         0.0500,  0.1000,  0.2500,  0.3900,  0.2100,  0.5400,  0.9500,  0.3100,
         0.3900, -0.0300,  0.1200,  0.3400,  0.2100,  0.5400,  0.9500,  0.3100,
         0.0500,  0.1000,  0.2500,  0.3900,  0.3100,  0.1100,  0.2200,  0.9000,
         0.5400,  0.9500,  0.3100,  0.1100,  0.8900,  0.0500,  0.1000,  0.2500,
         0.2500,  0.3900, -0.0300,  0.1200,  0.9000,  0.8900,  0.0500,  0.1000,
         0.7800,  0.2100,  0.5400,  0.9500])
Epoch: 5, Steps: 1 | Train Loss: 0.0835406 Vali Loss: 0.1249364
lr = 0.0000500050
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 6 cost time: 0.503953218460083
1it [00:00,  6.21it/s]
1it [00:00, 11.57it/s]
1it [00:00, 10.44it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2341, 0.2177, 0.2566, 0.2452, 0.2108, 0.1488, 0.2159, 0.2238, 0.2234,
        0.1700, 0.1899, 0.2213, 0.1717, 0.1903, 0.2117, 0.1564, 0.1877, 0.1682,
        0.1791, 0.1830, 0.2450, 0.2387, 0.2517, 0.1675, 0.2279, 0.2073, 0.2211,
        0.2399, 0.2253, 0.2173, 0.2298, 0.2321, 0.2676, 0.2131, 0.2221, 0.2191,
        0.2260, 0.2508, 0.2145, 0.1855, 0.2253, 0.1899, 0.2679, 0.2011, 0.0596,
        0.1763, 0.1064, 0.3283, 0.1632, 0.2315, 0.2218, 0.2272, 0.2315, 0.1653,
        0.2774, 0.2138, 0.2691, 0.2361, 0.2353, 0.2440, 0.2307, 0.2364, 0.2232,
        0.2594, 0.1940, 0.2301, 0.1971, 0.1779, 0.1809, 0.1949, 0.2288, 0.2495,
        0.2034, 0.1819, 0.2072, 0.2637, 0.2318, 0.1056, 0.3069, 0.2033, 0.2194,
        0.1973, 0.2432, 0.2149, 0.2184, 0.2384, 0.1938, 0.2238, 0.2463, 0.1907,
        0.2229, 0.2143, 0.2959, 0.2014, 0.2220, 0.2462, 0.2243, 0.2165, 0.2227,
        0.2015, 0.2044, 0.2305, 0.2193, 0.2058, 0.2326, 0.2512, 0.2042, 0.1942,
        0.2348, 0.2199, 0.2396, 0.2061, 0.2140, 0.2451, 0.2512, 0.1977, 0.2034,
        0.1827, 0.2066, 0.2640, 0.2701, 0.1494, 0.2301, 0.2590, 0.2051, 0.2190,
        0.2228, 0.2019, 0.2154, 0.1905, 0.3083, 0.2296, 0.2061, 0.2326, 0.2296,
        0.2095, 0.2493, 0.2190, 0.2146, 0.2094, 0.1887, 0.2448, 0.1998, 0.2565,
        0.2263, 0.2630, 0.1681, 0.2543, 0.2168, 0.2499, 0.2216, 0.2405, 0.2354,
        0.1803, 0.2353, 0.2412, 0.2439, 0.1870, 0.2627, 0.2071, 0.2644, 0.1839,
        0.2567, 0.2763, 0.2028, 0.2278, 0.2454, 0.2210, 0.2281, 0.2092, 0.2408,
        0.1982])
true tensor([ 0.8900,  0.0500,  0.1000,  0.2500,  0.1000,  0.2500,  0.3900, -0.0300,
         0.1000,  0.2500,  0.3900, -0.0300,  0.5400,  0.9500,  0.3100,  0.1100,
         0.2200,  0.9000,  0.8900,  0.0500,  0.9000,  0.8900,  0.0500,  0.1000,
         0.8900,  0.0500,  0.1000,  0.2500,  0.3100,  0.1100,  0.2200,  0.9000,
         0.1000,  0.2500,  0.3900, -0.0300,  0.0500,  0.1000,  0.2500,  0.3900,
         0.2500,  0.3900, -0.0300,  0.1200,  0.9000,  0.8900,  0.0500,  0.1000,
         0.9500,  0.3100,  0.1100,  0.2200,  0.1100,  0.2200,  0.9000,  0.8900,
         0.5400,  0.9500,  0.3100,  0.1100,  0.3900, -0.0300,  0.1200,  0.3400,
         0.1200,  0.3400,  0.3800,  0.1000,  0.1100,  0.2200,  0.9000,  0.8900,
         0.7800,  0.2100,  0.5400,  0.9500,  0.7800,  0.2100,  0.5400,  0.9500,
         0.0500,  0.1000,  0.2500,  0.3900, -0.0300,  0.1200,  0.3400,  0.3800,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.8900,  0.0500,  0.1000,  0.2500,
         0.2100,  0.5400,  0.9500,  0.3100,  0.2200,  0.9000,  0.8900,  0.0500,
         0.9500,  0.3100,  0.1100,  0.2200,  0.9000,  0.8900,  0.0500,  0.1000,
         0.7800,  0.2100,  0.5400,  0.9500,  0.2500,  0.3900, -0.0300,  0.1200,
         0.3100,  0.1100,  0.2200,  0.9000,  0.9500,  0.3100,  0.1100,  0.2200,
         0.3100,  0.1100,  0.2200,  0.9000,  0.5400,  0.9500,  0.3100,  0.1100,
         0.1100,  0.2200,  0.9000,  0.8900,  0.2100,  0.5400,  0.9500,  0.3100,
         0.2100,  0.5400,  0.9500,  0.3100,  0.3900, -0.0300,  0.1200,  0.3400,
         0.3900, -0.0300,  0.1200,  0.3400,  0.2200,  0.9000,  0.8900,  0.0500,
        -0.0300,  0.1200,  0.3400,  0.3800,  0.0500,  0.1000,  0.2500,  0.3900,
         0.2500,  0.3900, -0.0300,  0.1200])
Epoch: 6, Steps: 1 | Train Loss: 0.0827149 Vali Loss: 0.1257315
lr = 0.0000345557
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 372) (1, 372)
test shape: (1, 1, 372) (1, 1, 372)
mae:0.5152, mse:0.6618, rmse:0.8135, r2:-0.4269
mse_mean = 0.6618, mse_std = 0.0000
r2_mean = -0.4269, mae_std = 0.0000