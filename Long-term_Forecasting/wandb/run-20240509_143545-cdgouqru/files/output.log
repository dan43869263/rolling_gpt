['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.09s/it]
1it [00:00, 12.29it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3613293170928955
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([67])
missing_idx_len: 43
pred tensor([0.2202, 0.2281, 0.2089, 0.2616, 0.2260, 0.2059, 0.1906, 0.1663, 0.2931,
        0.0588, 0.2505, 0.2118, 0.1905, 0.2380, 0.2674, 0.3399, 0.0987, 0.0032,
        0.2279, 0.2986, 0.2071, 0.4319, 0.2154, 0.2428, 0.1893, 0.2144, 0.2584,
        0.2348, 0.2016, 0.2651, 0.2859, 0.1596, 0.2510, 0.2132, 0.2090, 0.2117,
        0.2041, 0.1997, 0.2295, 0.2324, 0.4033, 0.2778, 0.5220, 0.2407, 0.2517,
        0.2055, 0.2028, 0.5027, 0.1931, 0.1959, 0.2251, 0.1560, 0.1200, 0.2731,
        0.2335, 0.2216, 0.2267, 0.2365, 0.2476, 0.2528, 0.1900, 0.0278, 0.2822,
        0.2428, 0.2799, 0.2527, 0.2326])
true tensor([0.2780, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800, 0.3020, 0.2480, 0.2780,
        0.2800, 0.2140, 0.2480, 0.2780, 0.4500, 0.4500, 0.2140, 0.2480, 0.2780,
        0.3020, 0.2940, 0.2940, 0.4500, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800,
        0.3020, 0.4500, 0.3020, 0.2940, 0.4500, 0.3020, 0.2940, 0.4500, 0.2780,
        0.2800, 0.3020, 0.2940, 0.4500, 0.2140, 0.2480, 0.2780, 0.2940, 0.2800,
        0.3020, 0.2940, 0.2480, 0.2780, 0.2800, 0.4500, 0.2940, 0.4500, 0.4500,
        0.2780, 0.2800, 0.3020, 0.2780, 0.2800, 0.3020, 0.2940, 0.2480, 0.2780,
        0.2800, 0.2800, 0.3020, 0.2940])
Epoch: 1, Steps: 1 | Train Loss: 0.0506660 Vali Loss: 0.0165961
lr = 0.0000975531
Validation loss decreased (inf --> 0.016596).  Saving model ...
1it [00:00,  6.40it/s]
1it [00:00, 11.60it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.48206567764282227
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([67])
missing_idx_len: 43
pred tensor([ 0.3651,  0.1336,  0.1833,  0.2216,  0.2570,  0.2176,  0.2025,  0.2080,
         0.2454,  0.2078,  0.2428,  0.1531,  0.3777,  0.3682,  0.2473,  0.2245,
         0.2132,  0.2307,  0.2299,  0.1922,  0.2746,  0.1851,  0.1686,  0.2248,
         0.2709,  0.2261,  0.5310,  0.0901,  0.2066, -0.0813,  0.3414,  0.1073,
         0.2444,  0.2653,  0.3683,  0.1935,  0.3642,  0.2279,  0.2242,  0.2139,
         0.2507,  0.2394,  0.2795,  0.3113,  0.2294,  0.2619,  0.2975,  0.3234,
         0.4372,  0.2707,  0.2359,  0.2524,  0.1892,  0.3317,  0.3382,  0.1137,
         0.1983,  0.2779,  0.4476,  0.1861,  0.2312,  0.1977,  0.2551,  0.2228,
         0.2259,  0.2123,  0.1810])
true tensor([0.2480, 0.2780, 0.2800, 0.2780, 0.2800, 0.3020, 0.4500, 0.4500, 0.2800,
        0.3020, 0.2940, 0.2140, 0.2480, 0.2780, 0.4500, 0.2780, 0.2800, 0.3020,
        0.2940, 0.2780, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800, 0.3020, 0.3020,
        0.2940, 0.4500, 0.2480, 0.2780, 0.2800, 0.4500, 0.4500, 0.2140, 0.2480,
        0.2780, 0.4500, 0.2940, 0.4500, 0.2940, 0.4500, 0.4500, 0.2940, 0.3020,
        0.2940, 0.2480, 0.2780, 0.2800, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800,
        0.3020, 0.2940, 0.2140, 0.2480, 0.2780, 0.2780, 0.2800, 0.3020, 0.3020,
        0.2940, 0.2800, 0.3020, 0.2940])
Epoch: 2, Steps: 1 | Train Loss: 0.0484821 Vali Loss: 0.0161091
lr = 0.0000904518
Validation loss decreased (0.016596 --> 0.016109).  Saving model ...
1it [00:00,  6.21it/s]
1it [00:00, 12.41it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.49253392219543457
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([67])
missing_idx_len: 43
pred tensor([0.2472, 0.2602, 0.2433, 0.2268, 0.2254, 0.2272, 0.2295, 0.1637, 0.0119,
        0.2426, 0.3527, 0.1915, 0.1731, 0.1927, 0.2165, 0.1747, 0.2158, 0.2313,
        0.2300, 0.2216, 0.2633, 0.2584, 0.2547, 0.2512, 0.2554, 0.2038, 0.1530,
        0.2155, 0.1907, 0.2494, 0.2774, 0.2095, 0.2502, 0.2093, 0.1992, 0.1887,
        0.2613, 0.2313, 0.2357, 0.2509, 0.2290, 0.2437, 0.2131, 0.4058, 0.3120,
        0.2667, 0.3716, 0.1850, 0.0544, 0.2277, 0.2343, 0.2283, 0.2068, 0.4488,
        0.2368, 0.2253, 0.2511, 0.2252, 0.2800, 0.2224, 0.3019, 0.2538, 0.2416,
        0.1747, 0.2632, 0.1081, 0.0657])
true tensor([0.4500, 0.2780, 0.2800, 0.3020, 0.2800, 0.3020, 0.2940, 0.2480, 0.2780,
        0.2800, 0.2140, 0.2480, 0.2780, 0.2780, 0.2800, 0.3020, 0.2940, 0.3020,
        0.2940, 0.2800, 0.3020, 0.2940, 0.4500, 0.2780, 0.2800, 0.3020, 0.4500,
        0.4500, 0.4500, 0.3020, 0.2940, 0.2940, 0.4500, 0.2780, 0.2800, 0.3020,
        0.2800, 0.3020, 0.2940, 0.2940, 0.4500, 0.2940, 0.4500, 0.4500, 0.3020,
        0.2940, 0.2480, 0.2780, 0.2800, 0.2780, 0.2800, 0.3020, 0.2940, 0.4500,
        0.2780, 0.2800, 0.3020, 0.2940, 0.2480, 0.2780, 0.2800, 0.2140, 0.2480,
        0.2780, 0.2140, 0.2480, 0.2780])
Epoch: 3, Steps: 1 | Train Loss: 0.0496527 Vali Loss: 0.0129241
lr = 0.0000793913
Validation loss decreased (0.016109 --> 0.012924).  Saving model ...
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.4823474884033203
1it [00:00,  6.52it/s]
1it [00:00, 12.03it/s]
1it [00:00,  6.24it/s]
1it [00:00, 12.23it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([67])
missing_idx_len: 43
pred tensor([ 0.2657,  0.2456,  0.2701,  0.1579,  0.2414,  0.2135,  0.2362,  0.2123,
         0.3216,  0.3457,  0.3682,  0.1451,  0.2062,  0.3252,  0.2521,  0.1883,
         0.2432,  0.2523,  0.2333,  0.2327,  0.2803,  0.2603,  0.2235,  0.1200,
         0.3360,  0.3424,  0.2090,  0.2363, -0.1271,  0.2224,  0.2377,  0.1794,
         0.2052,  0.1726,  0.3910,  0.1845,  0.0739,  0.1948,  0.1983,  0.2088,
         0.2397,  0.2585,  0.2060,  0.2013,  0.0689,  0.3835,  0.2241,  0.2229,
         0.2391,  0.2759,  0.2284,  0.2372,  0.2437,  0.2299,  0.2592,  0.2160,
         0.2313,  0.1975,  0.3513,  0.1311,  0.1628,  0.2516,  0.1696,  0.2443,
         0.2390,  0.1909,  0.1791])
true tensor([0.4500, 0.3020, 0.2940, 0.4500, 0.2780, 0.2800, 0.3020, 0.2940, 0.3020,
        0.2940, 0.2140, 0.2480, 0.2780, 0.2480, 0.2780, 0.2800, 0.2800, 0.3020,
        0.2940, 0.2940, 0.4500, 0.2940, 0.2940, 0.2140, 0.2480, 0.2780, 0.3020,
        0.2940, 0.4500, 0.2780, 0.2800, 0.3020, 0.2940, 0.2140, 0.2480, 0.2780,
        0.4500, 0.2780, 0.2800, 0.3020, 0.2780, 0.2800, 0.3020, 0.2480, 0.2780,
        0.2800, 0.2780, 0.2800, 0.3020, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800,
        0.3020, 0.2940, 0.4500, 0.4500, 0.2480, 0.2780, 0.2800, 0.4500, 0.4500,
        0.2800, 0.3020, 0.2940, 0.4500])
Epoch: 4, Steps: 1 | Train Loss: 0.0499212 Vali Loss: 0.0193247
lr = 0.0000654543
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.4809608459472656
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([67])
missing_idx_len: 43
pred tensor([0.2267, 0.1900, 0.1877, 0.2393, 0.1750, 0.1904, 0.1388, 0.2078, 0.2508,
        0.2478, 0.1965, 0.2212, 0.2331, 0.2950, 0.0803, 0.2255, 0.2324, 0.4117,
        0.0701, 0.2144, 0.2439, 0.2439, 0.2173, 0.2244, 0.2374, 0.2560, 0.2438,
        0.2278, 0.2232, 0.1989, 0.1945, 0.3292, 0.2725, 0.1965, 0.2544, 0.2039,
        0.2106, 0.2262, 0.2265, 0.2552, 0.1938, 0.2145, 0.2118, 0.3245, 0.2414,
        0.1542, 0.2704, 0.2341, 0.2043, 0.4638, 0.5268, 0.1344, 0.3049, 0.2525,
        0.3350, 0.0100, 0.0673, 0.2636, 0.2111, 0.2378, 0.2276, 0.2586, 0.2122,
        0.2308, 0.3509, 0.2763, 0.3867])
true tensor([0.2940, 0.4500, 0.2780, 0.2800, 0.3020, 0.2940, 0.4500, 0.2780, 0.2800,
        0.3020, 0.4500, 0.2940, 0.4500, 0.2140, 0.2480, 0.2780, 0.2480, 0.2780,
        0.2800, 0.2780, 0.2800, 0.3020, 0.2940, 0.4500, 0.3020, 0.2940, 0.2800,
        0.3020, 0.2940, 0.3020, 0.2940, 0.3020, 0.2940, 0.2780, 0.2800, 0.3020,
        0.2940, 0.2780, 0.2800, 0.3020, 0.2940, 0.4500, 0.2140, 0.2480, 0.2780,
        0.4500, 0.2800, 0.3020, 0.2940, 0.4500, 0.2480, 0.2780, 0.2800, 0.4500,
        0.2480, 0.2780, 0.2800, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800, 0.3020,
        0.4500, 0.2140, 0.2480, 0.2780])
Epoch: 5, Steps: 1 | Train Loss: 0.0487365 Vali Loss: 0.0164900
lr = 0.0000500050
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 6 cost time: 0.48395323753356934
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([67])
missing_idx_len: 43
pred tensor([0.2476, 0.2362, 0.2077, 0.2575, 0.2545, 0.2631, 0.1910, 0.2604, 0.1889,
        0.2315, 0.1844, 0.2128, 0.3398, 0.3279, 0.2298, 0.2331, 0.2189, 0.1380,
        0.0665, 0.2329, 0.2669, 0.0206, 0.1039, 0.3160, 0.1736, 0.0742, 0.0672,
        0.2351, 0.1573, 0.3783, 0.2594, 0.2059, 0.2248, 0.2263, 0.2234, 0.2511,
        0.2226, 0.1216, 0.2457, 0.0823, 0.2198, 0.2780, 0.2076, 0.2499, 0.2416,
        0.2230, 0.2233, 0.2227, 0.1973, 0.2299, 0.2368, 0.2258, 0.2730, 0.2108,
        0.2729, 0.2418, 0.3406, 0.1443, 0.2340, 0.1730, 0.3239, 0.1240, 0.1750,
        0.2624, 0.2566, 0.4114, 0.2123])
true tensor([0.2780, 0.2800, 0.3020, 0.2940, 0.2800, 0.3020, 0.2940, 0.4500, 0.2780,
        0.2800, 0.3020, 0.2940, 0.3020, 0.2940, 0.2780, 0.2800, 0.3020, 0.4500,
        0.4500, 0.3020, 0.2940, 0.2140, 0.2480, 0.2780, 0.2140, 0.2480, 0.2780,
        0.4500, 0.4500, 0.2480, 0.2780, 0.2800, 0.2940, 0.2780, 0.2800, 0.3020,
        0.2940, 0.2140, 0.2480, 0.2780, 0.4500, 0.2800, 0.3020, 0.2940, 0.2780,
        0.2800, 0.3020, 0.2940, 0.2800, 0.3020, 0.2940, 0.2780, 0.2800, 0.3020,
        0.3020, 0.2940, 0.2480, 0.2780, 0.2800, 0.2480, 0.2780, 0.2800, 0.4500,
        0.4500, 0.2940, 0.4500, 0.4500])
Epoch: 6, Steps: 1 | Train Loss: 0.0471556 Vali Loss: 0.0157121
lr = 0.0000345557
EarlyStopping counter: 3 out of 3
Early stopping
1it [00:00,  6.24it/s]
1it [00:00, 11.61it/s]
1it [00:00, 10.30it/s]
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 363) (1, 363)
test shape: (1, 1, 363) (1, 1, 363)
mae:2.1673, mse:12.3311, rmse:3.5116, r2:-0.6160
mse_mean = 12.3311, mse_std = 0.0000
r2_mean = -0.6160, mae_std = 0.0000