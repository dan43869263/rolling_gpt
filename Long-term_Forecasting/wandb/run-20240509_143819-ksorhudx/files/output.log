['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.10s/it]
1it [00:00, 12.08it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3885064125061035
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2319, 0.1882, 0.2274, 0.2395, 0.2211, 0.1993, 0.2358, 0.1961, 0.2555,
        0.1908, 0.2523, 0.1818, 0.2155, 0.2384, 0.2162, 0.2275, 0.2702, 0.1905,
        0.2610, 0.2080, 0.2090, 0.2458, 0.2174, 0.2241, 0.2251, 0.2484, 0.2218,
        0.2086, 0.1996, 0.2353, 0.2281, 0.2687, 0.2138, 0.2339, 0.2409, 0.2201,
        0.2510, 0.2069, 0.2154, 0.2339, 0.2168, 0.2256, 0.2099, 0.2153, 0.1673,
        0.1786, 0.2152, 0.2422, 0.2370, 0.1882, 0.2152, 0.2377, 0.2596, 0.1345,
        0.2834, 0.1020, 0.2627, 0.2050, 0.2140, 0.2254, 0.2047, 0.2321, 0.2150,
        0.2317, 0.2311, 0.1885, 0.2693, 0.1944, 0.1968, 0.2443, 0.2230, 0.2007,
        0.3794, 0.1951, 0.2012, 0.3188, 0.2488, 0.2020, 0.2403, 0.2120, 0.2335,
        0.2245, 0.2182, 0.2201, 0.2195, 0.1844, 0.2403, 0.2401, 0.2533, 0.2257,
        0.2421, 0.1765, 0.2902, 0.1579, 0.2807, 0.2851, 0.2433, 0.1807, 0.2249,
        0.1940, 0.2238, 0.2272, 0.2144, 0.2364, 0.2394, 0.1787, 0.2318, 0.3090,
        0.2160, 0.2074, 0.2194, 0.2150, 0.2163, 0.2099, 0.2116, 0.2159, 0.2197,
        0.2163, 0.2816, 0.2851, 0.2804, 0.2012, 0.2509, 0.2385, 0.2190, 0.2155,
        0.2147, 0.2071, 0.2482, 0.2006, 0.2235, 0.2387, 0.2288, 0.2164, 0.2271,
        0.2067, 0.2402, 0.2331, 0.2126, 0.2532, 0.2125, 0.2659, 0.2403, 0.1939,
        0.2034, 0.2108, 0.2168, 0.2257, 0.2221, 0.2005, 0.2207, 0.2615, 0.2173,
        0.2381, 0.2082, 0.2484, 0.2239, 0.2234, 0.2104, 0.2266, 0.2463, 0.2086,
        0.2299, 0.2227, 0.2496, 0.2204, 0.2468, 0.2258, 0.2469, 0.2580, 0.2258,
        0.2425])
true tensor([ 0.3402,  0.5746,  0.5519,  0.4687, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.3251, -0.4536, -0.2344, -0.3024, -0.4914, -0.3251, -0.4536, -0.2344,
        -0.1663, -0.4914, -0.3251, -0.4536,  0.1663,  0.3100,  0.4461,  0.3402,
         0.5519,  0.4687,  0.2646,  0.3402,  0.5746,  0.5519,  0.4687,  0.2646,
        -0.1663, -0.4914, -0.3251, -0.4536, -0.3024,  0.0302,  0.1663,  0.3100,
         0.0302,  0.1663,  0.3100,  0.4461,  0.5519,  0.4687,  0.2646,  0.3402,
        -0.2344, -0.3024,  0.0302,  0.1663,  0.3402,  0.5746,  0.5519,  0.4687,
         0.4461,  0.3402,  0.5746,  0.5519, -0.3251, -0.4536, -0.2344, -0.3024,
         0.5519,  0.4687,  0.2646,  0.3402,  0.3100,  0.4461,  0.3402,  0.5746,
        -0.3024,  0.0302,  0.1663,  0.3100,  0.4687,  0.2646,  0.3402,  0.2797,
        -0.3024,  0.0302,  0.1663,  0.3100,  0.5746,  0.5519,  0.4687,  0.2646,
         0.4461,  0.3402,  0.5746,  0.5519, -0.4536, -0.2344, -0.3024,  0.0302,
         0.5746,  0.5519,  0.4687,  0.2646, -0.1663, -0.4914, -0.3251, -0.4536,
         0.0302,  0.1663,  0.3100,  0.4461,  0.4461,  0.3402,  0.5746,  0.5519,
        -0.2344, -0.3024,  0.0302,  0.1663, -0.4914, -0.3251, -0.4536, -0.2344,
         0.4687,  0.2646,  0.3402,  0.2797,  0.0302,  0.1663,  0.3100,  0.4461,
         0.1663,  0.3100,  0.4461,  0.3402,  0.3402,  0.5746,  0.5519,  0.4687,
         0.1663,  0.3100,  0.4461,  0.3402,  0.3100,  0.4461,  0.3402,  0.5746,
         0.2646,  0.3402,  0.2797,  0.2268,  0.4687,  0.2646,  0.3402,  0.2797,
         0.3100,  0.4461,  0.3402,  0.5746, -0.3251, -0.4536, -0.2344, -0.3024,
        -0.4536, -0.2344, -0.3024,  0.0302, -0.4914, -0.3251, -0.4536, -0.2344,
        -0.2344, -0.3024,  0.0302,  0.1663])
Epoch: 1, Steps: 1 | Train Loss: 0.9330307 Vali Loss: 0.1353821
lr = 0.0000975531
Validation loss decreased (inf --> 0.135382).  Saving model ...
1it [00:00,  6.19it/s]
1it [00:00, 11.54it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5018618106842041
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2408, 0.2482, 0.2375, 0.2300, 0.2293, 0.1647, 0.3678, 0.1823, 0.2287,
        0.2034, 0.2662, 0.2320, 0.2252, 0.2103, 0.1302, 0.2068, 0.1973, 0.2624,
        0.2013, 0.2184, 0.2532, 0.2037, 0.2482, 0.2397, 0.3235, 0.1417, 0.3483,
        0.1160, 0.2392, 0.1798, 0.2469, 0.2140, 0.1911, 0.2524, 0.2270, 0.2341,
        0.2374, 0.2578, 0.3292, 0.1146, 0.2330, 0.2185, 0.2538, 0.2188, 0.2426,
        0.1970, 0.2089, 0.2549, 0.2225, 0.2074, 0.2374, 0.1758, 0.2531, 0.1860,
        0.2708, 0.2378, 0.2327, 0.2293, 0.1716, 0.2445, 0.2517, 0.2227, 0.2558,
        0.2290, 0.2260, 0.2259, 0.1851, 0.3016, 0.2710, 0.2315, 0.2521, 0.2623,
        0.1712, 0.1662, 0.2122, 0.2493, 0.2171, 0.2028, 0.2187, 0.2463, 0.2344,
        0.2077, 0.1977, 0.2266, 0.2093, 0.2047, 0.2188, 0.2240, 0.2235, 0.2262,
        0.1767, 0.2323, 0.2489, 0.2167, 0.2265, 0.2073, 0.2351, 0.2023, 0.2141,
        0.2360, 0.2374, 0.2311, 0.2053, 0.2656, 0.2351, 0.2132, 0.2156, 0.2154,
        0.2669, 0.2067, 0.2717, 0.2011, 0.2261, 0.2388, 0.1863, 0.2022, 0.2130,
        0.2707, 0.2147, 0.1876, 0.3047, 0.2348, 0.3224, 0.1856, 0.2517, 0.2655,
        0.2334, 0.1710, 0.2567, 0.2298, 0.2356, 0.1928, 0.2168, 0.2052, 0.2172,
        0.2345, 0.2461, 0.2189, 0.2224, 0.2320, 0.2475, 0.2365, 0.2608, 0.2352,
        0.2440, 0.2353, 0.2048, 0.2074, 0.2415, 0.2564, 0.2100, 0.2577, 0.2297,
        0.2254, 0.2348, 0.2235, 0.2468, 0.2157, 0.2460, 0.1454, 0.2169, 0.2264,
        0.1875, 0.2342, 0.2355, 0.2114, 0.1981, 0.2544, 0.2453, 0.1858, 0.2307,
        0.2296])
true tensor([ 0.3100,  0.4461,  0.3402,  0.5746,  0.3402,  0.5746,  0.5519,  0.4687,
        -0.4914, -0.3251, -0.4536, -0.2344,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.3251, -0.4536, -0.2344, -0.3024,  0.4687,  0.2646,  0.3402,  0.2797,
         0.4461,  0.3402,  0.5746,  0.5519,  0.5746,  0.5519,  0.4687,  0.2646,
         0.3100,  0.4461,  0.3402,  0.5746, -0.2344, -0.3024,  0.0302,  0.1663,
        -0.1663, -0.4914, -0.3251, -0.4536,  0.4687,  0.2646,  0.3402,  0.2797,
        -0.4536, -0.2344, -0.3024,  0.0302, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.3251, -0.4536, -0.2344, -0.3024, -0.3024,  0.0302,  0.1663,  0.3100,
         0.5746,  0.5519,  0.4687,  0.2646, -0.4914, -0.3251, -0.4536, -0.2344,
         0.5519,  0.4687,  0.2646,  0.3402,  0.2646,  0.3402,  0.2797,  0.2268,
        -0.1663, -0.4914, -0.3251, -0.4536,  0.5519,  0.4687,  0.2646,  0.3402,
         0.0302,  0.1663,  0.3100,  0.4461,  0.5519,  0.4687,  0.2646,  0.3402,
         0.4461,  0.3402,  0.5746,  0.5519,  0.0302,  0.1663,  0.3100,  0.4461,
         0.4687,  0.2646,  0.3402,  0.2797,  0.5746,  0.5519,  0.4687,  0.2646,
         0.0302,  0.1663,  0.3100,  0.4461,  0.3100,  0.4461,  0.3402,  0.5746,
        -0.3024,  0.0302,  0.1663,  0.3100,  0.3402,  0.5746,  0.5519,  0.4687,
         0.4461,  0.3402,  0.5746,  0.5519, -0.4914, -0.3251, -0.4536, -0.2344,
         0.3402,  0.5746,  0.5519,  0.4687, -0.2344, -0.3024,  0.0302,  0.1663,
        -0.4536, -0.2344, -0.3024,  0.0302,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.1663, -0.4914, -0.3251, -0.4536, -0.3251, -0.4536, -0.2344, -0.3024,
        -0.3024,  0.0302,  0.1663,  0.3100,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.2344, -0.3024,  0.0302,  0.1663])
Epoch: 2, Steps: 1 | Train Loss: 0.9319768 Vali Loss: 0.1343388
lr = 0.0000904518
Validation loss decreased (0.135382 --> 0.134339).  Saving model ...
1it [00:00,  6.05it/s]
1it [00:00, 13.15it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5028882026672363
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2056, 0.2283, 0.2259, 0.2366, 0.1967, 0.2550, 0.2458, 0.2413, 0.2249,
        0.2082, 0.2239, 0.2576, 0.2573, 0.2142, 0.2222, 0.2264, 0.2062, 0.2174,
        0.1938, 0.2331, 0.2386, 0.1902, 0.2712, 0.2269, 0.0875, 0.2156, 0.2156,
        0.0919, 0.1972, 0.1963, 0.2243, 0.2455, 0.2498, 0.1943, 0.2268, 0.2089,
        0.2411, 0.1813, 0.2051, 0.2102, 0.1869, 0.2152, 0.1886, 0.2634, 0.2324,
        0.2009, 0.2112, 0.2181, 0.2388, 0.2354, 0.2219, 0.2255, 0.1991, 0.2478,
        0.2226, 0.1981, 0.1685, 0.1900, 0.2445, 0.2297, 0.1854, 0.2273, 0.2625,
        0.2323, 0.2119, 0.2293, 0.2019, 0.2289, 0.2504, 0.2105, 0.2461, 0.2170,
        0.1948, 0.2591, 0.1739, 0.1932, 0.2238, 0.2198, 0.2435, 0.2430, 0.2359,
        0.2354, 0.2177, 0.2070, 0.2443, 0.2616, 0.2008, 0.2169, 0.2581, 0.2128,
        0.2407, 0.1940, 0.2327, 0.1825, 0.2241, 0.1600, 0.2446, 0.1941, 0.1994,
        0.2276, 0.2149, 0.2058, 0.2071, 0.2328, 0.2090, 0.1804, 0.2193, 0.2455,
        0.2429, 0.1811, 0.2229, 0.2093, 0.2302, 0.2023, 0.2296, 0.2590, 0.2468,
        0.2009, 0.2495, 0.2491, 0.1808, 0.3075, 0.2352, 0.1959, 0.2523, 0.2159,
        0.2302, 0.1982, 0.2078, 0.2311, 0.2193, 0.2359, 0.2376, 0.2260, 0.2412,
        0.2164, 0.2476, 0.2117, 0.2129, 0.2252, 0.2417, 0.2455, 0.1982, 0.2251,
        0.1996, 0.1980, 0.2657, 0.2257, 0.2374, 0.2163, 0.2405, 0.2018, 0.4626,
        0.2097, 0.2300, 0.0179, 0.2436, 0.2518, 0.2634, 0.1974, 0.2744, 0.2512,
        0.2462, 0.1789, 0.2441, 0.2150, 0.2398, 0.2017, 0.2464, 0.2502, 0.2291,
        0.1912])
true tensor([ 0.1663,  0.3100,  0.4461,  0.3402,  0.5746,  0.5519,  0.4687,  0.2646,
         0.3402,  0.5746,  0.5519,  0.4687,  0.4461,  0.3402,  0.5746,  0.5519,
        -0.3251, -0.4536, -0.2344, -0.3024,  0.4461,  0.3402,  0.5746,  0.5519,
        -0.2344, -0.3024,  0.0302,  0.1663, -0.4914, -0.3251, -0.4536, -0.2344,
         0.4461,  0.3402,  0.5746,  0.5519, -0.1663, -0.4914, -0.3251, -0.4536,
        -0.4536, -0.2344, -0.3024,  0.0302, -0.3024,  0.0302,  0.1663,  0.3100,
        -0.2344, -0.3024,  0.0302,  0.1663,  0.3100,  0.4461,  0.3402,  0.5746,
         0.5519,  0.4687,  0.2646,  0.3402, -0.3251, -0.4536, -0.2344, -0.3024,
         0.2646,  0.3402,  0.2797,  0.2268,  0.4687,  0.2646,  0.3402,  0.2797,
         0.5519,  0.4687,  0.2646,  0.3402, -0.3024,  0.0302,  0.1663,  0.3100,
         0.3402,  0.5746,  0.5519,  0.4687,  0.0302,  0.1663,  0.3100,  0.4461,
         0.5746,  0.5519,  0.4687,  0.2646, -0.3251, -0.4536, -0.2344, -0.3024,
        -0.2344, -0.3024,  0.0302,  0.1663,  0.0302,  0.1663,  0.3100,  0.4461,
         0.5746,  0.5519,  0.4687,  0.2646,  0.3402,  0.5746,  0.5519,  0.4687,
         0.0302,  0.1663,  0.3100,  0.4461,  0.4687,  0.2646,  0.3402,  0.2797,
         0.3100,  0.4461,  0.3402,  0.5746,  0.4687,  0.2646,  0.3402,  0.2797,
        -0.3024,  0.0302,  0.1663,  0.3100, -0.4914, -0.3251, -0.4536, -0.2344,
        -0.4536, -0.2344, -0.3024,  0.0302,  0.1663,  0.3100,  0.4461,  0.3402,
         0.5519,  0.4687,  0.2646,  0.3402, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.4914, -0.3251, -0.4536, -0.2344, -0.1663, -0.4914, -0.3251, -0.4536,
         0.1663,  0.3100,  0.4461,  0.3402,  0.3100,  0.4461,  0.3402,  0.5746,
        -0.1663, -0.4914, -0.3251, -0.4536])
Epoch: 3, Steps: 1 | Train Loss: 0.9270856 Vali Loss: 0.1312104
lr = 0.0000793913
Validation loss decreased (0.134339 --> 0.131210).  Saving model ...
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.5009326934814453
1it [00:00,  6.13it/s]
1it [00:00, 11.88it/s]
1it [00:00,  6.44it/s]
1it [00:00, 11.42it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2586, 0.1823, 0.2388, 0.2699, 0.1899, 0.2608, 0.1884, 0.2598, 0.2139,
        0.2488, 0.2141, 0.2199, 0.2560, 0.2277, 0.2495, 0.2355, 0.2179, 0.2332,
        0.2418, 0.2055, 0.0726, 0.3702, 0.3454, 0.2714, 0.2554, 0.2226, 0.2501,
        0.2250, 0.2416, 0.1948, 0.2550, 0.2068, 0.2234, 0.2110, 0.2277, 0.2105,
        0.3082, 0.1314, 0.2686, 0.1526, 0.2061, 0.2050, 0.2349, 0.2412, 0.2237,
        0.2463, 0.2044, 0.2237, 0.2231, 0.2044, 0.2397, 0.1991, 0.2245, 0.2345,
        0.2263, 0.1727, 0.2632, 0.1905, 0.2614, 0.2182, 0.2268, 0.2234, 0.2528,
        0.2462, 0.2184, 0.2296, 0.2146, 0.2173, 0.2388, 0.2293, 0.2350, 0.2335,
        0.2205, 0.2452, 0.1949, 0.2438, 0.2110, 0.1921, 0.1570, 0.2579, 0.2652,
        0.2509, 0.1733, 0.1715, 0.2584, 0.2217, 0.2150, 0.2472, 0.2533, 0.2085,
        0.2579, 0.2184, 0.2278, 0.2124, 0.2322, 0.2672, 0.4419, 0.1179, 0.2772,
        0.0062, 0.2278, 0.2407, 0.2418, 0.2285, 0.2471, 0.2222, 0.2414, 0.2224,
        0.2016, 0.2555, 0.2139, 0.2479, 0.2010, 0.2295, 0.2254, 0.2126, 0.2418,
        0.2311, 0.2299, 0.2333, 0.2087, 0.2467, 0.2209, 0.2306, 0.2316, 0.2223,
        0.2541, 0.2405, 0.2286, 0.2405, 0.1880, 0.2507, 0.2352, 0.2259, 0.1927,
        0.2948, 0.2479, 0.2370, 0.2173, 0.2263, 0.1779, 0.1966, 0.1987, 0.2326,
        0.1959, 0.2432, 0.2350, 0.2485, 0.2586, 0.2505, 0.2020, 0.2062, 0.2210,
        0.1833, 0.2279, 0.1918, 0.2530, 0.2445, 0.2062, 0.2035, 0.2648, 0.1671,
        0.2642, 0.2423, 0.2479, 0.1944, 0.2030, 0.2320, 0.2399, 0.1711, 0.2163,
        0.2417])
true tensor([ 0.4687,  0.2646,  0.3402,  0.2797,  0.3100,  0.4461,  0.3402,  0.5746,
         0.1663,  0.3100,  0.4461,  0.3402, -0.3024,  0.0302,  0.1663,  0.3100,
         0.2646,  0.3402,  0.2797,  0.2268, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.3024,  0.0302,  0.1663,  0.3100, -0.1663, -0.4914, -0.3251, -0.4536,
         0.4461,  0.3402,  0.5746,  0.5519,  0.3402,  0.5746,  0.5519,  0.4687,
        -0.4914, -0.3251, -0.4536, -0.2344,  0.3100,  0.4461,  0.3402,  0.5746,
        -0.2344, -0.3024,  0.0302,  0.1663,  0.0302,  0.1663,  0.3100,  0.4461,
         0.5746,  0.5519,  0.4687,  0.2646,  0.0302,  0.1663,  0.3100,  0.4461,
         0.0302,  0.1663,  0.3100,  0.4461, -0.1663, -0.4914, -0.3251, -0.4536,
         0.3100,  0.4461,  0.3402,  0.5746, -0.3024,  0.0302,  0.1663,  0.3100,
         0.1663,  0.3100,  0.4461,  0.3402,  0.4461,  0.3402,  0.5746,  0.5519,
         0.4687,  0.2646,  0.3402,  0.2797,  0.3402,  0.5746,  0.5519,  0.4687,
         0.3402,  0.5746,  0.5519,  0.4687, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.1663, -0.4914, -0.3251, -0.4536,  0.5746,  0.5519,  0.4687,  0.2646,
        -0.3251, -0.4536, -0.2344, -0.3024,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.3251, -0.4536, -0.2344, -0.3024, -0.4914, -0.3251, -0.4536, -0.2344,
        -0.3251, -0.4536, -0.2344, -0.3024, -0.2344, -0.3024,  0.0302,  0.1663,
        -0.4536, -0.2344, -0.3024,  0.0302,  0.5519,  0.4687,  0.2646,  0.3402,
         0.5519,  0.4687,  0.2646,  0.3402, -0.4914, -0.3251, -0.4536, -0.2344,
         0.4461,  0.3402,  0.5746,  0.5519,  0.5519,  0.4687,  0.2646,  0.3402,
         0.4687,  0.2646,  0.3402,  0.2797, -0.2344, -0.3024,  0.0302,  0.1663,
         0.5746,  0.5519,  0.4687,  0.2646])
Epoch: 4, Steps: 1 | Train Loss: 0.9238706 Vali Loss: 0.1350403
lr = 0.0000654543
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.4995613098144531
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2433, 0.2251, 0.2030, 0.2564, 0.2639, 0.1166, 0.2846, 0.2468, 0.2174,
        0.2282, 0.2552, 0.2609, 0.2171, 0.2166, 0.2015, 0.2570, 0.2097, 0.2211,
        0.2092, 0.2284, 0.2164, 0.2381, 0.2110, 0.2347, 0.2352, 0.2395, 0.2394,
        0.2184, 0.2327, 0.2562, 0.2302, 0.2147, 0.1746, 0.1774, 0.2189, 0.2422,
        0.2385, 0.1839, 0.2229, 0.1903, 0.2176, 0.2261, 0.2467, 0.2278, 0.2136,
        0.2289, 0.2403, 0.2262, 0.1910, 0.2015, 0.2473, 0.1997, 0.2250, 0.2304,
        0.1747, 0.2222, 0.2201, 0.2341, 0.1945, 0.2884, 0.2265, 0.2273, 0.2081,
        0.2187, 0.2340, 0.2032, 0.2180, 0.2756, 0.2476, 0.1838, 0.2459, 0.2116,
        0.2819, 0.2601, 0.1934, 0.2713, 0.2414, 0.2174, 0.2127, 0.2012, 0.2158,
        0.2176, 0.2271, 0.2388, 0.2177, 0.2136, 0.2083, 0.2071, 0.2827, 0.2085,
        0.2823, 0.2043, 0.2383, 0.2389, 0.2834, 0.1815, 0.1679, 0.2722, 0.1971,
        0.2088, 0.2833, 0.1851, 0.2843, 0.1549, 0.2358, 0.2326, 0.2134, 0.2258,
        0.2287, 0.1902, 0.2258, 0.2193, 0.2524, 0.2189, 0.2251, 0.1959, 0.2132,
        0.2409, 0.2112, 0.2232, 0.2373, 0.3302, 0.3015, 0.1952, 0.3412, 0.0644,
        0.4305, 0.2417, 0.2516, 0.2264, 0.2445, 0.1957, 0.2274, 0.2029, 0.2430,
        0.2409, 0.2247, 0.2537, 0.2352, 0.1947, 0.2477, 0.2330, 0.2288, 0.2233,
        0.2341, 0.2143, 0.2377, 0.2003, 0.2160, 0.2201, 0.2503, 0.2032, 0.2226,
        0.2191, 0.1965, 0.2543, 0.2034, 0.2322, 0.2298, 0.2371, 0.2188, 0.1676,
        0.2418, 0.2241, 0.2401, 0.2249, 0.2120, 0.2292, 0.2596, 0.2394, 0.2235,
        0.2343])
true tensor([ 0.0302,  0.1663,  0.3100,  0.4461,  0.4687,  0.2646,  0.3402,  0.2797,
        -0.4536, -0.2344, -0.3024,  0.0302,  0.3402,  0.5746,  0.5519,  0.4687,
         0.2646,  0.3402,  0.2797,  0.2268, -0.3251, -0.4536, -0.2344, -0.3024,
         0.5519,  0.4687,  0.2646,  0.3402,  0.0302,  0.1663,  0.3100,  0.4461,
         0.5519,  0.4687,  0.2646,  0.3402, -0.1663, -0.4914, -0.3251, -0.4536,
         0.3402,  0.5746,  0.5519,  0.4687, -0.4914, -0.3251, -0.4536, -0.2344,
        -0.3251, -0.4536, -0.2344, -0.3024,  0.0302,  0.1663,  0.3100,  0.4461,
         0.5746,  0.5519,  0.4687,  0.2646, -0.3024,  0.0302,  0.1663,  0.3100,
        -0.2344, -0.3024,  0.0302,  0.1663,  0.4461,  0.3402,  0.5746,  0.5519,
         0.1663,  0.3100,  0.4461,  0.3402, -0.3024,  0.0302,  0.1663,  0.3100,
        -0.3024,  0.0302,  0.1663,  0.3100, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.4536, -0.2344, -0.3024,  0.0302,  0.3402,  0.5746,  0.5519,  0.4687,
         0.3100,  0.4461,  0.3402,  0.5746,  0.5746,  0.5519,  0.4687,  0.2646,
         0.3100,  0.4461,  0.3402,  0.5746, -0.1663, -0.4914, -0.3251, -0.4536,
         0.4687,  0.2646,  0.3402,  0.2797,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.2344, -0.3024,  0.0302,  0.1663,  0.4687,  0.2646,  0.3402,  0.2797,
         0.4461,  0.3402,  0.5746,  0.5519, -0.4914, -0.3251, -0.4536, -0.2344,
         0.5519,  0.4687,  0.2646,  0.3402, -0.4914, -0.3251, -0.4536, -0.2344,
         0.4461,  0.3402,  0.5746,  0.5519, -0.2344, -0.3024,  0.0302,  0.1663,
        -0.3251, -0.4536, -0.2344, -0.3024,  0.3100,  0.4461,  0.3402,  0.5746,
         0.5746,  0.5519,  0.4687,  0.2646,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.1663, -0.4914, -0.3251, -0.4536])
Epoch: 5, Steps: 1 | Train Loss: 0.9217455 Vali Loss: 0.1326875
lr = 0.0000500050
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 6 cost time: 0.4853708744049072
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2073,  0.2770,  0.1755,  0.2642,  0.3211,  0.2331,  0.2622, -0.0326,
         0.2324,  0.2008,  0.2223,  0.1962,  0.2232,  0.2080,  0.1955,  0.2405,
         0.2318,  0.2395,  0.2052,  0.2419,  0.2216,  0.2258,  0.2129,  0.2408,
         0.2136,  0.2329,  0.2158,  0.2009,  0.2550,  0.2268,  0.1263,  0.2572,
         0.2330,  0.2085,  0.2201,  0.2386,  0.2303,  0.2242,  0.2265,  0.2177,
         0.2648,  0.1706,  0.2685,  0.2059,  0.2457,  0.2186,  0.2259,  0.2268,
         0.2291,  0.2130,  0.2305,  0.2685,  0.2326,  0.2044,  0.2000,  0.1911,
         0.2272,  0.2187,  0.2307,  0.2274,  0.2278,  0.1783,  0.2863,  0.2782,
         0.2004,  0.2405,  0.2170,  0.2195,  0.2417,  0.1794,  0.3271,  0.1955,
         0.2400,  0.2148,  0.2281,  0.2099,  0.2187,  0.2229,  0.2700,  0.1839,
         0.2339,  0.2166,  0.2373,  0.1839,  0.2685,  0.2200,  0.2458,  0.2277,
         0.2540,  0.2034,  0.2552,  0.2024,  0.2108,  0.2404,  0.2571,  0.2069,
         0.2241,  0.2226,  0.2183,  0.2451,  0.2397,  0.2195,  0.1924,  0.2224,
         0.2651,  0.2275,  0.2269,  0.2095,  0.2436,  0.2558,  0.2029,  0.2514,
         0.2388,  0.2211,  0.2261,  0.2476,  0.2440,  0.1792,  0.2401,  0.2496,
         0.2099,  0.2248,  0.4005,  0.1653,  0.2479,  0.2102,  0.2309,  0.2103,
         0.2140,  0.2211,  0.2245,  0.2509,  0.2053,  0.2230,  0.2097,  0.2332,
         0.2601,  0.2007,  0.2399,  0.2348,  0.4843,  0.2570,  0.2366, -0.1297,
         0.2429,  0.2010,  0.2600,  0.2326,  0.2316,  0.2224,  0.2588,  0.1993,
         0.2261,  0.2290,  0.2673,  0.1862,  0.2288,  0.2256,  0.1958,  0.2503,
         0.3130,  0.1570,  0.3011,  0.3113,  0.2298,  0.2025,  0.2302,  0.2179,
         0.2183,  0.2191,  0.2240,  0.2646])
true tensor([ 0.3100,  0.4461,  0.3402,  0.5746,  0.3402,  0.5746,  0.5519,  0.4687,
         0.3402,  0.5746,  0.5519,  0.4687, -0.3251, -0.4536, -0.2344, -0.3024,
         0.0302,  0.1663,  0.3100,  0.4461,  0.1663,  0.3100,  0.4461,  0.3402,
         0.3100,  0.4461,  0.3402,  0.5746, -0.2344, -0.3024,  0.0302,  0.1663,
         0.3402,  0.5746,  0.5519,  0.4687,  0.4461,  0.3402,  0.5746,  0.5519,
         0.5746,  0.5519,  0.4687,  0.2646,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.4536, -0.2344, -0.3024,  0.0302, -0.3024,  0.0302,  0.1663,  0.3100,
        -0.3251, -0.4536, -0.2344, -0.3024,  0.5519,  0.4687,  0.2646,  0.3402,
         0.2646,  0.3402,  0.2797,  0.2268, -0.3024,  0.0302,  0.1663,  0.3100,
        -0.1663, -0.4914, -0.3251, -0.4536, -0.1663, -0.4914, -0.3251, -0.4536,
         0.4461,  0.3402,  0.5746,  0.5519,  0.4687,  0.2646,  0.3402,  0.2797,
         0.4687,  0.2646,  0.3402,  0.2797,  0.3100,  0.4461,  0.3402,  0.5746,
        -0.4914, -0.3251, -0.4536, -0.2344,  0.0302,  0.1663,  0.3100,  0.4461,
        -0.4536, -0.2344, -0.3024,  0.0302,  0.1663,  0.3100,  0.4461,  0.3402,
        -0.1663, -0.4914, -0.3251, -0.4536,  0.5746,  0.5519,  0.4687,  0.2646,
        -0.2344, -0.3024,  0.0302,  0.1663, -0.4536, -0.2344, -0.3024,  0.0302,
        -0.2344, -0.3024,  0.0302,  0.1663, -0.3251, -0.4536, -0.2344, -0.3024,
        -0.3024,  0.0302,  0.1663,  0.3100, -0.4914, -0.3251, -0.4536, -0.2344,
        -0.4914, -0.3251, -0.4536, -0.2344,  0.5519,  0.4687,  0.2646,  0.3402,
         0.5519,  0.4687,  0.2646,  0.3402,  0.0302,  0.1663,  0.3100,  0.4461,
         0.4687,  0.2646,  0.3402,  0.2797,  0.4461,  0.3402,  0.5746,  0.5519,
         0.5746,  0.5519,  0.4687,  0.2646])
1it [00:00,  6.19it/s]
1it [00:00, 11.81it/s]
1it [00:00, 10.23it/s]
Epoch: 6, Steps: 1 | Train Loss: 0.9203054 Vali Loss: 0.1353931
lr = 0.0000345557
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 372) (1, 372)
test shape: (1, 1, 372) (1, 1, 372)
mae:0.8345, mse:1.1550, rmse:1.0747, r2:-1.4543
mse_mean = 1.1550, mse_std = 0.0000
r2_mean = -1.4543, mae_std = 0.0000