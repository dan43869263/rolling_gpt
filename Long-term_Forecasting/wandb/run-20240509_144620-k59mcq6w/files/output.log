['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.12s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.4224486351013184
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2323,  0.1275,  0.1752,  0.1248,  0.2259, -0.0177,  0.2176,  0.2010,
         0.1065,  0.1860,  0.2413,  0.2605, -0.0699,  0.0594,  0.1741,  0.3650,
         0.1658,  0.2376,  0.2455,  0.3652,  0.0409,  0.2399,  0.2740, -0.0563,
         0.1795,  0.1662,  0.3342, -0.0230,  0.0385,  0.0012,  0.2827, -0.0442,
         0.2706,  0.1471,  0.4285,  0.0568,  0.1595,  0.0086,  0.4556,  0.0958,
         0.2693,  0.0590,  0.5535,  0.0986,  0.0196, -0.0240,  0.3237,  0.3912,
         0.3420, -0.1628,  0.3868, -0.0337,  0.2727,  0.0048,  0.4003,  0.0664,
         0.0581,  0.1265,  0.2693,  0.0743,  0.2175,  0.2293,  0.2127,  0.1883,
         0.3279, -0.2119,  0.4407,  0.0540,  0.1765,  0.1566,  0.1321,  0.0063,
         0.0078,  0.1116,  0.3283,  0.5060,  0.2402, -0.0630,  0.4526,  0.1800,
         0.1415,  0.1341,  0.0775,  0.1208, -0.0628,  0.1798,  0.2873,  0.3520,
         0.2910, -0.0022,  0.4684,  0.0893,  0.1092,  0.1118,  0.2474,  0.4291,
         0.3220, -0.2511,  0.8445, -0.0480,  0.2067,  0.2448,  0.2450,  0.1143,
        -0.0367,  0.1492,  0.1877,  0.3813, -0.1016,  0.2127,  0.2350,  0.6084,
         0.1548,  0.1307,  0.2274, -0.0114,  0.1784,  0.2275,  0.2354,  0.2001,
         0.2109,  0.1263,  0.1260,  0.2398,  0.1161,  0.0432,  0.1910,  0.0158,
        -0.0749,  0.1454,  0.3470,  0.4382,  0.1086,  0.1178,  0.1558,  0.5624,
         0.1421,  0.0490,  0.2340, -0.0057,  0.1869,  0.0584,  0.3561,  0.4981,
         0.1297,  0.2008,  0.2904, -0.1141,  0.0845,  0.1282,  0.2072,  0.3806,
         0.2084,  0.0284,  0.2329,  0.0964,  0.2061,  0.1039,  0.1774,  0.1299,
         0.1786,  0.2669,  0.1444,  0.1069,  0.2228,  0.1123,  0.3423,  0.1745,
         0.0498,  0.1309,  0.1623,  0.4128])
true tensor([-0.5700, -1.3300, -0.9000,  0.9900,  5.0500,  0.9800, -1.1800, -0.4600,
        -0.4400,  5.0500,  0.9800, -1.1800,  1.8400, -0.4400,  5.0500,  0.9800,
         0.0300,  1.8400, -0.4400,  5.0500, -0.4800, -0.4200, -0.5100, -0.5700,
        -0.9000,  0.9900,  1.2900, -0.3500, -1.3300, -0.9000,  0.9900,  1.2900,
         0.0300,  1.8400, -0.4400,  5.0500, -1.1800, -0.4600, -0.4800, -0.4200,
        -0.4600, -0.4800, -0.4200, -0.5100, -0.9000,  0.9900,  1.2900, -0.3500,
         0.9800, -1.1800, -0.4600, -0.4800, -0.5700, -1.3300, -0.9000,  0.9900,
        -0.5100, -0.5700, -1.3300, -0.9000, -0.4400,  5.0500,  0.9800, -1.1800,
        -0.9000,  0.9900,  1.2900, -0.3500, -0.4200, -0.5100, -0.5700, -1.3300,
        -1.1800, -0.4600, -0.4800, -0.4200,  0.9900,  1.2900, -0.3500, -0.6800,
        -1.1800, -0.4600, -0.4800, -0.4200, -1.3300, -0.9000,  0.9900,  1.2900,
        -0.5100, -0.5700, -1.3300, -0.9000,  5.0500,  0.9800, -1.1800, -0.4600,
        -1.3300, -0.9000,  0.9900,  1.2900,  0.0300,  1.8400, -0.4400,  5.0500,
        -0.4600, -0.4800, -0.4200, -0.5100, -0.5100, -0.5700, -1.3300, -0.9000,
         0.9800, -1.1800, -0.4600, -0.4800,  1.8400, -0.4400,  5.0500,  0.9800,
         0.9900,  1.2900, -0.3500, -0.6800, -0.4600, -0.4800, -0.4200, -0.5100,
        -0.4800, -0.4200, -0.5100, -0.5700, -0.5700, -1.3300, -0.9000,  0.9900,
        -0.4800, -0.4200, -0.5100, -0.5700, -0.4200, -0.5100, -0.5700, -1.3300,
         1.2900, -0.3500, -0.6800, -0.7300,  0.9900,  1.2900, -0.3500, -0.6800,
        -0.4200, -0.5100, -0.5700, -1.3300, -0.4400,  5.0500,  0.9800, -1.1800,
         5.0500,  0.9800, -1.1800, -0.4600,  1.8400, -0.4400,  5.0500,  0.9800,
         0.9800, -1.1800, -0.4600, -0.4800])
Epoch: 1, Steps: 1 | Train Loss: 4.5652704 Vali Loss: 2.4934821
lr = 0.0000975531
1it [00:00, 11.60it/s]
1it [00:00,  5.73it/s]
1it [00:00, 11.61it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5449213981628418
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 2.4938e-01, -6.4930e-02,  4.2463e-01, -1.3159e-02,  1.1483e-01,
         7.0846e-02,  3.4499e-01,  1.1193e-01,  2.7324e-01,  8.0527e-02,
         2.8991e-01,  1.9222e-01,  3.2856e-01, -1.0788e-01,  3.7325e-01,
         4.4528e-02,  2.2226e-01,  1.7007e-01,  1.9587e-01,  2.4757e-01,
         6.2706e-02,  1.4760e-01,  2.5119e-01, -9.5077e-02,  2.7400e-01,
         3.9276e-02,  5.4169e-01,  1.3834e-01,  6.5046e-02,  1.9652e-01,
         2.5177e-01,  3.3409e-01,  8.0933e-02,  1.4805e-01,  2.8056e-01,
        -1.3844e-01,  1.0138e-01,  7.5684e-02,  3.3123e-01,  3.0839e-02,
         1.9959e-01,  1.4966e-01,  2.3347e-01,  5.9174e-02,  9.8449e-03,
         1.9357e-01,  2.2175e-01,  4.4056e-01,  2.2460e-01, -1.9883e-02,
         4.8274e-01,  1.4156e-01,  1.8863e-01,  2.2351e-01,  1.4671e-01,
         3.8190e-01,  1.9205e-01,  1.7240e-01,  8.8328e-02,  1.9571e-01,
         2.6722e-03,  2.4229e-01,  2.4099e-01,  4.8140e-01,  2.2452e-01,
         1.9033e-01,  2.5227e-01,  7.6501e-03,  1.1435e-01,  1.7713e-01,
         2.6800e-01,  2.2278e-01,  2.7613e-02,  1.4132e-01,  2.0130e-01,
         4.2321e-01,  1.3890e-01,  4.3158e-02,  2.1895e-01,  4.2302e-02,
         1.0534e-01,  2.0559e-01,  2.7196e-01,  3.2051e-01,  3.5351e-01,
        -9.4261e-02,  5.1466e-01,  1.5976e-02,  1.6522e-01, -6.7095e-02,
         3.6358e-01,  1.0893e-01,  1.5500e-01,  1.8665e-01,  1.6708e-01,
         1.3385e-01, -3.9327e-02,  1.4129e-01,  2.5325e-01, -1.0689e-01,
         5.4621e-02,  3.3350e-01,  2.3670e-01,  3.2942e-01,  3.8682e-01,
         9.3155e-02,  1.5001e-01,  5.9905e-02,  1.7199e-01, -3.5727e-01,
         6.4439e-01,  2.7679e-02,  1.1222e-01, -6.3520e-02,  2.6905e-01,
        -1.0839e-02,  6.9052e-02,  1.4525e-01,  2.7624e-01,  4.5988e-01,
         2.1947e-01,  6.1980e-02,  5.2881e-01,  3.7668e-02, -2.7356e-04,
         1.3445e-01,  2.0874e-01,  3.5676e-01,  1.4393e-01,  9.9321e-02,
         2.1311e-02,  6.0885e-01,  2.2851e-01,  4.4688e-02,  3.3746e-01,
        -5.6711e-03,  1.4605e-01,  1.5642e-01,  3.6122e-01, -8.4432e-02,
         1.7729e-02,  1.8948e-01,  2.5243e-01,  5.5143e-01,  1.8319e-01,
         1.4013e-01,  2.1723e-01,  4.7558e-02,  1.3131e-01,  2.9190e-01,
         1.8064e-01,  4.8718e-02,  1.4980e-01,  2.1077e-01,  1.3287e-01,
         2.1442e-01,  1.9942e-01,  1.5145e-01,  2.3061e-01,  2.0449e-01,
         1.3008e-01,  6.4116e-02,  3.1400e-01, -7.3348e-02,  3.7430e-02,
         1.6249e-01,  2.4626e-01,  4.0330e-01,  2.9255e-01, -4.6080e-02,
         4.9302e-01,  1.1760e-01])
true tensor([-0.4200, -0.5100, -0.5700, -1.3300, -0.5700, -1.3300, -0.9000,  0.9900,
         1.8400, -0.4400,  5.0500,  0.9800, -0.4800, -0.4200, -0.5100, -0.5700,
        -0.4400,  5.0500,  0.9800, -1.1800,  0.9900,  1.2900, -0.3500, -0.6800,
        -0.5100, -0.5700, -1.3300, -0.9000, -1.3300, -0.9000,  0.9900,  1.2900,
        -0.4200, -0.5100, -0.5700, -1.3300,  0.9800, -1.1800, -0.4600, -0.4800,
         0.0300,  1.8400, -0.4400,  5.0500,  0.9900,  1.2900, -0.3500, -0.6800,
         5.0500,  0.9800, -1.1800, -0.4600,  5.0500,  0.9800, -1.1800, -0.4600,
        -0.4400,  5.0500,  0.9800, -1.1800, -1.1800, -0.4600, -0.4800, -0.4200,
        -1.3300, -0.9000,  0.9900,  1.2900,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.9000,  0.9900,  1.2900, -0.3500,  1.2900, -0.3500, -0.6800, -0.7300,
         0.0300,  1.8400, -0.4400,  5.0500, -0.9000,  0.9900,  1.2900, -0.3500,
        -0.4600, -0.4800, -0.4200, -0.5100, -0.9000,  0.9900,  1.2900, -0.3500,
        -0.5100, -0.5700, -1.3300, -0.9000, -0.4600, -0.4800, -0.4200, -0.5100,
         0.9900,  1.2900, -0.3500, -0.6800, -1.3300, -0.9000,  0.9900,  1.2900,
        -0.4600, -0.4800, -0.4200, -0.5100, -0.4200, -0.5100, -0.5700, -1.3300,
        -1.1800, -0.4600, -0.4800, -0.4200, -0.5700, -1.3300, -0.9000,  0.9900,
        -0.5100, -0.5700, -1.3300, -0.9000,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.5700, -1.3300, -0.9000,  0.9900,  0.9800, -1.1800, -0.4600, -0.4800,
         5.0500,  0.9800, -1.1800, -0.4600, -0.4800, -0.4200, -0.5100, -0.5700,
         0.0300,  1.8400, -0.4400,  5.0500, -0.4400,  5.0500,  0.9800, -1.1800,
        -1.1800, -0.4600, -0.4800, -0.4200, -0.4800, -0.4200, -0.5100, -0.5700,
         0.9800, -1.1800, -0.4600, -0.4800])
Epoch: 2, Steps: 1 | Train Loss: 4.5647507 Vali Loss: 2.4848497
lr = 0.0000904518
Validation loss decreased (2.493482 --> 2.484850).  Saving model ...
1it [00:00,  5.74it/s]
1it [00:00, 11.97it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5349524021148682
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 1.4310e-01,  7.1090e-02,  2.6959e-01, -1.4559e-01,  8.0958e-02,
         4.0815e-02,  2.3772e-01, -6.4704e-02,  2.3030e-02,  2.5152e-01,
         2.9826e-01, -1.6963e-01,  1.3750e-01,  7.7498e-02,  1.6809e-01,
         1.0011e-02,  2.3138e-01,  1.1921e-01,  2.5478e-01,  1.7360e-01,
         1.6605e-01,  5.2056e-02,  1.6982e-01,  4.8652e-01, -4.3450e-02,
        -3.5153e-03,  1.9448e-01,  5.3871e-01,  1.8372e-01,  8.6454e-02,
         2.0058e-01,  2.2365e-01,  2.1292e-01, -1.0430e-01,  3.6363e-01,
         2.5517e-04,  1.2611e-01,  1.3137e-01,  2.2744e-01,  2.7076e-01,
         8.1964e-03,  1.5367e-01,  3.8197e-01,  2.8292e-01,  1.4624e-01,
         2.0306e-01,  8.4365e-02, -3.4485e-02,  3.2612e-01, -5.0359e-02,
         5.1347e-01,  3.7869e-02,  6.7136e-02,  2.4771e-01,  2.6035e-01,
        -8.5990e-02,  6.9534e-02,  2.0065e-01,  3.8368e-01,  3.9796e-01,
         2.3078e-01,  1.6845e-01,  2.6484e-01,  1.3986e-01,  1.1314e-01,
         2.8967e-01,  9.3534e-02,  4.6997e-02,  1.8043e-01,  1.3653e-01,
         5.2237e-02, -7.2923e-02,  4.9667e-02,  8.7359e-02,  1.6900e-01,
        -4.8894e-02,  1.1399e-02,  1.3545e-01,  2.4401e-01,  4.5825e-01,
        -4.8409e-02,  2.6015e-01,  2.6950e-01,  4.1109e-01,  6.9962e-02,
         2.5997e-01,  2.6317e-01, -5.0243e-02,  2.8919e-01, -1.7793e-01,
         4.5078e-01, -2.4379e-02,  9.6533e-02,  1.4192e-01,  1.4137e-01,
         3.7458e-01,  4.3706e-02,  2.1720e-01,  3.4925e-01, -1.3040e-01,
         2.9353e-01, -1.7730e-01,  4.0479e-01,  4.2082e-02, -1.7118e-04,
         4.2855e-01,  3.2447e-01,  4.5901e-01,  1.9780e-01, -1.2937e-01,
         4.3384e-01,  1.0422e-01,  1.4755e-01,  8.2495e-02,  2.6038e-01,
         3.4725e-01, -1.1039e-01,  2.4977e-01,  2.5424e-01,  3.9700e-01,
         8.2071e-02,  5.6831e-02,  1.1454e-01,  4.6293e-01,  3.4492e-01,
        -1.1793e-01,  4.0410e-01,  1.6760e-01,  1.6753e-01, -1.2121e-01,
         4.4340e-01,  4.0558e-02,  2.6464e-01,  1.1268e-01,  3.3547e-01,
         1.6255e-01,  1.4788e-01,  2.3044e-01,  2.8364e-01,  1.1262e-01,
         3.2843e-01, -2.2639e-01,  5.0603e-01, -6.0419e-02,  2.7418e-01,
        -1.5575e-02,  3.3187e-01,  1.7213e-01,  2.6596e-01, -3.5575e-02,
         3.2003e-01,  1.4344e-01,  1.7494e-01,  1.7365e-01,  2.7621e-01,
         2.4698e-01,  1.8262e-01,  2.5695e-01,  2.1387e-01,  2.1711e-01,
        -2.0712e-02,  2.2007e-01,  1.9727e-01,  3.6263e-01,  1.9996e-01,
         1.5866e-01,  4.2394e-01,  1.4724e-01,  1.6451e-01,  1.7323e-01,
         2.2688e-01,  1.2853e-01])
true tensor([-0.4800, -0.4200, -0.5100, -0.5700, -1.3300, -0.9000,  0.9900,  1.2900,
        -0.5700, -1.3300, -0.9000,  0.9900, -0.5100, -0.5700, -1.3300, -0.9000,
        -0.4400,  5.0500,  0.9800, -1.1800, -0.5100, -0.5700, -1.3300, -0.9000,
         0.9800, -1.1800, -0.4600, -0.4800,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.5100, -0.5700, -1.3300, -0.9000,  0.0300,  1.8400, -0.4400,  5.0500,
         5.0500,  0.9800, -1.1800, -0.4600, -1.1800, -0.4600, -0.4800, -0.4200,
         0.9800, -1.1800, -0.4600, -0.4800, -0.4200, -0.5100, -0.5700, -1.3300,
        -0.9000,  0.9900,  1.2900, -0.3500, -0.4400,  5.0500,  0.9800, -1.1800,
         1.2900, -0.3500, -0.6800, -0.7300,  0.9900,  1.2900, -0.3500, -0.6800,
        -0.9000,  0.9900,  1.2900, -0.3500, -1.1800, -0.4600, -0.4800, -0.4200,
        -0.5700, -1.3300, -0.9000,  0.9900, -0.4600, -0.4800, -0.4200, -0.5100,
        -1.3300, -0.9000,  0.9900,  1.2900, -0.4400,  5.0500,  0.9800, -1.1800,
         0.9800, -1.1800, -0.4600, -0.4800, -0.4600, -0.4800, -0.4200, -0.5100,
        -1.3300, -0.9000,  0.9900,  1.2900, -0.5700, -1.3300, -0.9000,  0.9900,
        -0.4600, -0.4800, -0.4200, -0.5100,  0.9900,  1.2900, -0.3500, -0.6800,
        -0.4200, -0.5100, -0.5700, -1.3300,  0.9900,  1.2900, -0.3500, -0.6800,
        -1.1800, -0.4600, -0.4800, -0.4200,  1.8400, -0.4400,  5.0500,  0.9800,
         5.0500,  0.9800, -1.1800, -0.4600, -0.4800, -0.4200, -0.5100, -0.5700,
        -0.9000,  0.9900,  1.2900, -0.3500,  5.0500,  0.9800, -1.1800, -0.4600,
         1.8400, -0.4400,  5.0500,  0.9800,  0.0300,  1.8400, -0.4400,  5.0500,
        -0.4800, -0.4200, -0.5100, -0.5700, -0.4200, -0.5100, -0.5700, -1.3300,
         0.0300,  1.8400, -0.4400,  5.0500])
Epoch: 3, Steps: 1 | Train Loss: 4.5663710 Vali Loss: 2.4986720
lr = 0.0000793913
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.516491174697876
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.0826,  0.1613,  0.2361,  0.3549,  0.0450,  0.1683,  0.2850,  0.4153,
         0.2404,  0.1088,  0.3281,  0.1725, -0.0295,  0.0442,  0.2643,  0.5441,
         0.0159,  0.1785,  0.2201,  0.1783,  0.3207,  0.0013,  0.3936,  0.1298,
         0.2489,  0.0035,  0.3082,  0.1105,  0.1428,  0.2051,  0.2770,  0.1082,
        -0.0493,  0.3196,  0.2501,  0.3908,  0.2463, -0.3138,  0.5651,  0.0363,
         0.2230,  0.2153,  0.2762,  0.2101,  0.1497,  0.0990,  0.1891,  0.2244,
         0.1471,  0.1151,  0.1837,  0.0128,  0.0635,  0.1440,  0.2076, -0.0463,
         0.2391, -0.1195,  0.4243,  0.0906, -0.0447,  0.1352,  0.2551,  0.4655,
         0.3563,  0.0150,  0.3731,  0.1650,  0.2162,  0.2138,  0.1930,  0.1473,
         0.2248, -0.0575,  0.3163,  0.1287,  0.1361,  0.1379,  0.1843,  0.1320,
        -0.0247,  0.1325,  0.2606,  0.3872,  0.1136,  0.1268,  0.0997,  0.1151,
         0.2287,  0.0549,  0.2393,  0.1793,  0.1869,  0.1958,  0.2606,  0.0822,
        -0.2337,  0.2318,  0.3027,  0.2883,  0.1344,  0.2662,  0.2039,  0.4210,
         0.1628,  0.1950,  0.2212,  0.3097,  0.0712,  0.2276,  0.2692, -0.1381,
         0.2146,  0.1659,  0.2070,  0.2659,  0.1646,  0.1427,  0.2235,  0.1893,
         0.2537,  0.2551,  0.1457,  0.1224,  0.2489,  0.2211,  0.2509,  0.2629,
         0.1793,  0.1872,  0.1831,  0.2085,  0.0513,  0.1860,  0.3325,  0.4380,
         0.2661,  0.0484,  0.2115,  0.0219, -0.0011,  0.1432,  0.3457,  0.4677,
         0.2427,  0.0927,  0.4074,  0.1713,  0.1557,  0.1693,  0.1733,  0.2905,
         0.1846,  0.0917,  0.3953,  0.0677,  0.2483,  0.0381,  0.2302, -0.0317,
         0.0372,  0.1019,  0.2341, -0.0507,  0.3355,  0.0064,  0.3687,  0.0625,
         0.0479,  0.0725,  0.2461,  0.4213])
true tensor([ 0.9900,  1.2900, -0.3500, -0.6800, -0.4200, -0.5100, -0.5700, -1.3300,
        -0.4800, -0.4200, -0.5100, -0.5700, -1.1800, -0.4600, -0.4800, -0.4200,
         1.2900, -0.3500, -0.6800, -0.7300,  5.0500,  0.9800, -1.1800, -0.4600,
        -1.1800, -0.4600, -0.4800, -0.4200,  0.0300,  1.8400, -0.4400,  5.0500,
        -0.5100, -0.5700, -1.3300, -0.9000, -0.5700, -1.3300, -0.9000,  0.9900,
         1.8400, -0.4400,  5.0500,  0.9800, -0.4200, -0.5100, -0.5700, -1.3300,
         0.9800, -1.1800, -0.4600, -0.4800, -0.4600, -0.4800, -0.4200, -0.5100,
        -1.3300, -0.9000,  0.9900,  1.2900, -0.4600, -0.4800, -0.4200, -0.5100,
        -0.4600, -0.4800, -0.4200, -0.5100,  0.0300,  1.8400, -0.4400,  5.0500,
        -0.4200, -0.5100, -0.5700, -1.3300, -1.1800, -0.4600, -0.4800, -0.4200,
        -0.4800, -0.4200, -0.5100, -0.5700, -0.5100, -0.5700, -1.3300, -0.9000,
         0.9900,  1.2900, -0.3500, -0.6800, -0.5700, -1.3300, -0.9000,  0.9900,
        -0.5700, -1.3300, -0.9000,  0.9900,  5.0500,  0.9800, -1.1800, -0.4600,
         0.0300,  1.8400, -0.4400,  5.0500, -1.3300, -0.9000,  0.9900,  1.2900,
        -0.4400,  5.0500,  0.9800, -1.1800, -0.4800, -0.4200, -0.5100, -0.5700,
        -0.4400,  5.0500,  0.9800, -1.1800,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.4400,  5.0500,  0.9800, -1.1800,  0.9800, -1.1800, -0.4600, -0.4800,
         5.0500,  0.9800, -1.1800, -0.4600, -0.9000,  0.9900,  1.2900, -0.3500,
        -0.9000,  0.9900,  1.2900, -0.3500,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.5100, -0.5700, -1.3300, -0.9000, -0.9000,  0.9900,  1.2900, -0.3500,
         0.9900,  1.2900, -0.3500, -0.6800,  0.9800, -1.1800, -0.4600, -0.4800,
        -1.3300, -0.9000,  0.9900,  1.2900])
Epoch: 4, Steps: 1 | Train Loss: 4.5652456 Vali Loss: 2.4859564
lr = 0.0000654543
EarlyStopping counter: 2 out of 3
1it [00:00,  6.02it/s]
1it [00:00, 12.31it/s]
1it [00:00,  6.04it/s]
1it [00:00, 11.30it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.5012881755828857
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.2660,  0.2639,  0.3191,  0.4439,  0.0614,  0.1253,  0.2194, -0.0651,
         0.0606,  0.1728,  0.3315,  0.2858,  0.0787,  0.1242,  0.1561, -0.1671,
        -0.0069,  0.2188,  0.1300,  0.0716,  0.2113,  0.2250,  0.1962,  0.2039,
         0.2733,  0.1029,  0.3236,  0.0511,  0.1700,  0.0912,  0.1251,  0.0678,
         0.1356,  0.1470,  0.2737,  0.4365,  0.1722,  0.1360,  0.2761,  0.2905,
         0.2284, -0.0197,  0.5208,  0.0737,  0.2746,  0.1487,  0.2440,  0.2106,
         0.2046,  0.1581,  0.2398,  0.2690,  0.3164,  0.0516,  0.2863,  0.0021,
         0.2482,  0.2548,  0.2232,  0.0478,  0.2120,  0.0137,  0.3243,  0.0805,
         0.1124,  0.1540,  0.2900,  0.4890,  0.0375,  0.2348,  0.2468,  0.3604,
         0.1393,  0.0991,  0.1643,  0.5614,  0.1728,  0.2628,  0.1482,  0.0558,
        -0.0322,  0.2311,  0.3232,  0.3534,  0.2553,  0.1414,  0.2047,  0.2117,
         0.1512,  0.1425,  0.2515,  0.0462,  0.0575,  0.1158,  0.2677,  0.2256,
         0.0363,  0.1712,  0.3518,  0.5089,  0.2837, -0.1705,  0.5698,  0.0583,
         0.2384, -0.0377,  0.1660,  0.0663,  0.1808,  0.1955,  0.2660,  0.1995,
         0.3434, -0.0731,  0.4920,  0.0662,  0.1028,  0.2566,  0.2938, -0.1111,
         0.1663,  0.0872,  0.3817,  0.1395, -0.0815,  0.2317,  0.2351,  0.2036,
         0.4071, -0.1222,  0.5066,  0.0537,  0.1766,  0.1967,  0.1229,  0.1853,
         0.1178,  0.1500,  0.1855,  0.0220,  0.1366,  0.2775,  0.2831,  0.2130,
         0.0995,  0.0870,  0.2914, -0.0778,  0.0447,  0.2263,  0.1007, -0.0701,
         0.2324,  0.1680,  0.1593,  0.1394,  0.0935,  0.1263,  0.2215, -0.0744,
        -0.1143,  0.3449,  0.1412,  0.4484,  0.2345,  0.0219,  0.5398,  0.0334,
         0.1876,  0.2009,  0.1828,  0.1431])
true tensor([-0.4600, -0.4800, -0.4200, -0.5100,  0.9900,  1.2900, -0.3500, -0.6800,
         5.0500,  0.9800, -1.1800, -0.4600, -0.5700, -1.3300, -0.9000,  0.9900,
         1.2900, -0.3500, -0.6800, -0.7300, -0.4400,  5.0500,  0.9800, -1.1800,
        -0.9000,  0.9900,  1.2900, -0.3500, -0.4600, -0.4800, -0.4200, -0.5100,
        -0.9000,  0.9900,  1.2900, -0.3500,  0.0300,  1.8400, -0.4400,  5.0500,
        -0.5700, -1.3300, -0.9000,  0.9900,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.4400,  5.0500,  0.9800, -1.1800, -0.4600, -0.4800, -0.4200, -0.5100,
        -1.3300, -0.9000,  0.9900,  1.2900, -1.1800, -0.4600, -0.4800, -0.4200,
         0.9800, -1.1800, -0.4600, -0.4800, -0.5100, -0.5700, -1.3300, -0.9000,
        -0.4800, -0.4200, -0.5100, -0.5700, -1.1800, -0.4600, -0.4800, -0.4200,
        -1.1800, -0.4600, -0.4800, -0.4200,  5.0500,  0.9800, -1.1800, -0.4600,
         5.0500,  0.9800, -1.1800, -0.4600, -0.5700, -1.3300, -0.9000,  0.9900,
        -0.4200, -0.5100, -0.5700, -1.3300, -1.3300, -0.9000,  0.9900,  1.2900,
        -0.4200, -0.5100, -0.5700, -1.3300,  0.0300,  1.8400, -0.4400,  5.0500,
         0.9900,  1.2900, -0.3500, -0.6800, -0.4800, -0.4200, -0.5100, -0.5700,
         0.9800, -1.1800, -0.4600, -0.4800,  0.9900,  1.2900, -0.3500, -0.6800,
        -0.5100, -0.5700, -1.3300, -0.9000,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.9000,  0.9900,  1.2900, -0.3500,  1.8400, -0.4400,  5.0500,  0.9800,
        -0.5100, -0.5700, -1.3300, -0.9000,  0.9800, -1.1800, -0.4600, -0.4800,
        -0.4400,  5.0500,  0.9800, -1.1800, -0.4200, -0.5100, -0.5700, -1.3300,
        -1.3300, -0.9000,  0.9900,  1.2900, -0.4800, -0.4200, -0.5100, -0.5700,
         0.0300,  1.8400, -0.4400,  5.0500])
Epoch: 5, Steps: 1 | Train Loss: 4.5706725 Vali Loss: 2.5142500
lr = 0.0000500050
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 246) (1, 246)
test shape: (1, 1, 246) (1, 1, 246)
mae:0.9991, mse:1.1944, rmse:1.0929, r2:-0.2650
mse_mean = 1.1944, mse_std = 0.0000
r2_mean = -0.2650, mae_std = 0.0000
1it [00:00,  9.76it/s]