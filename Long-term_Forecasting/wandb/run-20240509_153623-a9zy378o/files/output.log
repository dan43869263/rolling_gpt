['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.10s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.4160826206207275
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2168, 0.2565, 0.2067, 0.2464, 0.1955, 0.2067, 0.2021, 0.2443, 0.2537,
        0.2880, 0.1747, 0.1860, 0.2170, 0.2415, 0.2293, 0.2137, 0.2342, 0.2202,
        0.2582, 0.2297, 0.1915, 0.2457, 0.2155, 0.2516, 0.2256, 0.2194, 0.2411,
        0.2242, 0.2164, 0.2108, 0.2266, 0.2058, 0.1923, 0.2395, 0.2547, 0.1533,
        0.2311, 0.2663, 0.2321, 0.2333, 0.2637, 0.2131, 0.2269, 0.2149, 0.2033,
        0.2219, 0.1921, 0.2211, 0.2294, 0.1999, 0.2722, 0.2616, 0.2031, 0.2975,
        0.2451, 0.2619, 0.2387, 0.2200, 0.2314, 0.2436, 0.2409, 0.1957, 0.2076,
        0.2174, 0.2102, 0.2163, 0.2539, 0.2102, 0.2411, 0.2025, 0.2149, 0.1860,
        0.2531, 0.2204, 0.2170, 0.1969, 0.2223, 0.2248, 0.2436, 0.2208, 0.2577,
        0.2129, 0.2330, 0.2277, 0.2502, 0.2047, 0.2389, 0.2474, 0.2569, 0.2327,
        0.2326, 0.2656, 0.2709, 0.1927, 0.2388, 0.2033, 0.1739, 0.2090, 0.2197,
        0.2427, 0.2184, 0.2073, 0.2574, 0.2178, 0.2235, 0.2360, 0.2388, 0.2029,
        0.2361, 0.2038, 0.2209, 0.2524, 0.2224, 0.2410, 0.2012, 0.2275, 0.2565,
        0.1990, 0.3234, 0.2119, 0.2302, 0.1980, 0.2653, 0.2081, 0.2774, 0.2296,
        0.1100, 0.2744, 0.2502, 0.2229, 0.2029, 0.2234, 0.2488, 0.2060, 0.2460,
        0.2008, 0.1916, 0.2599, 0.1943, 0.2432, 0.2216, 0.2263, 0.1895, 0.2293,
        0.2214, 0.2503, 0.2650, 0.1982, 0.2211, 0.2435, 0.2045, 0.2322, 0.2784,
        0.1988, 0.2233, 0.2441, 0.2051, 0.2027, 0.1932, 0.1967, 0.2134, 0.2311,
        0.2336, 0.1912, 0.2569, 0.1996, 0.2460, 0.2199, 0.2188, 0.2026, 0.2318,
        0.2262])
true tensor([ 0.0400,  0.1600,  0.1900,  0.1400,  0.3200,  0.1700,  0.2000,  0.2400,
         0.3200,  0.1700,  0.2000,  0.2400, -0.4000,  0.3200,  0.1700,  0.2000,
         0.0100, -0.4000,  0.3200,  0.1700,  0.2400,  0.1500,  0.1500,  0.0400,
         0.1900,  0.1400,  0.1200,  0.2000,  0.1600,  0.1900,  0.1400,  0.1200,
         0.0700,  0.0100, -0.4000,  0.3200,  0.2000,  0.2400,  0.2400,  0.1500,
         0.2400,  0.2400,  0.1500,  0.1500,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1700,  0.2000,  0.2400,  0.2400,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1500,  0.0400,  0.1600,  0.1900, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1900,  0.1400,  0.1200,  0.2000,  0.1500,  0.1500,  0.0400,  0.1600,
         0.2400,  0.2400,  0.1500,  0.1500,  0.1400,  0.1200,  0.2000,  0.2900,
         0.2000,  0.2400,  0.2400,  0.1500,  0.1900,  0.1400,  0.1200,  0.2000,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1700,  0.2000,  0.2400,  0.2400,
         0.1600,  0.1900,  0.1400,  0.1200,  0.0700,  0.0100, -0.4000,  0.3200,
         0.2400,  0.1500,  0.1500,  0.0400,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1700,  0.2000,  0.2400,  0.2400,  0.0100, -0.4000,  0.3200,  0.1700,
         0.1400,  0.1200,  0.2000,  0.2900,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1500,  0.1500,  0.0400,  0.1600,  0.1600,  0.1900,  0.1400,  0.1200,
         0.2400,  0.1500,  0.1500,  0.0400,  0.1500,  0.0400,  0.1600,  0.1900,
         0.1200,  0.2000,  0.2900,  0.3200,  0.1200,  0.2000,  0.2900,  0.3200,
         0.1500,  0.1500,  0.0400,  0.1600, -0.4000,  0.3200,  0.1700,  0.2000,
         0.3200,  0.1700,  0.2000,  0.2400,  0.0100, -0.4000,  0.3200,  0.1700,
         0.2000,  0.2400,  0.2400,  0.1500])
Epoch: 1, Steps: 1 | Train Loss: 0.0693931 Vali Loss: 0.0264642
lr = 0.0000975531
1it [00:00, 11.49it/s]
1it [00:00,  6.14it/s]
1it [00:00, 11.42it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5111494064331055
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2684, 0.2098, 0.2398, 0.2457, 0.2276, 0.2140, 0.2063, 0.2056, 0.2364,
        0.1868, 0.2520, 0.2392, 0.2079, 0.1728, 0.1713, 0.2347, 0.2309, 0.2122,
        0.2258, 0.2154, 0.2278, 0.2151, 0.2461, 0.2326, 0.4322, 0.1726, 0.1655,
        0.3730, 0.2522, 0.2073, 0.1988, 0.2641, 0.2438, 0.2419, 0.2188, 0.1965,
        0.2208, 0.2280, 0.2273, 0.2419, 0.1958, 0.1983, 0.2052, 0.2082, 0.2334,
        0.2337, 0.2426, 0.2382, 0.1811, 0.2182, 0.2023, 0.2439, 0.2787, 0.1781,
        0.2471, 0.2258, 0.2250, 0.2153, 0.1883, 0.1916, 0.2511, 0.2473, 0.2325,
        0.2266, 0.2217, 0.2113, 0.2416, 0.1996, 0.1459, 0.2274, 0.1563, 0.2627,
        0.2187, 0.2092, 0.1790, 0.2416, 0.2447, 0.2209, 0.2290, 0.2279, 0.2493,
        0.1854, 0.2404, 0.2577, 0.2454, 0.2052, 0.2401, 0.2133, 0.2522, 0.1986,
        0.2084, 0.2311, 0.2499, 0.1906, 0.2551, 0.2006, 0.2256, 0.2184, 0.2140,
        0.2439, 0.2107, 0.2687, 0.2460, 0.1940, 0.2242, 0.2255, 0.2307, 0.2167,
        0.1863, 0.2124, 0.2308, 0.2229, 0.2463, 0.2407, 0.2111, 0.2394, 0.2090,
        0.2334, 0.2223, 0.2261, 0.2550, 0.3143, 0.1933, 0.3446, 0.1936, 0.1958,
        0.3763, 0.2694, 0.2242, 0.2316, 0.2098, 0.2484, 0.2441, 0.1647, 0.2674,
        0.1842, 0.2187, 0.2206, 0.2058, 0.2386, 0.2245, 0.2093, 0.2193, 0.2507,
        0.2236, 0.2219, 0.2051, 0.2028, 0.2271, 0.2199, 0.1869, 0.2142, 0.2231,
        0.1920, 0.2764, 0.1889, 0.2658, 0.1174, 0.3138, 0.2339, 0.2511, 0.2169,
        0.2357, 0.2474, 0.2279, 0.2600, 0.2219, 0.1907, 0.2228, 0.2576, 0.2793,
        0.2838])
true tensor([ 0.1500,  0.1500,  0.0400,  0.1600,  0.0400,  0.1600,  0.1900,  0.1400,
         0.0100, -0.4000,  0.3200,  0.1700,  0.2400,  0.1500,  0.1500,  0.0400,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1900,  0.1400,  0.1200,  0.2000,
         0.1500,  0.1500,  0.0400,  0.1600,  0.1700,  0.2000,  0.2400,  0.2400,
         0.0700,  0.0100, -0.4000,  0.3200,  0.1200,  0.2000,  0.2900,  0.3200,
         0.3200,  0.1700,  0.2000,  0.2400,  0.1700,  0.2000,  0.2400,  0.2400,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1600,  0.1900,  0.1400,  0.1200, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1400,  0.1200,  0.2000,  0.2900,  0.1200,  0.2000,  0.2900,  0.3200,
         0.0100, -0.4000,  0.3200,  0.1700,  0.1900,  0.1400,  0.1200,  0.2000,
         0.2400,  0.2400,  0.1500,  0.1500,  0.1900,  0.1400,  0.1200,  0.2000,
         0.1500,  0.0400,  0.1600,  0.1900,  0.2400,  0.1500,  0.1500,  0.0400,
         0.1400,  0.1200,  0.2000,  0.2900,  0.1600,  0.1900,  0.1400,  0.1200,
         0.2400,  0.2400,  0.1500,  0.1500,  0.1500,  0.0400,  0.1600,  0.1900,
         0.2000,  0.2400,  0.2400,  0.1500,  0.1600,  0.1900,  0.1400,  0.1200,
         0.0400,  0.1600,  0.1900,  0.1400,  0.0100, -0.4000,  0.3200,  0.1700,
         0.0400,  0.1600,  0.1900,  0.1400,  0.2000,  0.2400,  0.2400,  0.1500,
         0.3200,  0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,  0.0400,
         0.0700,  0.0100, -0.4000,  0.3200,  0.3200,  0.1700,  0.2000,  0.2400,
         0.2000,  0.2400,  0.2400,  0.1500,  0.1500,  0.1500,  0.0400,  0.1600,
         0.1700,  0.2000,  0.2400,  0.2400])
Epoch: 2, Steps: 1 | Train Loss: 0.0691274 Vali Loss: 0.0257183
lr = 0.0000904518
Validation loss decreased (0.026464 --> 0.025718).  Saving model ...
1it [00:00,  5.47it/s]
1it [00:00, 11.54it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5466656684875488
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2169, 0.2287, 0.2018, 0.2457, 0.2152, 0.2314, 0.2487, 0.2349, 0.2265,
        0.2300, 0.2229, 0.2313, 0.1680, 0.1916, 0.3171, 0.1881, 0.1957, 0.2104,
        0.1943, 0.2028, 0.2171, 0.2533, 0.2083, 0.2334, 0.2377, 0.2160, 0.2234,
        0.2101, 0.2488, 0.1532, 0.2843, 0.2043, 0.2698, 0.2361, 0.2202, 0.2564,
        0.2301, 0.2104, 0.2546, 0.2620, 0.2806, 0.2108, 0.2365, 0.2084, 0.2427,
        0.2158, 0.2256, 0.2100, 0.2198, 0.1758, 0.2577, 0.2933, 0.2387, 0.2038,
        0.2349, 0.1898, 0.2054, 0.2057, 0.2099, 0.2317, 0.2221, 0.2120, 0.2003,
        0.2557, 0.2648, 0.1799, 0.2732, 0.2246, 0.2050, 0.2159, 0.2545, 0.2193,
        0.2485, 0.1999, 0.2637, 0.1800, 0.2345, 0.2610, 0.2149, 0.2218, 0.2614,
        0.2390, 0.2365, 0.1763, 0.2375, 0.2511, 0.1867, 0.2178, 0.1704, 0.2270,
        0.2605, 0.2109, 0.2218, 0.1594, 0.3016, 0.2209, 0.2388, 0.2154, 0.2147,
        0.2223, 0.2680, 0.1796, 0.1992, 0.2083, 0.2519, 0.2121, 0.2146, 0.2503,
        0.2470, 0.1867, 0.2142, 0.2162, 0.2180, 0.2671, 0.2461, 0.2024, 0.2102,
        0.2065, 0.2512, 0.2275, 0.2257, 0.2484, 0.1730, 0.2381, 0.2422, 0.2246,
        0.2441, 0.1989, 0.2615, 0.2266, 0.2274, 0.2437, 0.2337, 0.1650, 0.2539,
        0.2494, 0.2369, 0.2130, 0.2085, 0.2280, 0.1934, 0.2566, 0.2002, 0.2383,
        0.2006, 0.2165, 0.2686, 0.2364, 0.2149, 0.1957, 0.2116, 0.2241, 0.1956,
        0.2460, 0.1885, 0.2394, 0.2082, 0.2138, 0.2439, 0.2101, 0.2752, 0.2093,
        0.1585, 0.2147, 0.3585, 0.1424, 0.2627, 0.2256, 0.2200, 0.1892, 0.3032,
        0.1746])
true tensor([ 0.2400,  0.1500,  0.1500,  0.0400,  0.1600,  0.1900,  0.1400,  0.1200,
         0.0400,  0.1600,  0.1900,  0.1400,  0.1500,  0.0400,  0.1600,  0.1900,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.0400,  0.1600,  0.1900,  0.1400,
         0.2000,  0.2400,  0.2400,  0.1500,  0.0100, -0.4000,  0.3200,  0.1700,
         0.1500,  0.0400,  0.1600,  0.1900,  0.0100, -0.4000,  0.3200,  0.1700,
         0.1700,  0.2000,  0.2400,  0.2400,  0.2000,  0.2400,  0.2400,  0.1500,
         0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,  0.0400,  0.1600,
         0.1400,  0.1200,  0.2000,  0.2900, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1200,  0.2000,  0.2900,  0.3200,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1900,  0.1400,  0.1200,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1600,  0.1900,  0.1400,  0.1200,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1600,  0.1900,  0.1400,  0.1200,  0.3200,  0.1700,  0.2000,  0.2400,
         0.1700,  0.2000,  0.2400,  0.2400,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1900,  0.1400,  0.1200,  0.2000,  0.0400,  0.1600,  0.1900,  0.1400,
         0.2400,  0.1500,  0.1500,  0.0400,  0.1200,  0.2000,  0.2900,  0.3200,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1400,  0.1200,  0.2000,  0.2900,
         0.2000,  0.2400,  0.2400,  0.1500,  0.0100, -0.4000,  0.3200,  0.1700,
         0.3200,  0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,  0.0400,
         0.1900,  0.1400,  0.1200,  0.2000,  0.3200,  0.1700,  0.2000,  0.2400,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.0700,  0.0100, -0.4000,  0.3200,
         0.1500,  0.1500,  0.0400,  0.1600,  0.1500,  0.1500,  0.0400,  0.1600,
         0.0700,  0.0100, -0.4000,  0.3200])
Epoch: 3, Steps: 1 | Train Loss: 0.0687957 Vali Loss: 0.0256418
lr = 0.0000793913
Validation loss decreased (0.025718 --> 0.025642).  Saving model ...
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
1it [00:00,  6.16it/s]
1it [00:00, 11.11it/s]
Epoch: 4 cost time: 0.5093832015991211
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2096, 0.2198, 0.2635, 0.2321, 0.2592, 0.2534, 0.2078, 0.2393, 0.2042,
        0.2120, 0.1933, 0.2517, 0.2351, 0.2410, 0.2114, 0.2228, 0.2160, 0.2044,
        0.2629, 0.2359, 0.1949, 0.1892, 0.1983, 0.2470, 0.2385, 0.2414, 0.2323,
        0.2508, 0.2088, 0.2107, 0.2041, 0.1946, 0.1940, 0.2413, 0.2104, 0.2551,
        0.2342, 0.2073, 0.2036, 0.2259, 0.2509, 0.1802, 0.2610, 0.1933, 0.2453,
        0.2089, 0.2077, 0.2013, 0.2349, 0.2030, 0.2369, 0.2346, 0.2244, 0.2368,
        0.2184, 0.2212, 0.2097, 0.2169, 0.2322, 0.2148, 0.2347, 0.2564, 0.2222,
        0.2184, 0.2406, 0.2176, 0.2198, 0.2095, 0.2175, 0.1808, 0.2695, 0.1731,
        0.2592, 0.2114, 0.2385, 0.2243, 0.1648, 0.2773, 0.1962, 0.2433, 0.2683,
        0.2579, 0.2306, 0.1980, 0.2058, 0.2505, 0.1920, 0.2642, 0.2152, 0.2323,
        0.2355, 0.1979, 0.1988, 0.2451, 0.2064, 0.2704, 0.2493, 0.2217, 0.2318,
        0.2031, 0.2085, 0.1782, 0.2069, 0.2262, 0.2565, 0.1918, 0.2664, 0.2383,
        0.1912, 0.2321, 0.2527, 0.2198, 0.1951, 0.2614, 0.2348, 0.1985, 0.2278,
        0.2352, 0.2262, 0.2387, 0.2250, 0.2128, 0.2644, 0.2101, 0.2119, 0.1713,
        0.2550, 0.2176, 0.2084, 0.2527, 0.1524, 0.1822, 0.2459, 0.2516, 0.2052,
        0.2320, 0.2554, 0.2012, 0.2246, 0.2104, 0.2064, 0.2097, 0.2201, 0.2622,
        0.2608, 0.2089, 0.2339, 0.2372, 0.2090, 0.2174, 0.2252, 0.2322, 0.1998,
        0.2524, 0.2450, 0.3140, 0.2128, 0.2161, 0.2430, 0.2344, 0.1890, 0.2386,
        0.2666, 0.2599, 0.2279, 0.1977, 0.2518, 0.2924, 0.2617, 0.2235, 0.2410,
        0.2416])
true tensor([ 0.1200,  0.2000,  0.2900,  0.3200,  0.1500,  0.0400,  0.1600,  0.1900,
         0.2400,  0.1500,  0.1500,  0.0400,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1200,  0.2000,  0.2900,  0.3200,  0.3200,  0.1700,  0.2000,  0.2400,
         0.2000,  0.2400,  0.2400,  0.1500,  0.0700,  0.0100, -0.4000,  0.3200,
         0.0400,  0.1600,  0.1900,  0.1400,  0.0400,  0.1600,  0.1900,  0.1400,
         0.0100, -0.4000,  0.3200,  0.1700,  0.1500,  0.1500,  0.0400,  0.1600,
         0.1700,  0.2000,  0.2400,  0.2400,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1600,  0.1900,  0.1400,  0.1200,  0.2400,  0.1500,  0.1500,  0.0400,
         0.2400,  0.2400,  0.1500,  0.1500,  0.0700,  0.0100, -0.4000,  0.3200,
         0.1500,  0.1500,  0.0400,  0.1600,  0.2000,  0.2400,  0.2400,  0.1500,
         0.1500,  0.1500,  0.0400,  0.1600,  0.1500,  0.0400,  0.1600,  0.1900,
         0.1400,  0.1200,  0.2000,  0.2900,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1600,  0.1900,  0.1400,  0.1200,  0.1700,  0.2000,  0.2400,  0.2400,
         0.0100, -0.4000,  0.3200,  0.1700,  0.1600,  0.1900,  0.1400,  0.1200,
         0.3200,  0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,  0.0400,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.0100, -0.4000,  0.3200,  0.1700,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.2000,  0.2400,  0.2400,  0.1500,
         0.3200,  0.1700,  0.2000,  0.2400,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1900,  0.1400,  0.1200,  0.2000, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1900,  0.1400,  0.1200,  0.2000,
         0.1400,  0.1200,  0.2000,  0.2900,  0.1700,  0.2000,  0.2400,  0.2400,
         0.1900,  0.1400,  0.1200,  0.2000])
Epoch: 4, Steps: 1 | Train Loss: 0.0690010 Vali Loss: 0.0252251
lr = 0.0000654543
Validation loss decreased (0.025642 --> 0.025225).  Saving model ...
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 5 cost time: 0.5304481983184814
1it [00:00,  5.89it/s]
1it [00:00, 11.61it/s]
1it [00:00,  6.04it/s]
1it [00:00, 11.67it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2264, 0.2547, 0.2164, 0.2228, 0.2259, 0.2110, 0.2592, 0.2268, 0.2445,
        0.2166, 0.2165, 0.1986, 0.2926, 0.1356, 0.2516, 0.1923, 0.2392, 0.2083,
        0.2515, 0.2261, 0.2551, 0.2224, 0.2213, 0.2390, 0.2466, 0.2283, 0.2407,
        0.2155, 0.2312, 0.2298, 0.2103, 0.2104, 0.2038, 0.2095, 0.1988, 0.2501,
        0.2385, 0.2036, 0.2422, 0.2407, 0.2422, 0.2160, 0.2397, 0.2380, 0.2067,
        0.1814, 0.2430, 0.2350, 0.2336, 0.2306, 0.2337, 0.2180, 0.2548, 0.1965,
        0.2058, 0.2262, 0.1987, 0.2466, 0.2249, 0.2259, 0.2494, 0.2376, 0.2265,
        0.2350, 0.2312, 0.2270, 0.2010, 0.2151, 0.2137, 0.2341, 0.2094, 0.2270,
        0.2395, 0.2012, 0.2369, 0.1935, 0.2694, 0.2196, 0.2168, 0.2176, 0.2120,
        0.2392, 0.2102, 0.2189, 0.1793, 0.2039, 0.1950, 0.2367, 0.2483, 0.1971,
        0.2166, 0.1997, 0.1977, 0.2352, 0.1809, 0.2000, 0.2409, 0.2325, 0.2183,
        0.2230, 0.1729, 0.2094, 0.2408, 0.2425, 0.2546, 0.1971, 0.2106, 0.2496,
        0.1867, 0.1999, 0.2120, 0.1961, 0.2207, 0.2355, 0.2296, 0.1990, 0.2187,
        0.2293, 0.2160, 0.2263, 0.2096, 0.2309, 0.2533, 0.2817, 0.1626, 0.2543,
        0.2380, 0.1042, 0.2187, 0.2738, 0.2206, 0.2319, 0.2539, 0.1881, 0.2772,
        0.1834, 0.2177, 0.1653, 0.2476, 0.2082, 0.2003, 0.2141, 0.2152, 0.2176,
        0.1619, 0.1673, 0.2349, 0.2038, 0.2254, 0.2298, 0.2407, 0.2151, 0.2044,
        0.2230, 0.1814, 0.2031, 0.2257, 0.2065, 0.2155, 0.2116, 0.2535, 0.2242,
        0.2385, 0.2223, 0.1984, 0.2136, 0.1906, 0.2539, 0.2132, 0.1945, 0.2859,
        0.1536])
true tensor([ 0.2400,  0.1500,  0.1500,  0.0400,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1700,  0.2000,  0.2400,  0.2400,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1200,  0.2000,  0.2900,  0.3200, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1900,  0.1400,  0.1200,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1400,  0.1200,  0.2000,  0.2900,  0.0100, -0.4000,  0.3200,  0.1700,
         0.0400,  0.1600,  0.1900,  0.1400,  0.0100, -0.4000,  0.3200,  0.1700,
         0.3200,  0.1700,  0.2000,  0.2400,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1600,  0.1900,  0.1400,  0.1200,  0.2000,  0.2400,  0.2400,  0.1500,
         0.2000,  0.2400,  0.2400,  0.1500,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1500,  0.1500,  0.0400,  0.1600,  0.2000,  0.2400,  0.2400,  0.1500,
         0.2400,  0.2400,  0.1500,  0.1500,  0.3200,  0.1700,  0.2000,  0.2400,
         0.3200,  0.1700,  0.2000,  0.2400,  0.1600,  0.1900,  0.1400,  0.1200,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1600,  0.1900,  0.1400,  0.1200,
         0.1500,  0.1500,  0.0400,  0.1600,  0.0700,  0.0100, -0.4000,  0.3200,
         0.1400,  0.1200,  0.2000,  0.2900,  0.2400,  0.1500,  0.1500,  0.0400,
         0.1700,  0.2000,  0.2400,  0.2400,  0.1200,  0.2000,  0.2900,  0.3200,
         0.1500,  0.0400,  0.1600,  0.1900,  0.0100, -0.4000,  0.3200,  0.1700,
         0.1900,  0.1400,  0.1200,  0.2000, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1700,  0.2000,  0.2400,  0.2400,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.1500,  0.1500,  0.0400,  0.1600,
         0.1900,  0.1400,  0.1200,  0.2000,  0.2400,  0.1500,  0.1500,  0.0400,
         0.0700,  0.0100, -0.4000,  0.3200])
Epoch: 5, Steps: 1 | Train Loss: 0.0677720 Vali Loss: 0.0255318
lr = 0.0000500050
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 6 cost time: 0.5216522216796875
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2828, 0.2180, 0.2294, 0.2432, 0.2302, 0.1991, 0.2329, 0.1953, 0.2300,
        0.1913, 0.2324, 0.2242, 0.2004, 0.2363, 0.2011, 0.2176, 0.2144, 0.2445,
        0.2174, 0.1980, 0.2435, 0.2433, 0.1901, 0.2381, 0.2181, 0.2349, 0.2197,
        0.2272, 0.2314, 0.2086, 0.2512, 0.2819, 0.2334, 0.2748, 0.1998, 0.2506,
        0.2282, 0.2287, 0.1937, 0.2427, 0.1709, 0.2131, 0.2056, 0.2076, 0.2495,
        0.2343, 0.2418, 0.2252, 0.2544, 0.2244, 0.2357, 0.2125, 0.2414, 0.2293,
        0.2214, 0.2376, 0.2517, 0.2297, 0.2251, 0.2349, 0.1738, 0.2055, 0.1973,
        0.2430, 0.2203, 0.2165, 0.2158, 0.2071, 0.2603, 0.2653, 0.2389, 0.2588,
        0.2484, 0.1931, 0.2624, 0.2408, 0.1774, 0.2198, 0.1839, 0.1936, 0.2287,
        0.2349, 0.2265, 0.2398, 0.2291, 0.2049, 0.2642, 0.2188, 0.2122, 0.2200,
        0.2487, 0.2418, 0.2400, 0.1286, 0.2331, 0.1274, 0.2172, 0.2130, 0.2652,
        0.1906, 0.2284, 0.2116, 0.1832, 0.2121, 0.2276, 0.1943, 0.2409, 0.2034,
        0.1913, 0.2246, 0.2182, 0.2194, 0.2148, 0.1976, 0.2783, 0.1665, 0.2550,
        0.2036, 0.2279, 0.2376, 0.2158, 0.2314, 0.2021, 0.2094, 0.1871, 0.1993,
        0.1925, 0.2325, 0.2426, 0.2292, 0.2136, 0.2245, 0.2353, 0.1995, 0.2227,
        0.2133, 0.2332, 0.2530, 0.2110, 0.2016, 0.2043, 0.2005, 0.2185, 0.2175,
        0.2010, 0.1811, 0.2339, 0.2435, 0.2742, 0.2116, 0.2732, 0.2402, 0.2494,
        0.2053, 0.2686, 0.2067, 0.2465, 0.2128, 0.2207, 0.2059, 0.1103, 0.2891,
        0.2369, 0.1949, 0.1936, 0.1640, 0.3649, 0.2549, 0.1792, 0.2265, 0.2339,
        0.2412])
true tensor([ 0.1500,  0.1500,  0.0400,  0.1600,  0.1600,  0.1900,  0.1400,  0.1200,
         0.0400,  0.1600,  0.1900,  0.1400, -0.4000,  0.3200,  0.1700,  0.2000,
         0.2400,  0.1500,  0.1500,  0.0400,  0.2400,  0.1500,  0.1500,  0.0400,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1700,  0.2000,  0.2400,  0.2400,
         0.0400,  0.1600,  0.1900,  0.1400,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1600,  0.1900,  0.1400,  0.1200,  0.1500,  0.1500,  0.0400,  0.1600,
         0.1700,  0.2000,  0.2400,  0.2400,  0.2000,  0.2400,  0.2400,  0.1500,
         0.3200,  0.1700,  0.2000,  0.2400,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1200,  0.2000,  0.2900,  0.3200,  0.2000,  0.2400,  0.2400,  0.1500,
         0.0100, -0.4000,  0.3200,  0.1700,  0.0700,  0.0100, -0.4000,  0.3200,
         0.1500,  0.0400,  0.1600,  0.1900,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1400,  0.1200,  0.2000,  0.2900,  0.1500,  0.1500,  0.0400,  0.1600,
         0.0100, -0.4000,  0.3200,  0.1700,  0.2400,  0.2400,  0.1500,  0.1500,
         0.3200,  0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,  0.0400,
         0.0700,  0.0100, -0.4000,  0.3200,  0.1900,  0.1400,  0.1200,  0.2000,
         0.1700,  0.2000,  0.2400,  0.2400,  0.3200,  0.1700,  0.2000,  0.2400,
         0.2000,  0.2400,  0.2400,  0.1500, -0.4000,  0.3200,  0.1700,  0.2000,
         0.2400,  0.2400,  0.1500,  0.1500, -0.4000,  0.3200,  0.1700,  0.2000,
         0.0100, -0.4000,  0.3200,  0.1700,  0.1900,  0.1400,  0.1200,  0.2000,
         0.1900,  0.1400,  0.1200,  0.2000,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1200,  0.2000,  0.2900,  0.3200,  0.1500,  0.0400,  0.1600,  0.1900,
         0.1600,  0.1900,  0.1400,  0.1200])
Epoch: 6, Steps: 1 | Train Loss: 0.0685128 Vali Loss: 0.0252911
lr = 0.0000345557
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 7 cost time: 0.5066127777099609
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2302, 0.2369, 0.2414, 0.2937, 0.2014, 0.2356, 0.2366, 0.2061, 0.2353,
        0.2039, 0.2487, 0.2061, 0.2318, 0.2579, 0.2022, 0.2352, 0.1746, 0.1676,
        0.1658, 0.2039, 0.1494, 0.1732, 0.2766, 0.2501, 0.2411, 0.2097, 0.2646,
        0.2262, 0.2386, 0.2316, 0.2203, 0.1929, 0.2663, 0.2085, 0.2644, 0.2438,
        0.2082, 0.2380, 0.1922, 0.2378, 0.2494, 0.2019, 0.2413, 0.2113, 0.2527,
        0.2472, 0.2614, 0.2353, 0.1948, 0.2265, 0.2037, 0.2232, 0.2374, 0.2313,
        0.1956, 0.2192, 0.2094, 0.2110, 0.2568, 0.1778, 0.2304, 0.2158, 0.2610,
        0.2199, 0.2343, 0.1947, 0.2206, 0.2020, 0.2747, 0.2251, 0.2378, 0.2094,
        0.2236, 0.2289, 0.2601, 0.2030, 0.2450, 0.2136, 0.2001, 0.2039, 0.1959,
        0.2047, 0.1890, 0.2564, 0.2380, 0.2639, 0.2165, 0.2603, 0.2528, 0.2126,
        0.2512, 0.2342, 0.2170, 0.1832, 0.1871, 0.2325, 0.2169, 0.2317, 0.2508,
        0.2364, 0.2313, 0.2015, 0.2234, 0.2257, 0.1636, 0.2097, 0.1839, 0.2180,
        0.2040, 0.2364, 0.1865, 0.1991, 0.2136, 0.2169, 0.2369, 0.2055, 0.2493,
        0.1748, 0.2215, 0.2210, 0.2424, 0.2632, 0.2056, 0.2382, 0.2396, 0.2069,
        0.2434, 0.2072, 0.2338, 0.2252, 0.2757, 0.2875, 0.2432, 0.2021, 0.2240,
        0.2349, 0.2990, 0.1960, 0.2162, 0.1619, 0.1311, 0.2152, 0.1774, 0.2541,
        0.2299, 0.1653, 0.2502, 0.2446, 0.2494, 0.2319, 0.2492, 0.2019, 0.2489,
        0.2318, 0.2304, 0.2174, 0.1938, 0.1778, 0.2292, 0.2050, 0.2111, 0.2111,
        0.2869, 0.2350, 0.2180, 0.2335, 0.2404, 0.2267, 0.2137, 0.2314, 0.1998,
        0.2027])
true tensor([ 0.2000,  0.2400,  0.2400,  0.1500,  0.2000,  0.2400,  0.2400,  0.1500,
         0.1900,  0.1400,  0.1200,  0.2000,  0.2000,  0.2400,  0.2400,  0.1500,
         0.0400,  0.1600,  0.1900,  0.1400,  0.1500,  0.0400,  0.1600,  0.1900,
         0.0100, -0.4000,  0.3200,  0.1700,  0.1500,  0.1500,  0.0400,  0.1600,
         0.1900,  0.1400,  0.1200,  0.2000,  0.2400,  0.1500,  0.1500,  0.0400,
         0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.0400,  0.1600,  0.1900,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.3200,  0.1700,  0.2000,  0.2400,
         0.0100, -0.4000,  0.3200,  0.1700,  0.1400,  0.1200,  0.2000,  0.2900,
        -0.4000,  0.3200,  0.1700,  0.2000,  0.1600,  0.1900,  0.1400,  0.1200,
         0.1600,  0.1900,  0.1400,  0.1200,  0.2400,  0.2400,  0.1500,  0.1500,
         0.1400,  0.1200,  0.2000,  0.2900,  0.0400,  0.1600,  0.1900,  0.1400,
         0.1200,  0.2000,  0.2900,  0.3200,  0.3200,  0.1700,  0.2000,  0.2400,
         0.1700,  0.2000,  0.2400,  0.2400,  0.1500,  0.0400,  0.1600,  0.1900,
         0.1600,  0.1900,  0.1400,  0.1200, -0.4000,  0.3200,  0.1700,  0.2000,
         0.1700,  0.2000,  0.2400,  0.2400,  0.0400,  0.1600,  0.1900,  0.1400,
         0.2400,  0.2400,  0.1500,  0.1500,  0.1400,  0.1200,  0.2000,  0.2900,
         0.1500,  0.1500,  0.0400,  0.1600,  0.1900,  0.1400,  0.1200,  0.2000,
         0.2400,  0.2400,  0.1500,  0.1500,  0.2400,  0.1500,  0.1500,  0.0400,
         0.0100, -0.4000,  0.3200,  0.1700,  0.3200,  0.1700,  0.2000,  0.2400,
         0.1500,  0.1500,  0.0400,  0.1600,  0.0700,  0.0100, -0.4000,  0.3200,
         0.0700,  0.0100, -0.4000,  0.3200,  0.1200,  0.2000,  0.2900,  0.3200,
         0.2400,  0.1500,  0.1500,  0.0400])
Epoch: 7, Steps: 1 | Train Loss: 0.0681063 Vali Loss: 0.0253487
lr = 0.0000206187
EarlyStopping counter: 3 out of 3
Early stopping
1it [00:00,  6.11it/s]
1it [00:00, 10.36it/s]
1it [00:00, 10.03it/s]
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 371) (1, 371)
test shape: (1, 1, 371) (1, 1, 371)
mae:0.5630, mse:0.7543, rmse:0.8685, r2:-0.5994
mse_mean = 0.7543, mse_std = 0.0000
r2_mean = -0.5994, mae_std = 0.0000