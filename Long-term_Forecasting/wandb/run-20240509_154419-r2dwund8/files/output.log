['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.09s/it]
0it [00:00, ?it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3810088634490967
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([ 0.1848,  0.2134,  0.1841,  0.1867,  0.2080,  0.1155,  0.2749,  0.2684,
         0.1281,  0.1894,  0.2192,  0.2584,  0.1537,  0.2092,  0.2838,  0.2771,
         0.1890,  0.2073,  0.2819,  0.2373,  0.2086,  0.2778,  0.2259,  0.1517,
         0.1774,  0.2272,  0.2578,  0.1290,  0.1844,  0.1830,  0.2535,  0.1408,
         0.2135, -0.1942,  0.3279,  0.1074,  0.2160,  0.2150,  0.2574,  0.3072,
         0.1806,  0.2683,  0.2610,  0.2219,  0.2475,  0.2443,  0.2456,  0.2508,
         0.2395,  0.1424,  0.2268,  0.1754,  0.2537,  0.2232,  0.2174,  0.1884,
         0.2106,  0.1284,  0.2059,  0.2172,  0.2223,  0.2403,  0.2576,  0.2241,
         0.2432,  0.1390,  0.2500,  0.2389,  0.1952,  0.1183,  0.2268,  0.1679,
         0.1454,  0.2099,  0.2691,  0.2839,  0.2682,  0.1501,  0.2641,  0.1987,
         0.2693,  0.0732,  0.1767,  0.1761,  0.1256,  0.1588,  0.2551,  0.2727,
         0.3085,  0.1683,  0.3162,  0.2342,  0.1465,  0.1521,  0.2643,  0.2387,
         0.1866,  0.1982,  0.3043,  0.1475,  0.2089,  0.2574,  0.2766,  0.1033,
         0.1387,  0.2464,  0.1843,  0.2441,  0.2084,  0.2309,  0.2578,  0.2589,
         0.2351,  0.1950,  0.2003,  0.2011,  0.1872,  0.2718,  0.2152,  0.1945,
         0.2304,  0.2135,  0.2243,  0.2955,  0.2028,  0.1835,  0.2044,  0.2629,
         0.1674,  0.2138,  0.2689,  0.2897,  0.1351,  0.1097,  0.1764,  0.2999,
         0.2313,  0.1749,  0.2037,  0.1471,  0.2430,  0.1879,  0.3011,  0.3022,
         0.1761,  0.1576,  0.1669,  0.1813,  0.1952,  0.2094,  0.1800,  0.2848,
         0.2179,  0.2369,  0.2316,  0.2391,  0.2118,  0.1436,  0.1922,  0.1657,
         0.2282,  0.2467,  0.2153,  0.2226,  0.2254,  0.1426,  0.2700,  0.2043,
         0.2056,  0.2310,  0.1879,  0.2363])
true tensor([0.4000, 0.4600, 0.4800, 0.4900, 0.2500, 0.3100, 0.3000, 0.3400, 0.1800,
        0.2500, 0.3100, 0.3000, 0.1700, 0.1800, 0.2500, 0.3100, 0.1400, 0.1700,
        0.1800, 0.2500, 0.3800, 0.4100, 0.4200, 0.4000, 0.4800, 0.4900, 0.4500,
        0.5500, 0.4600, 0.4800, 0.4900, 0.4500, 0.1400, 0.1700, 0.1800, 0.2500,
        0.3000, 0.3400, 0.3800, 0.4100, 0.3400, 0.3800, 0.4100, 0.4200, 0.4800,
        0.4900, 0.4500, 0.5500, 0.3100, 0.3000, 0.3400, 0.3800, 0.4000, 0.4600,
        0.4800, 0.4900, 0.4200, 0.4000, 0.4600, 0.4800, 0.1800, 0.2500, 0.3100,
        0.3000, 0.4800, 0.4900, 0.4500, 0.5500, 0.4100, 0.4200, 0.4000, 0.4600,
        0.3000, 0.3400, 0.3800, 0.4100, 0.4900, 0.4500, 0.5500, 0.6300, 0.3000,
        0.3400, 0.3800, 0.4100, 0.4600, 0.4800, 0.4900, 0.4500, 0.4200, 0.4000,
        0.4600, 0.4800, 0.2500, 0.3100, 0.3000, 0.3400, 0.4600, 0.4800, 0.4900,
        0.4500, 0.1400, 0.1700, 0.1800, 0.2500, 0.3400, 0.3800, 0.4100, 0.4200,
        0.4200, 0.4000, 0.4600, 0.4800, 0.3100, 0.3000, 0.3400, 0.3800, 0.1700,
        0.1800, 0.2500, 0.3100, 0.4900, 0.4500, 0.5500, 0.6300, 0.3400, 0.3800,
        0.4100, 0.4200, 0.3800, 0.4100, 0.4200, 0.4000, 0.4000, 0.4600, 0.4800,
        0.4900, 0.3800, 0.4100, 0.4200, 0.4000, 0.4100, 0.4200, 0.4000, 0.4600,
        0.4500, 0.5500, 0.6300, 0.6200, 0.4900, 0.4500, 0.5500, 0.6300, 0.4100,
        0.4200, 0.4000, 0.4600, 0.1800, 0.2500, 0.3100, 0.3000, 0.2500, 0.3100,
        0.3000, 0.3400, 0.1700, 0.1800, 0.2500, 0.3100, 0.3100, 0.3000, 0.3400,
        0.3800])
Epoch: 1, Steps: 1 | Train Loss: 0.0361341 Vali Loss: 0.0425946
lr = 0.0000975531
1it [00:00, 11.06it/s]
1it [00:00,  6.10it/s]
1it [00:00, 11.60it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5096652507781982
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2050, 0.1157, 0.1718, 0.1663, 0.1800, 0.1894, 0.1509, 0.2376, 0.2663,
        0.0906, 0.2805, 0.1985, 0.2778, 0.2001, 0.3456, 0.1399, 0.2086, 0.2184,
        0.2043, 0.2489, 0.1826, 0.1951, 0.1728, 0.1896, 0.2751, 0.1459, 0.3162,
        0.1836, 0.1515, 0.1613, 0.2048, 0.2776, 0.1803, 0.2589, 0.1744, 0.1131,
        0.2088, 0.1498, 0.2917, 0.1507, 0.2336, 0.1227, 0.2578, 0.0846, 0.2032,
        0.2787, 0.2142, 0.2650, 0.2325, 0.1844, 0.2685, 0.2169, 0.2076, 0.2371,
        0.2008, 0.2438, 0.1938, 0.1619, 0.1614, 0.1720, 0.1302, 0.2173, 0.2101,
        0.2939, 0.1881, 0.2951, 0.2642, 0.1578, 0.1687, 0.1688, 0.2778, 0.2058,
        0.1146, 0.1675, 0.2407, 0.2550, 0.1803, 0.1809, 0.2507, 0.0999, 0.2746,
        0.0701, 0.0520, 0.4041, 0.2486, 0.1408, 0.2969, 0.1820, 0.2074, 0.1523,
        0.2485, 0.2134, 0.2041, 0.2197, 0.1844, 0.1317, 0.1447, 0.1725, 0.2365,
        0.1898, 0.1661, 0.2190, 0.1113, 0.2569, 0.2572, 0.1898, 0.1774, 0.1320,
        0.1601, 0.1474, 0.2616, 0.2088, 0.2297, 0.1742, 0.2607, 0.2189, 0.1424,
        0.2511, 0.2896, 0.3165, 0.2435, 0.2572, 0.2548, 0.1846, 0.1834, 0.2332,
        0.1141, 0.2712, 0.2531, 0.1983, 0.2787, 0.2172, 0.1641, 0.1073, 0.2687,
        0.1731, 0.1484, 0.2037, 0.2374, 0.1316, 0.1512, 0.1978, 0.1706, 0.2937,
        0.2295, 0.1827, 0.2293, 0.1884, 0.1885, 0.2601, 0.2140, 0.1406, 0.1749,
        0.2061, 0.1404, 0.2285, 0.2633, 0.1952, 0.2272, 0.2228, 0.2006, 0.1156,
        0.2941, 0.1181, 0.1848, 0.1735, 0.2300, 0.2596, 0.2205, 0.1586, 0.2389,
        0.2421])
true tensor([0.4100, 0.4200, 0.4000, 0.4600, 0.4000, 0.4600, 0.4800, 0.4900, 0.1700,
        0.1800, 0.2500, 0.3100, 0.3800, 0.4100, 0.4200, 0.4000, 0.1800, 0.2500,
        0.3100, 0.3000, 0.4900, 0.4500, 0.5500, 0.6300, 0.4200, 0.4000, 0.4600,
        0.4800, 0.4600, 0.4800, 0.4900, 0.4500, 0.4100, 0.4200, 0.4000, 0.4600,
        0.3100, 0.3000, 0.3400, 0.3800, 0.1400, 0.1700, 0.1800, 0.2500, 0.4900,
        0.4500, 0.5500, 0.6300, 0.2500, 0.3100, 0.3000, 0.3400, 0.2500, 0.3100,
        0.3000, 0.3400, 0.1800, 0.2500, 0.3100, 0.3000, 0.3000, 0.3400, 0.3800,
        0.4100, 0.4600, 0.4800, 0.4900, 0.4500, 0.1700, 0.1800, 0.2500, 0.3100,
        0.4800, 0.4900, 0.4500, 0.5500, 0.4500, 0.5500, 0.6300, 0.6200, 0.1400,
        0.1700, 0.1800, 0.2500, 0.4800, 0.4900, 0.4500, 0.5500, 0.3400, 0.3800,
        0.4100, 0.4200, 0.4800, 0.4900, 0.4500, 0.5500, 0.4200, 0.4000, 0.4600,
        0.4800, 0.3400, 0.3800, 0.4100, 0.4200, 0.4900, 0.4500, 0.5500, 0.6300,
        0.4600, 0.4800, 0.4900, 0.4500, 0.3400, 0.3800, 0.4100, 0.4200, 0.4100,
        0.4200, 0.4000, 0.4600, 0.3000, 0.3400, 0.3800, 0.4100, 0.4000, 0.4600,
        0.4800, 0.4900, 0.4200, 0.4000, 0.4600, 0.4800, 0.1700, 0.1800, 0.2500,
        0.3100, 0.4000, 0.4600, 0.4800, 0.4900, 0.3100, 0.3000, 0.3400, 0.3800,
        0.2500, 0.3100, 0.3000, 0.3400, 0.3800, 0.4100, 0.4200, 0.4000, 0.1400,
        0.1700, 0.1800, 0.2500, 0.1800, 0.2500, 0.3100, 0.3000, 0.3000, 0.3400,
        0.3800, 0.4100, 0.3800, 0.4100, 0.4200, 0.4000, 0.3100, 0.3000, 0.3400,
        0.3800])
Epoch: 2, Steps: 1 | Train Loss: 0.0370694 Vali Loss: 0.0459070
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5028769969940186
1it [00:00,  6.49it/s]
1it [00:00, 11.56it/s]
1it [00:00,  6.32it/s]
1it [00:00, 12.59it/s]
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2191, 0.1445, 0.1610, 0.1120, 0.2477, 0.1074, 0.2714, 0.1855, 0.1382,
        0.2413, 0.2394, 0.1312, 0.1708, 0.1606, 0.1859, 0.2050, 0.2279, 0.1831,
        0.2312, 0.1982, 0.2903, 0.2307, 0.2719, 0.2160, 0.1648, 0.1339, 0.1374,
        0.3246, 0.1991, 0.0743, 0.2093, 0.2418, 0.2440, 0.0911, 0.2433, 0.1901,
        0.0675, 0.1308, 0.2362, 0.1973, 0.1866, 0.1507, 0.2808, 0.2512, 0.1723,
        0.2072, 0.1673, 0.1890, 0.2509, 0.1369, 0.3375, 0.1543, 0.1466, 0.1872,
        0.2057, 0.1384, 0.1566, 0.2352, 0.2605, 0.2028, 0.2199, 0.2063, 0.2791,
        0.0927, 0.1531, 0.2094, 0.1493, 0.2037, 0.1981, 0.1883, 0.1511, 0.1790,
        0.1426, 0.1895, 0.1587, 0.1592, 0.1759, 0.1563, 0.1951, 0.2637, 0.1674,
        0.2353, 0.1553, 0.3461, 0.2420, 0.3025, 0.2223, 0.1167, 0.2129, 0.1671,
        0.2080, 0.1176, 0.1201, 0.1546, 0.1838, 0.3609, 0.1898, 0.2166, 0.2469,
        0.1126, 0.2213, 0.1075, 0.1970, 0.1982, 0.0956, 0.2950, 0.2248, 0.2280,
        0.1681, 0.2429, 0.2319, 0.2769, 0.1861, 0.2279, 0.1826, 0.2727, 0.1441,
        0.2703, 0.2658, 0.2138, 0.1377, 0.2675, 0.2091, 0.2266, 0.2359, 0.2227,
        0.2193, 0.2292, 0.1441, 0.1361, 0.2901, 0.1989, 0.2324, 0.1351, 0.3337,
        0.1650, 0.2071, 0.1744, 0.2649, 0.1809, 0.2956, 0.1380, 0.2509, 0.1524,
        0.1589, 0.2281, 0.2719, 0.2325, 0.2317, 0.1398, 0.2729, 0.1841, 0.1622,
        0.1453, 0.2629, 0.2319, 0.1533, 0.1475, 0.1623, 0.1971, 0.1542, 0.1896,
        0.2281, 0.2235, 0.1890, 0.1342, 0.2737, 0.2725, 0.1581, 0.1860, 0.2324,
        0.1092])
true tensor([0.3800, 0.4100, 0.4200, 0.4000, 0.4600, 0.4800, 0.4900, 0.4500, 0.4000,
        0.4600, 0.4800, 0.4900, 0.4200, 0.4000, 0.4600, 0.4800, 0.1800, 0.2500,
        0.3100, 0.3000, 0.4200, 0.4000, 0.4600, 0.4800, 0.3100, 0.3000, 0.3400,
        0.3800, 0.1700, 0.1800, 0.2500, 0.3100, 0.4200, 0.4000, 0.4600, 0.4800,
        0.1400, 0.1700, 0.1800, 0.2500, 0.2500, 0.3100, 0.3000, 0.3400, 0.3000,
        0.3400, 0.3800, 0.4100, 0.3100, 0.3000, 0.3400, 0.3800, 0.4100, 0.4200,
        0.4000, 0.4600, 0.4800, 0.4900, 0.4500, 0.5500, 0.1800, 0.2500, 0.3100,
        0.3000, 0.4500, 0.5500, 0.6300, 0.6200, 0.4900, 0.4500, 0.5500, 0.6300,
        0.4800, 0.4900, 0.4500, 0.5500, 0.3000, 0.3400, 0.3800, 0.4100, 0.4000,
        0.4600, 0.4800, 0.4900, 0.3400, 0.3800, 0.4100, 0.4200, 0.4600, 0.4800,
        0.4900, 0.4500, 0.1800, 0.2500, 0.3100, 0.3000, 0.3100, 0.3000, 0.3400,
        0.3800, 0.3400, 0.3800, 0.4100, 0.4200, 0.4600, 0.4800, 0.4900, 0.4500,
        0.4000, 0.4600, 0.4800, 0.4900, 0.3400, 0.3800, 0.4100, 0.4200, 0.4900,
        0.4500, 0.5500, 0.6300, 0.4100, 0.4200, 0.4000, 0.4600, 0.4900, 0.4500,
        0.5500, 0.6300, 0.3000, 0.3400, 0.3800, 0.4100, 0.1700, 0.1800, 0.2500,
        0.3100, 0.2500, 0.3100, 0.3000, 0.3400, 0.3800, 0.4100, 0.4200, 0.4000,
        0.4800, 0.4900, 0.4500, 0.5500, 0.2500, 0.3100, 0.3000, 0.3400, 0.1700,
        0.1800, 0.2500, 0.3100, 0.1400, 0.1700, 0.1800, 0.2500, 0.3800, 0.4100,
        0.4200, 0.4000, 0.4100, 0.4200, 0.4000, 0.4600, 0.1400, 0.1700, 0.1800,
        0.2500])
Epoch: 3, Steps: 1 | Train Loss: 0.0351039 Vali Loss: 0.0463929
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.513789176940918
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.1757, 0.2264, 0.2419, 0.2524, 0.1683, 0.2286, 0.2508, 0.3018, 0.2335,
        0.1498, 0.2084, 0.1513, 0.1809, 0.2393, 0.2470, 0.2550, 0.1649, 0.2120,
        0.2144, 0.2015, 0.2438, 0.1553, 0.2326, 0.1877, 0.2164, 0.2111, 0.2360,
        0.2005, 0.1664, 0.0818, 0.4361, 0.0087, 0.1526, 0.1975, 0.2591, 0.2510,
        0.1648, 0.1266, 0.1788, 0.2157, 0.2445, 0.1787, 0.2444, 0.2265, 0.1908,
        0.1680, 0.1677, 0.2066, 0.2333, 0.1868, 0.2375, 0.1098, 0.2271, 0.1799,
        0.2259, 0.1324, 0.2324, 0.1355, 0.2889, 0.0957, 0.1499, 0.2246, 0.1979,
        0.1993, 0.2135, 0.2012, 0.1474, 0.2363, 0.1993, 0.1627, 0.1953, 0.1680,
        0.1676, 0.2467, 0.1759, 0.2061, 0.1167, 0.3394, 0.1673, 0.1473, 0.1166,
        0.2010, 0.2202, 0.2049, 0.1879, 0.1795, 0.1869, 0.2175, 0.2217, 0.2357,
        0.2202, 0.2130, 0.2089, 0.2465, 0.1989, 0.2210, 0.1777, 0.1847, 0.1008,
        0.3230, 0.1757, 0.2013, 0.1969, 0.2504, 0.1889, 0.1665, 0.2154, 0.2992,
        0.1371, 0.2510, 0.2206, 0.1192, 0.2317, 0.2338, 0.1918, 0.2160, 0.2334,
        0.2293, 0.2022, 0.1391, 0.2465, 0.2320, 0.1700, 0.1334, 0.2405, 0.1372,
        0.3083, 0.1907, 0.1929, 0.1753, 0.1655, 0.2139, 0.0815, 0.2081, 0.2813,
        0.2769, 0.2793, 0.1411, 0.2635, 0.1350, 0.1506, 0.2768, 0.2888, 0.2427,
        0.1879, 0.3261, 0.1776, 0.2750, 0.1849, 0.1612, 0.1846, 0.2863, 0.1672,
        0.2283, 0.2474, 0.1908, 0.2500, 0.1379, 0.1848, 0.1647, 0.1405, 0.1310,
        0.2488, 0.1907, 0.2592, 0.2539, 0.1619, 0.2117, 0.1867, 0.1577, 0.2333,
        0.2634])
true tensor([0.4900, 0.4500, 0.5500, 0.6300, 0.4100, 0.4200, 0.4000, 0.4600, 0.3800,
        0.4100, 0.4200, 0.4000, 0.3000, 0.3400, 0.3800, 0.4100, 0.4500, 0.5500,
        0.6300, 0.6200, 0.2500, 0.3100, 0.3000, 0.3400, 0.3000, 0.3400, 0.3800,
        0.4100, 0.1400, 0.1700, 0.1800, 0.2500, 0.4200, 0.4000, 0.4600, 0.4800,
        0.4000, 0.4600, 0.4800, 0.4900, 0.1700, 0.1800, 0.2500, 0.3100, 0.4100,
        0.4200, 0.4000, 0.4600, 0.3100, 0.3000, 0.3400, 0.3800, 0.3400, 0.3800,
        0.4100, 0.4200, 0.4600, 0.4800, 0.4900, 0.4500, 0.3400, 0.3800, 0.4100,
        0.4200, 0.3400, 0.3800, 0.4100, 0.4200, 0.1400, 0.1700, 0.1800, 0.2500,
        0.4100, 0.4200, 0.4000, 0.4600, 0.3000, 0.3400, 0.3800, 0.4100, 0.3800,
        0.4100, 0.4200, 0.4000, 0.4200, 0.4000, 0.4600, 0.4800, 0.4900, 0.4500,
        0.5500, 0.6300, 0.4000, 0.4600, 0.4800, 0.4900, 0.4000, 0.4600, 0.4800,
        0.4900, 0.2500, 0.3100, 0.3000, 0.3400, 0.1400, 0.1700, 0.1800, 0.2500,
        0.4600, 0.4800, 0.4900, 0.4500, 0.1800, 0.2500, 0.3100, 0.3000, 0.3800,
        0.4100, 0.4200, 0.4000, 0.1800, 0.2500, 0.3100, 0.3000, 0.1700, 0.1800,
        0.2500, 0.3100, 0.1800, 0.2500, 0.3100, 0.3000, 0.3100, 0.3000, 0.3400,
        0.3800, 0.2500, 0.3100, 0.3000, 0.3400, 0.4800, 0.4900, 0.4500, 0.5500,
        0.4800, 0.4900, 0.4500, 0.5500, 0.1700, 0.1800, 0.2500, 0.3100, 0.4200,
        0.4000, 0.4600, 0.4800, 0.4800, 0.4900, 0.4500, 0.5500, 0.4900, 0.4500,
        0.5500, 0.6300, 0.3100, 0.3000, 0.3400, 0.3800, 0.4600, 0.4800, 0.4900,
        0.4500])
Epoch: 4, Steps: 1 | Train Loss: 0.0331472 Vali Loss: 0.0457704
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 372) (1, 372)
test shape: (1, 1, 372) (1, 1, 372)
mae:0.7301, mse:0.6433, rmse:0.8020, r2:-4.9948
mse_mean = 0.6433, mse_std = 0.0000
r2_mean = -4.9948, mae_std = 0.0000
1it [00:00,  9.76it/s]