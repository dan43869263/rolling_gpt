['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
train 337
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
val 43
['date', 'atq', 'ni', 'dv', 'acc', 'invest', 'mc', 'bm', 'dinvt', 'dar', 'capx', 'gm', 'sga', 'prc', 'ret', 'vol', 'shrout', 'medest', 'meanest', 'value']
test 93
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)
1it [00:01,  1.12s/it]
1it [00:00, 11.51it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 1 cost time: 1.3990507125854492
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2230, 0.2457, 0.2327, 0.1954, 0.2114, 0.2202, 0.2286, 0.2381, 0.1690,
        0.2152, 0.1858, 0.1997, 0.2197, 0.2207, 0.2272, 0.2115, 0.2117, 0.2190,
        0.2378, 0.2184, 0.2372, 0.2557, 0.2200, 0.2135, 0.2424, 0.1769, 0.2191,
        0.2623, 0.2422, 0.1761, 0.2012, 0.2343, 0.1835, 0.2561, 0.2101, 0.1892,
        0.2512, 0.2186, 0.2325, 0.2241, 0.1974, 0.2557, 0.2484, 0.2318, 0.2778,
        0.2289, 0.2519, 0.2860, 0.2133, 0.2156, 0.2387, 0.2219, 0.2215, 0.2109,
        0.2351, 0.1774, 0.2074, 0.2340, 0.2216, 0.2215, 0.1956, 0.2552, 0.2644,
        0.2018, 0.2595, 0.1763, 0.2204, 0.2327, 0.2061, 0.2066, 0.1953, 0.2466,
        0.2358, 0.2134, 0.2335, 0.2042, 0.2355, 0.1850, 0.2601, 0.2190, 0.2230,
        0.2236, 0.2193, 0.2237, 0.2211, 0.2029, 0.2679, 0.2706, 0.2342, 0.2208,
        0.2301, 0.2240, 0.2934, 0.1756, 0.2742, 0.2726, 0.2125, 0.2166, 0.2267,
        0.2053, 0.2279, 0.2150, 0.2374, 0.2210, 0.2172, 0.2199, 0.1855, 0.2309,
        0.1886, 0.2372, 0.2012, 0.2070, 0.2459, 0.1944, 0.1899, 0.2197, 0.2467,
        0.2423, 0.2638, 0.2830, 0.2055, 0.2392, 0.2104, 0.2309, 0.2032, 0.2219,
        0.2443, 0.1881, 0.2169, 0.1812, 0.2428, 0.2427, 0.1962, 0.1518, 0.2101,
        0.2448, 0.2219, 0.1945, 0.2362, 0.1959, 0.2658, 0.2183, 0.2602, 0.2342,
        0.2841, 0.1700, 0.2864, 0.2012, 0.2034, 0.2304, 0.1966, 0.2143, 0.2180,
        0.2232, 0.2324, 0.2398, 0.2276, 0.2075, 0.2247, 0.2407, 0.2691, 0.2175,
        0.2441, 0.2044, 0.2635, 0.1776, 0.3037, 0.2187, 0.2648, 0.2131, 0.2232,
        0.2492])
true tensor([-0.3500,  0.0200, -0.3000, -0.5800,  0.1900,  0.2300,  0.0300,  0.2900,
         0.1200,  0.1900,  0.2300,  0.0300, -0.0700,  0.1200,  0.1900,  0.2300,
         0.0000, -0.0700,  0.1200,  0.1900,  0.1100,  0.1000, -0.2400, -0.3500,
        -0.3000, -0.5800, -0.6700, -0.9800,  0.0200, -0.3000, -0.5800, -0.6700,
         0.0000, -0.0700,  0.1200,  0.1900,  0.0300,  0.2900,  0.1100,  0.1000,
         0.2900,  0.1100,  0.1000, -0.2400, -0.3000, -0.5800, -0.6700, -0.9800,
         0.2300,  0.0300,  0.2900,  0.1100, -0.3500,  0.0200, -0.3000, -0.5800,
        -0.2400, -0.3500,  0.0200, -0.3000,  0.1200,  0.1900,  0.2300,  0.0300,
        -0.3000, -0.5800, -0.6700, -0.9800,  0.1000, -0.2400, -0.3500,  0.0200,
         0.0300,  0.2900,  0.1100,  0.1000, -0.5800, -0.6700, -0.9800, -0.5500,
         0.0300,  0.2900,  0.1100,  0.1000,  0.0200, -0.3000, -0.5800, -0.6700,
        -0.2400, -0.3500,  0.0200, -0.3000,  0.1900,  0.2300,  0.0300,  0.2900,
         0.0200, -0.3000, -0.5800, -0.6700,  0.0000, -0.0700,  0.1200,  0.1900,
         0.2900,  0.1100,  0.1000, -0.2400, -0.2400, -0.3500,  0.0200, -0.3000,
         0.2300,  0.0300,  0.2900,  0.1100, -0.0700,  0.1200,  0.1900,  0.2300,
        -0.5800, -0.6700, -0.9800, -0.5500,  0.2900,  0.1100,  0.1000, -0.2400,
         0.1100,  0.1000, -0.2400, -0.3500, -0.3500,  0.0200, -0.3000, -0.5800,
         0.1100,  0.1000, -0.2400, -0.3500,  0.1000, -0.2400, -0.3500,  0.0200,
        -0.6700, -0.9800, -0.5500, -1.6400, -0.5800, -0.6700, -0.9800, -0.5500,
         0.1000, -0.2400, -0.3500,  0.0200,  0.1200,  0.1900,  0.2300,  0.0300,
         0.1900,  0.2300,  0.0300,  0.2900, -0.0700,  0.1200,  0.1900,  0.2300,
         0.2300,  0.0300,  0.2900,  0.1100])
Epoch: 1, Steps: 1 | Train Loss: 0.1290917 Vali Loss: 0.2551183
lr = 0.0000975531
Validation loss decreased (inf --> 0.255118).  Saving model ...
1it [00:00,  6.07it/s]
1it [00:00, 11.43it/s]
1it [00:00,  6.21it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 2 cost time: 0.5347251892089844
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2397, 0.1985, 0.2537, 0.2363, 0.2234, 0.1934, 0.2302, 0.1993, 0.2529,
        0.1637, 0.2648, 0.1917, 0.2147, 0.2155, 0.2808, 0.1724, 0.2094, 0.2457,
        0.2292, 0.2009, 0.2166, 0.2250, 0.1838, 0.2322, 0.2038, 0.2734, 0.1983,
        0.2205, 0.2471, 0.1877, 0.2380, 0.2658, 0.2101, 0.2230, 0.1903, 0.2419,
        0.2444, 0.1974, 0.2388, 0.2180, 0.2166, 0.2132, 0.2655, 0.2105, 0.2141,
        0.2313, 0.2209, 0.2174, 0.2182, 0.2078, 0.2491, 0.2090, 0.2374, 0.1838,
        0.2531, 0.2540, 0.2062, 0.2284, 0.2287, 0.2331, 0.2497, 0.2244, 0.2272,
        0.2056, 0.2563, 0.2230, 0.2028, 0.2216, 0.2271, 0.2067, 0.2325, 0.2163,
        0.2577, 0.2361, 0.2759, 0.2774, 0.2472, 0.2281, 0.2117, 0.2286, 0.1892,
        0.2291, 0.2186, 0.2084, 0.2606, 0.1898, 0.2341, 0.2105, 0.2122, 0.2222,
        0.1948, 0.2055, 0.2649, 0.2233, 0.1946, 0.2369, 0.1878, 0.2213, 0.2258,
        0.2357, 0.1837, 0.2201, 0.1866, 0.2241, 0.2441, 0.2089, 0.2092, 0.2304,
        0.2067, 0.1917, 0.2619, 0.2162, 0.2167, 0.2358, 0.2097, 0.2063, 0.2246,
        0.2699, 0.2439, 0.2167, 0.2508, 0.2179, 0.2171, 0.2303, 0.1922, 0.2204,
        0.2229, 0.2246, 0.2228, 0.2432, 0.2235, 0.2014, 0.2138, 0.2218, 0.2263,
        0.2362, 0.1994, 0.2541, 0.2167, 0.2056, 0.2514, 0.2343, 0.2485, 0.2540,
        0.2650, 0.2247, 0.2529, 0.2070, 0.2211, 0.2369, 0.2272, 0.2251, 0.2434,
        0.2040, 0.2097, 0.2409, 0.1962, 0.1799, 0.2042, 0.2143, 0.2112, 0.2273,
        0.2233, 0.2330, 0.2379, 0.2232, 0.2622, 0.2597, 0.2175, 0.2136, 0.2215,
        0.2258])
true tensor([ 0.1000, -0.2400, -0.3500,  0.0200, -0.3500,  0.0200, -0.3000, -0.5800,
        -0.0700,  0.1200,  0.1900,  0.2300,  0.1100,  0.1000, -0.2400, -0.3500,
         0.1200,  0.1900,  0.2300,  0.0300, -0.5800, -0.6700, -0.9800, -0.5500,
        -0.2400, -0.3500,  0.0200, -0.3000,  0.0200, -0.3000, -0.5800, -0.6700,
         0.1000, -0.2400, -0.3500,  0.0200,  0.2300,  0.0300,  0.2900,  0.1100,
         0.0000, -0.0700,  0.1200,  0.1900, -0.5800, -0.6700, -0.9800, -0.5500,
         0.1900,  0.2300,  0.0300,  0.2900,  0.1900,  0.2300,  0.0300,  0.2900,
         0.1200,  0.1900,  0.2300,  0.0300,  0.0300,  0.2900,  0.1100,  0.1000,
         0.0200, -0.3000, -0.5800, -0.6700, -0.0700,  0.1200,  0.1900,  0.2300,
        -0.3000, -0.5800, -0.6700, -0.9800, -0.6700, -0.9800, -0.5500, -1.6400,
         0.0000, -0.0700,  0.1200,  0.1900, -0.3000, -0.5800, -0.6700, -0.9800,
         0.2900,  0.1100,  0.1000, -0.2400, -0.3000, -0.5800, -0.6700, -0.9800,
        -0.2400, -0.3500,  0.0200, -0.3000,  0.2900,  0.1100,  0.1000, -0.2400,
        -0.5800, -0.6700, -0.9800, -0.5500,  0.0200, -0.3000, -0.5800, -0.6700,
         0.2900,  0.1100,  0.1000, -0.2400,  0.1000, -0.2400, -0.3500,  0.0200,
         0.0300,  0.2900,  0.1100,  0.1000, -0.3500,  0.0200, -0.3000, -0.5800,
        -0.2400, -0.3500,  0.0200, -0.3000, -0.0700,  0.1200,  0.1900,  0.2300,
        -0.3500,  0.0200, -0.3000, -0.5800,  0.2300,  0.0300,  0.2900,  0.1100,
         0.1900,  0.2300,  0.0300,  0.2900,  0.1100,  0.1000, -0.2400, -0.3500,
         0.0000, -0.0700,  0.1200,  0.1900,  0.1200,  0.1900,  0.2300,  0.0300,
         0.0300,  0.2900,  0.1100,  0.1000,  0.1100,  0.1000, -0.2400, -0.3500,
         0.2300,  0.0300,  0.2900,  0.1100])
Epoch: 2, Steps: 1 | Train Loss: 0.1264080 Vali Loss: 0.2556458
lr = 0.0000904518
EarlyStopping counter: 1 out of 3
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 3 cost time: 0.5013389587402344
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2265, 0.2214, 0.2153, 0.2277, 0.2292, 0.2131, 0.2006, 0.2463, 0.2201,
        0.2604, 0.2515, 0.1823, 0.2315, 0.2332, 0.2144, 0.2175, 0.2008, 0.2331,
        0.2190, 0.2279, 0.2397, 0.2146, 0.2400, 0.1961, 0.0420, 0.4838, 0.0761,
        0.3047, 0.2082, 0.2095, 0.2476, 0.2369, 0.2191, 0.2260, 0.2267, 0.2509,
        0.2253, 0.2269, 0.2605, 0.2170, 0.2027, 0.2172, 0.2502, 0.2328, 0.1878,
        0.2664, 0.2001, 0.1996, 0.2008, 0.2360, 0.2173, 0.2148, 0.2112, 0.1911,
        0.2019, 0.2326, 0.2509, 0.2455, 0.2648, 0.2311, 0.2141, 0.2608, 0.2571,
        0.1652, 0.2471, 0.2438, 0.2284, 0.2293, 0.1939, 0.2467, 0.2116, 0.2109,
        0.2215, 0.2383, 0.1741, 0.2404, 0.2427, 0.2529, 0.2495, 0.2368, 0.1914,
        0.2045, 0.2014, 0.2372, 0.2202, 0.2593, 0.2237, 0.1984, 0.2009, 0.2378,
        0.2472, 0.2030, 0.1640, 0.1927, 0.1856, 0.2138, 0.2660, 0.2012, 0.2250,
        0.2211, 0.1782, 0.2361, 0.1913, 0.2392, 0.2266, 0.1997, 0.2672, 0.2662,
        0.2209, 0.1824, 0.2422, 0.2124, 0.1924, 0.2201, 0.1937, 0.2238, 0.2088,
        0.2572, 0.2268, 0.1922, 0.2804, 0.2262, 0.2325, 0.2825, 0.2189, 0.2360,
        0.2427, 0.2138, 0.2366, 0.2141, 0.1965, 0.2251, 0.2674, 0.1999, 0.2557,
        0.2098, 0.2518, 0.2167, 0.2534, 0.2146, 0.2173, 0.2141, 0.2385, 0.2176,
        0.2445, 0.2224, 0.2208, 0.1892, 0.1887, 0.2163, 0.2271, 0.2311, 0.2415,
        0.1839, 0.2552, 0.2157, 0.2133, 0.2457, 0.2534, 0.2111, 0.2750, 0.2146,
        0.2788, 0.2469, 0.2334, 0.1346, 0.2129, 0.2336, 0.2111, 0.2059, 0.2706,
        0.1910])
true tensor([ 0.1100,  0.1000, -0.2400, -0.3500,  0.0200, -0.3000, -0.5800, -0.6700,
        -0.3500,  0.0200, -0.3000, -0.5800, -0.2400, -0.3500,  0.0200, -0.3000,
         0.1200,  0.1900,  0.2300,  0.0300, -0.2400, -0.3500,  0.0200, -0.3000,
         0.2300,  0.0300,  0.2900,  0.1100, -0.0700,  0.1200,  0.1900,  0.2300,
        -0.2400, -0.3500,  0.0200, -0.3000,  0.0000, -0.0700,  0.1200,  0.1900,
         0.1900,  0.2300,  0.0300,  0.2900,  0.0300,  0.2900,  0.1100,  0.1000,
         0.2300,  0.0300,  0.2900,  0.1100,  0.1000, -0.2400, -0.3500,  0.0200,
        -0.3000, -0.5800, -0.6700, -0.9800,  0.1200,  0.1900,  0.2300,  0.0300,
        -0.6700, -0.9800, -0.5500, -1.6400, -0.5800, -0.6700, -0.9800, -0.5500,
        -0.3000, -0.5800, -0.6700, -0.9800,  0.0300,  0.2900,  0.1100,  0.1000,
        -0.3500,  0.0200, -0.3000, -0.5800,  0.2900,  0.1100,  0.1000, -0.2400,
         0.0200, -0.3000, -0.5800, -0.6700,  0.1200,  0.1900,  0.2300,  0.0300,
         0.2300,  0.0300,  0.2900,  0.1100,  0.2900,  0.1100,  0.1000, -0.2400,
         0.0200, -0.3000, -0.5800, -0.6700, -0.3500,  0.0200, -0.3000, -0.5800,
         0.2900,  0.1100,  0.1000, -0.2400, -0.5800, -0.6700, -0.9800, -0.5500,
         0.1000, -0.2400, -0.3500,  0.0200, -0.5800, -0.6700, -0.9800, -0.5500,
         0.0300,  0.2900,  0.1100,  0.1000, -0.0700,  0.1200,  0.1900,  0.2300,
         0.1900,  0.2300,  0.0300,  0.2900,  0.1100,  0.1000, -0.2400, -0.3500,
        -0.3000, -0.5800, -0.6700, -0.9800,  0.1900,  0.2300,  0.0300,  0.2900,
        -0.0700,  0.1200,  0.1900,  0.2300,  0.0000, -0.0700,  0.1200,  0.1900,
         0.1100,  0.1000, -0.2400, -0.3500,  0.1000, -0.2400, -0.3500,  0.0200,
         0.0000, -0.0700,  0.1200,  0.1900])
Epoch: 3, Steps: 1 | Train Loss: 0.1290520 Vali Loss: 0.2572467
lr = 0.0000793913
EarlyStopping counter: 2 out of 3
1it [00:00, 11.56it/s]
1it [00:00,  6.18it/s]
1it [00:00, 11.68it/s]
1it [00:00,  9.85it/s]
outputs torch.Size([337, 12, 18])
B 337
L 18
M 18
Epoch: 4 cost time: 0.508519172668457
outputs torch.Size([43, 12, 18])
B 43
L 18
M 18
total vali observation: torch.Size([172])
missing_idx_len: 43
pred tensor([0.2280, 0.2243, 0.2152, 0.1774, 0.2255, 0.2330, 0.2180, 0.2329, 0.2291,
        0.2271, 0.2579, 0.2066, 0.2150, 0.2357, 0.2265, 0.1985, 0.2217, 0.2255,
        0.2518, 0.2038, 0.2126, 0.2134, 0.2330, 0.2196, 0.2678, 0.2168, 0.2187,
        0.2380, 0.2241, 0.2024, 0.2592, 0.2290, 0.1893, 0.2527, 0.1965, 0.2074,
        0.2313, 0.1945, 0.2556, 0.2185, 0.2425, 0.1828, 0.2623, 0.2233, 0.2164,
        0.1885, 0.2297, 0.2377, 0.2303, 0.2187, 0.2259, 0.2049, 0.2233, 0.2214,
        0.2326, 0.2137, 0.2224, 0.1767, 0.2603, 0.2352, 0.2154, 0.2317, 0.1895,
        0.2037, 0.2109, 0.2330, 0.1969, 0.2180, 0.2312, 0.2216, 0.2416, 0.2168,
        0.2387, 0.1971, 0.2357, 0.2141, 0.1905, 0.2609, 0.2261, 0.2227, 0.2317,
        0.1707, 0.2403, 0.2778, 0.2322, 0.2337, 0.2027, 0.2127, 0.2510, 0.2152,
        0.2544, 0.2301, 0.2205, 0.2488, 0.2289, 0.1940, 0.2083, 0.1606, 0.2101,
        0.2385, 0.2466, 0.1737, 0.2330, 0.2705, 0.2025, 0.2304, 0.2515, 0.2149,
        0.2388, 0.2343, 0.2304, 0.1934, 0.1810, 0.2143, 0.1911, 0.2163, 0.2543,
        0.2000, 0.2112, 0.2486, 0.2228, 0.2570, 0.2509, 0.2036, 0.2655, 0.2013,
        0.2669, 0.2147, 0.2177, 0.1964, 0.2123, 0.2418, 0.2334, 0.2175, 0.2654,
        0.2565, 0.2742, 0.2123, 0.2347, 0.2172, 0.2692, 0.2268, 0.2541, 0.2345,
        0.2590, 0.2133, 0.2482, 0.2495, 0.2297, 0.2115, 0.1935, 0.2109, 0.2361,
        0.2073, 0.2469, 0.2178, 0.2494, 0.2061, 0.2096, 0.2514, 0.1969, 0.1962,
        0.2546, 0.2571, 0.2425, 0.2413, 0.1979, 0.2420, 0.2396, 0.1743, 0.2450,
        0.2522])
true tensor([-0.5800, -0.6700, -0.9800, -0.5500,  0.1000, -0.2400, -0.3500,  0.0200,
         0.1100,  0.1000, -0.2400, -0.3500,  0.0300,  0.2900,  0.1100,  0.1000,
        -0.6700, -0.9800, -0.5500, -1.6400,  0.1900,  0.2300,  0.0300,  0.2900,
         0.0300,  0.2900,  0.1100,  0.1000,  0.0000, -0.0700,  0.1200,  0.1900,
        -0.2400, -0.3500,  0.0200, -0.3000, -0.3500,  0.0200, -0.3000, -0.5800,
        -0.0700,  0.1200,  0.1900,  0.2300,  0.1000, -0.2400, -0.3500,  0.0200,
         0.2300,  0.0300,  0.2900,  0.1100,  0.2900,  0.1100,  0.1000, -0.2400,
         0.0200, -0.3000, -0.5800, -0.6700,  0.2900,  0.1100,  0.1000, -0.2400,
         0.2900,  0.1100,  0.1000, -0.2400,  0.0000, -0.0700,  0.1200,  0.1900,
         0.1000, -0.2400, -0.3500,  0.0200,  0.0300,  0.2900,  0.1100,  0.1000,
         0.1100,  0.1000, -0.2400, -0.3500, -0.2400, -0.3500,  0.0200, -0.3000,
        -0.5800, -0.6700, -0.9800, -0.5500, -0.3500,  0.0200, -0.3000, -0.5800,
        -0.3500,  0.0200, -0.3000, -0.5800,  0.1900,  0.2300,  0.0300,  0.2900,
         0.0000, -0.0700,  0.1200,  0.1900,  0.0200, -0.3000, -0.5800, -0.6700,
         0.1200,  0.1900,  0.2300,  0.0300,  0.1100,  0.1000, -0.2400, -0.3500,
         0.1200,  0.1900,  0.2300,  0.0300, -0.0700,  0.1200,  0.1900,  0.2300,
         0.1200,  0.1900,  0.2300,  0.0300,  0.2300,  0.0300,  0.2900,  0.1100,
         0.1900,  0.2300,  0.0300,  0.2900, -0.3000, -0.5800, -0.6700, -0.9800,
        -0.3000, -0.5800, -0.6700, -0.9800, -0.0700,  0.1200,  0.1900,  0.2300,
        -0.2400, -0.3500,  0.0200, -0.3000, -0.3000, -0.5800, -0.6700, -0.9800,
        -0.5800, -0.6700, -0.9800, -0.5500,  0.2300,  0.0300,  0.2900,  0.1100,
         0.0200, -0.3000, -0.5800, -0.6700])
Epoch: 4, Steps: 1 | Train Loss: 0.1260668 Vali Loss: 0.2565813
lr = 0.0000654543
EarlyStopping counter: 3 out of 3
Early stopping
------------------------------------
outputs torch.Size([93, 12, 18])
B 93
L 18
M 18
test shape: (1, 9) (1, 9)
test shape: (1, 1, 9) (1, 1, 9)
mae:1.1941, mse:1.4267, rmse:1.1944, r2:-1782.3765
mse_mean = 1.4267, mse_std = 0.0000
r2_mean = -1782.3765, mae_std = 0.0000