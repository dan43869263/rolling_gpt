['date', 'atq_1', 'atq_2', 'atq_3', 'ni_1', 'ni_2', 'ni_3', 'dv_1', 'dv_2', 'dv_3', 'acc_1', 'acc_2', 'acc_3', 'invest_1', 'invest_2', 'invest_3', 'mc_1', 'mc_2', 'mc_3', 'bm_1', 'bm_2', 'bm_3', 'dinvt_1', 'dinvt_2', 'dinvt_3', 'dar_1', 'dar_2', 'dar_3', 'capx_1', 'capx_2', 'capx_3', 'gm_1', 'gm_2', 'gm_3', 'sga_1', 'sga_2', 'sga_3', 'prc_1', 'prc_2', 'prc_3', 'ret_1', 'ret_2', 'ret_3', 'vol_1', 'vol_2', 'vol_3', 'shrout_1', 'shrout_2', 'shrout_3', 'medest_1', 'medest_2', 'medest_3', 'meanest_1', 'meanest_2', 'meanest_3', 'value']
train 92
['date', 'atq_1', 'atq_2', 'atq_3', 'ni_1', 'ni_2', 'ni_3', 'dv_1', 'dv_2', 'dv_3', 'acc_1', 'acc_2', 'acc_3', 'invest_1', 'invest_2', 'invest_3', 'mc_1', 'mc_2', 'mc_3', 'bm_1', 'bm_2', 'bm_3', 'dinvt_1', 'dinvt_2', 'dinvt_3', 'dar_1', 'dar_2', 'dar_3', 'capx_1', 'capx_2', 'capx_3', 'gm_1', 'gm_2', 'gm_3', 'sga_1', 'sga_2', 'sga_3', 'prc_1', 'prc_2', 'prc_3', 'ret_1', 'ret_2', 'ret_3', 'vol_1', 'vol_2', 'vol_3', 'shrout_1', 'shrout_2', 'shrout_3', 'medest_1', 'medest_2', 'medest_3', 'meanest_1', 'meanest_2', 'meanest_3', 'value']
val 8
['date', 'atq_1', 'atq_2', 'atq_3', 'ni_1', 'ni_2', 'ni_3', 'dv_1', 'dv_2', 'dv_3', 'acc_1', 'acc_2', 'acc_3', 'invest_1', 'invest_2', 'invest_3', 'mc_1', 'mc_2', 'mc_3', 'bm_1', 'bm_2', 'bm_3', 'dinvt_1', 'dinvt_2', 'dinvt_3', 'dar_1', 'dar_2', 'dar_3', 'capx_1', 'capx_2', 'capx_3', 'gm_1', 'gm_2', 'gm_3', 'sga_1', 'sga_2', 'sga_3', 'prc_1', 'prc_2', 'prc_3', 'ret_1', 'ret_2', 'ret_3', 'vol_1', 'vol_2', 'vol_3', 'shrout_1', 'shrout_2', 'shrout_3', 'medest_1', 'medest_2', 'medest_3', 'meanest_1', 'meanest_2', 'meanest_3', 'value']
test 23
gpt2 = GPT2Model(
  (wte): Embedding(50257, 768)
  (wpe): Embedding(1024, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (act): NewGELUActivation()
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
)

1it [00:03,  3.22s/it]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 1 cost time: 3.585477113723755
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([-0.3362,  0.1131,  0.1968,  0.1049,  0.0021,  0.0963, -0.1981, -0.1450,
        -0.1369,  0.0798, -0.2398, -0.0076, -0.2466, -0.0724,  0.0089,  0.2599,
        -0.2269, -0.0324,  0.0694,  0.1557, -0.4218, -0.3443, -0.0345,  0.2138])
true tensor([0.5800, 0.5200, 0.5600, 0.5800, 0.5800, 0.5200, 0.5800, 0.5200, 0.5600,
        0.7100, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600, 0.5800, 0.5200,
        0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800])
Epoch: 1, Steps: 1 | Train Loss: 0.2960082 Vali Loss: 0.4149390
lr = 0.0000975531
Validation loss decreased (inf --> 0.414939).  Saving model ...
1it [00:00,  8.20it/s]
1it [00:00,  4.17it/s]
1it [00:00,  9.31it/s]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 2 cost time: 0.7452845573425293
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([-0.2663,  0.0801,  0.1001, -0.2856, -0.1552, -0.0989,  0.2377,  0.0957,
         0.1410,  0.0288, -0.2400,  0.0838, -0.0064, -0.4069, -0.2497,  0.0979,
         0.1406,  0.0405, -0.1032,  0.0476, -0.2862, -0.2225,  0.1188,  0.1623])
true tensor([0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.5800, 0.5200,
        0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.5800,
        0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600])
Epoch: 2, Steps: 1 | Train Loss: 0.2943226 Vali Loss: 0.3981142
lr = 0.0000904518
Validation loss decreased (0.414939 --> 0.398114).  Saving model ...
1it [00:00,  3.83it/s]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 3 cost time: 0.7731776237487793
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([-0.0310, -0.1514,  0.0191, -0.0945, -0.2214, -0.0520, -0.0637,  0.0531,
        -0.0050, -0.3702,  0.1017,  0.2147, -0.1296, -0.2151, -0.1236,  0.1392,
        -0.1898, -0.2214, -0.2097,  0.0089,  0.2569, -0.0127,  0.0544,  0.1649])
true tensor([0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600,
        0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.5800, 0.5200,
        0.5600, 0.7100, 0.4800, 0.5800, 0.5200, 0.5800])
Epoch: 3, Steps: 1 | Train Loss: 0.2854666 Vali Loss: 0.3941799
lr = 0.0000793913
Validation loss decreased (0.398114 --> 0.394180).  Saving model ...
1it [00:00,  8.09it/s]
1it [00:00,  3.68it/s]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 4 cost time: 0.7765491008758545
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([-0.0291, -0.3011, -0.0041,  0.0626, -0.2394, -0.1590,  0.0762,  0.2677,
         0.0594,  0.0666,  0.0105,  0.0371, -0.4729, -0.3277,  0.1905,  0.2786,
         0.1413, -0.1262,  0.1996,  0.0609, -0.2700, -0.1988, -0.1703,  0.1241])
true tensor([0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.5800,
        0.5200, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600, 0.5800, 0.5800,
        0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100])
Epoch: 4, Steps: 1 | Train Loss: 0.2884081 Vali Loss: 0.3999451
lr = 0.0000654543
EarlyStopping counter: 1 out of 3
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
1it [00:00,  7.38it/s]
1it [00:00,  4.08it/s]
1it [00:00,  7.94it/s]
Epoch: 5 cost time: 0.7269389629364014
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([ 0.0403, -0.0534,  0.0238, -0.4515, -0.2728,  0.1546,  0.3182, -0.0612,
        -0.1159,  0.0834,  0.0818,  0.0584,  0.0739, -0.2029, -0.1601,  0.1197,
         0.1991, -0.2741, -0.1261, -0.2081,  0.1270, -0.3345,  0.1858,  0.1917])
true tensor([0.5800, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600, 0.5800, 0.5200,
        0.5600, 0.5800, 0.5200, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.5800,
        0.5200, 0.5600, 0.7100, 0.5800, 0.5200, 0.5600])
Epoch: 5, Steps: 1 | Train Loss: 0.2720444 Vali Loss: 0.3926716
lr = 0.0000500050
Validation loss decreased (0.394180 --> 0.392672).  Saving model ...
1it [00:00,  4.07it/s]
1it [00:00,  8.12it/s]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 6 cost time: 0.7329025268554688
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([-0.1259,  0.0575, -0.3336, -0.1659,  0.1526,  0.2949, -0.1435, -0.2002,
         0.1709, -0.0216, -0.1879, -0.1883,  0.0147,  0.0241,  0.0519, -0.1965,
         0.1088,  0.2487,  0.1597,  0.0512, -0.2430,  0.0218,  0.1116,  0.1418])
true tensor([0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600, 0.5800, 0.5200, 0.5600,
        0.5800, 0.5200, 0.5600, 0.7100, 0.5800, 0.5200, 0.5800, 0.5200, 0.5600,
        0.5800, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800])
Epoch: 6, Steps: 1 | Train Loss: 0.2630226 Vali Loss: 0.3619504
lr = 0.0000345557
Validation loss decreased (0.392672 --> 0.361950).  Saving model ...
1it [00:00,  3.85it/s]
0it [00:00, ?it/s]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 7 cost time: 0.7551350593566895
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([ 0.0777, -0.3202,  0.1864,  0.1386, -0.0968, -0.0222,  0.1107,  0.1345,
        -0.2238, -0.0575,  0.0737,  0.1405, -0.0545,  0.1334, -0.0959, -0.1099,
         0.1701,  0.0447, -0.0665, -0.0955, -0.2286,  0.0838, -0.0186,  0.0969])
true tensor([0.5800, 0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.5800, 0.5200,
        0.5600, 0.7100, 0.4800, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600,
        0.5800, 0.5200, 0.5600, 0.7100, 0.5800, 0.5200])
Epoch: 7, Steps: 1 | Train Loss: 0.2624472 Vali Loss: 0.3398580
lr = 0.0000206187
1it [00:00,  8.23it/s]
1it [00:00,  3.98it/s]
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 8 cost time: 0.765150785446167
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([ 0.1313, -0.2713,  0.1907,  0.2482, -0.1325, -0.1424, -0.1655,  0.1072,
         0.0879,  0.2138,  0.0662, -0.4254, -0.1986,  0.1460,  0.3905,  0.0283,
        -0.1194,  0.0499,  0.0506, -0.0307, -0.3027, -0.1151,  0.1355,  0.2887])
true tensor([0.5800, 0.5800, 0.5200, 0.5600, 0.5800, 0.5200, 0.5600, 0.7100, 0.5800,
        0.5200, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.5800, 0.5200, 0.5600,
        0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600])
Epoch: 8, Steps: 1 | Train Loss: 0.2605059 Vali Loss: 0.3528736
lr = 0.0000095582
EarlyStopping counter: 1 out of 3
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 9 cost time: 0.7253427505493164
1it [00:00,  8.68it/s]
1it [00:00,  4.12it/s]
1it [00:00,  7.95it/s]
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([-0.0866, -0.0861, -0.0489,  0.0536, -0.0016, -0.2083,  0.0099, -0.1029,
         0.1717,  0.1487,  0.0420, -0.1952, -0.2922,  0.2076,  0.2183,  0.1505,
        -0.2573,  0.2547,  0.0670,  0.0848,  0.1156, -0.2443, -0.2127,  0.1944])
true tensor([0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.5800, 0.5200, 0.5600, 0.7100,
        0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600, 0.5800, 0.5800, 0.5200,
        0.5600, 0.5800, 0.5200, 0.5800, 0.5200, 0.5600])
Epoch: 9, Steps: 1 | Train Loss: 0.2687543 Vali Loss: 0.3540609
lr = 0.0000024569
EarlyStopping counter: 2 out of 3
outputs torch.Size([92, 12, 54])
B 92
L 18
M 54
Epoch: 10 cost time: 0.7578933238983154
outputs torch.Size([8, 12, 54])
B 8
L 18
M 54
total vali observation: torch.Size([24])
missing_idx_len: 8
pred tensor([ 0.0634, -0.1795, -0.0026, -0.2029, -0.1417,  0.0613,  0.0939,  0.0092,
         0.1702,  0.2048, -0.2016, -0.2312,  0.0308,  0.1984, -0.2375,  0.1359,
         0.1256, -0.2024, -0.0932, -0.0618,  0.2214, -0.1561, -0.0787,  0.1712])
true tensor([0.5800, 0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.3600, 0.5800, 0.5200,
        0.5800, 0.5200, 0.5600, 0.7100, 0.4800, 0.5800, 0.5200, 0.5600, 0.5800,
        0.5200, 0.5600, 0.7100, 0.5800, 0.5200, 0.5600])
Epoch: 10, Steps: 1 | Train Loss: 0.2613840 Vali Loss: 0.3590061
lr = 0.0000000100
EarlyStopping counter: 3 out of 3
Early stopping
1it [00:00,  4.00it/s]
1it [00:00,  8.11it/s]
1it [00:00,  7.24it/s]
------------------------------------
outputs torch.Size([23, 12, 54])
B 23
L 18
M 54
test shape: (1, 203) (1, 203)
test shape: (1, 1, 203) (1, 1, 203)
mae:0.3567, mse:0.1897, rmse:0.4356, r2:-5.4656
mse_mean = 0.1897, mse_std = 0.0000
r2_mean = -5.4656, mae_std = 0.0000